{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "8ddb0841-5aa3-4c1c-b9d1-90563ee16841",
      "metadata": {},
      "outputs": [],
      "source": [
        "<center>\n    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"400\" alt=\"cognitiveclass.ai logo\"  />\n</center>\n\n# Financial services: Lab. 1.  Dataset Creation, Order Books Analyses (using BTC and USD) \n\n\nEstimated time needed: **30** minutes\n\nThe tasks:<br>\n*  Download and process statistical time series of cryptocurrency order book (using BTC and USD), describing the dynamics of the cryptocurrency    market;\n*  Upload statistical data from the Pandas library;\n*  Calculate and analyze order book tendencies, calculating balance (saldo) of ask and bid indicator.\n\n\n\n\n### Objectives\n\nAfter completing this lab you will be able to:\n\n*  Acquire data in various ways\n*  Obtain insights from data with Pandas library \n*  Resample data\n*  Calculate Indicators for cryptocurrency market analysis \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc71621b-af71-4026-af1e-21cc9ffe2aae",
      "metadata": {},
      "outputs": [],
      "source": [
        "<h3>Table of Contents</h3>\n\n<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n<ol>\n    <li><a href=\"https://#data_acquisition\">Data Acquisition</a></li>\n        <ul>\n            <li><a href=\"https://#read_data\">Read Data</a></li>\n        </ul>\n    <li><a href=\"https://#resample\">Resample</a></li>\n        <ul>\n            <li><a href=\"https://#merge_join_concatenate_and_compare\">Merge, join, concatenate and compare</a></li>\n        </ul>\n    <li><a href=\"https://#basic_insight\">Basic Insight of Dataset</a></li>\n        <ul>\n            <li><a href=\"https://#data_types\">Data Types</a></li>\n            <li><a href=\"https://#describe\">Describe</a></li>\n            <li><a href=\"https://#info\">Info</a></li>\n            <li><a href=\"https://#save_dataset\">Save Dataset</a></li>\n        </ul>\n</ol>\n\n</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c0b3c5b-64d6-495a-98f3-691f4b5c1407",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. Data Acquisition\n<p>\nThere are various formats for a dataset: .csv, .json, .xlsx  etc. The dataset can be stored in different places, on your local machine or sometimes online.<br>\n\nIn this section, you will learn how to load a dataset into our Jupyter Notebook.<br>\n\nIn our case, the Trading Dataset is an online source, and it is in a CSV (comma separated value) format. Let's use this dataset as an example to practice data reading.\n\n<ul>\n    <li>Data source: <a href=\"https://archive.ics.uci.edu/ml/machine-learning-databases/autos/imports-85.data?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDA0101ENSkillsNetwork20235326-2021-01-01\" target=\"_blank\">https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-GPXX0UM3EN/orderbooks_bitfinex_BTCUSD%20(1).csv</a></li>\n    <li>Data source: <a href=\"https://archive.ics.uci.edu/ml/machine-learning-databases/autos/imports-85.data?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDA0101ENSkillsNetwork20235326-2021-01-01\" target=\"_blank\">https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-GPXX0UM3EN/trades_non_aggregated_bitfinex_BTCUSD.csv</a></li>\n    <li>Data type: csv</li>\n</ul>\nThe Pandas Library is a useful tool that enables us to read various datasets into a dataframe; our Jupyter notebook platforms have a built-in <b>Pandas Library</b> so that all we need to do is import Pandas without installing.\n</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "c3e662a4-40f8-41b6-97c5-ffdba053c07c",
      "metadata": {},
      "outputs": [],
      "source": [
        "#install specific version of libraries used in  lab\n#! mamba install pandas  -y\n#! mamba install numpy -y"
      ]
    },
    {
      "cell_type": "code",
      "id": "95c33844-13d1-4eb0-b60c-636eb4920276",
      "metadata": {},
      "outputs": [],
      "source": [
        "# import pandas library\nimport pandas as pd\nimport numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3efe340e-9550-4578-9934-afba597d02c7",
      "metadata": {},
      "outputs": [],
      "source": [
        "### Read Data\n<p>\nWe use <code>pandas.read_csv()</code> function to read the csv file. In the brackets, we put the file path along with a quotation mark so that pandas will read the file into a dataframe from that address. The file path can be either an URL or your local file address.<br>\n\nBecause the data does not include headers, we can add an argument <code>headers = None</code> inside the <code>read_csv()</code> method so that pandas will not automatically set the first row as a header.<br>\n\nYou can also assign the dataset to any variable you create.\n\n</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ada7d7e5-5e33-42bc-b386-2ee5aedc44fe",
      "metadata": {},
      "outputs": [],
      "source": [
        "You will need to download the dataset; if you are running locally, please comment out the following\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d37e3b6-9eab-4f72-9c61-1b5354d8a5c3",
      "metadata": {},
      "outputs": [],
      "source": [
        "<div class=\"alert alert-danger alertdanger\" >\nТут потрібно дописати в любомтувати чому є 2 різних набори даних і як ви їх з'єднувати. Напевно це краще маю зробити Марія\n</div>"
      ]
    },
    {
      "cell_type": "code",
      "id": "ed2aed20-ee6c-4754-94ae-5e100c917c41",
      "metadata": {},
      "outputs": [],
      "source": [
        "#you will need to download the dataset; if you are running locally, please comment out the following \npath_order_books= \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-GPXX0UM3EN/orderbooks_bitfinex_BTCUSD%20(1).csv\"\npath_BTC = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-GPXX0UM3EN/trades_non_aggregated_bitfinex_BTCUSD.csv\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d9c9a48-cc6f-404b-a347-b0c123d6f3f1",
      "metadata": {},
      "outputs": [],
      "source": [
        "This dataset was hosted on IBM Cloud object. Click <a href=\"https://cocl.us/DA101EN_object_storage?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDA0101ENSkillsNetwork20235326-2021-01-01\">HERE</a> for free storage.\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "0ef58c4e-e5f3-443f-800e-309941325c6d",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_orderbooks = pd.read_csv(path_order_books, index_col=0)\ndf_BTC = pd.read_csv(path_BTC, index_col=0)\n#add \"index_col\" to remove the header Unnamed"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2bda4e13-885b-4d26-81c0-c7a33769f1cd",
      "metadata": {},
      "outputs": [],
      "source": [
        "Further specify the value of the precision parameter equal to 2 to display two decimal signs (instead of 6 as default)."
      ]
    },
    {
      "cell_type": "code",
      "id": "87aa1cac-2d51-49ac-b2ca-439066b35b06",
      "metadata": {},
      "outputs": [],
      "source": [
        "pd.options.display.float_format = '{:.2f}'.format\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40a6ded3-f293-4eb1-9aeb-b09fe9feab43",
      "metadata": {},
      "outputs": [],
      "source": [
        "After reading the dataset, we can use the <code>dataframe.head(n)</code> method to check the top n rows of the dataframe, where n is an integer. Contrary to <code>dataframe.head(n)</code>, <code>dataframe.tail(n)</code> will show you the bottom n rows of the dataframe.\n\nWe should adds the suffix \"_BTC\" to column names in the df_BTC DataFrame. This may be done to distinguish this data from others that may be stored in the same DataFrame.\n\nWe also convert the value of the \"ts_BTC\" column from the string value type to the datetime type using the pd.to_datetime() function. This makes it easier to work with this data and perform some operations over time.\n\nAnd also Set column 'ts_BTC' as index of DataFrame df_BTC. This means that this column will be used to access the DataFrame's data and hierarchy.\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "e96418b5-06ed-429c-b065-b78b2259d3aa",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_BTC = df_BTC.add_suffix(\"_BTC\")\ndf_BTC['ts_BTC'] = pd.to_datetime(df_BTC['ts_BTC'])\ndf_BTC = df_BTC.set_index(\"ts_BTC\")\ndf_BTC.head(5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d724bb6-a34e-4036-a8ad-2b0aa58bb976",
      "metadata": {},
      "outputs": [],
      "source": [
        "<div class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\">\n<h1> Question #1: </h1>\n<b>Check the bottom 2\n    rows of data frame \"df_BTC\".</b>\n</div>\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "5fa45733-2e76-4506-9611-4fd034491ed6",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Write your code below and press Shift+Enter to execute \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96d1e3c6-255e-4b79-ad10-cb3e92215249",
      "metadata": {},
      "outputs": [],
      "source": [
        "<details><summary>Click here for the solution</summary>\n\n```python\nprint(\"The last 2 rows of the dataframe\\n\")\ndf_BTC.head(2)\n```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ed373ee-e70b-49e3-a44d-d8f61d7e4386",
      "metadata": {},
      "outputs": [],
      "source": [
        "Now we need to repeat what we did with the df_BTC dataframe and do it for the df_orderbooks dataframe"
      ]
    },
    {
      "cell_type": "code",
      "id": "d4735fcb-4d25-4cc8-8d49-c8399769dd2d",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_orderbooks = df_orderbooks.add_suffix(\"_BTC\")\ndf_orderbooks['ts_BTC'] = pd.to_datetime(df_orderbooks['ts_BTC'])\ndf_orderbooks = df_orderbooks.set_index(\"ts_BTC\")\ndf_orderbooks.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ccce9f74-2143-490b-830a-f63cd96eb8a3",
      "metadata": {},
      "outputs": [],
      "source": [
        "Since we need analize separately bid and ask let's to divide the orderbook into separate Data Sets. This will allow us to write 2 different data pairs to our dataset."
      ]
    },
    {
      "cell_type": "code",
      "id": "ac2fa4ba-6c92-49bf-8408-9d0fd51426e7",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_ask = df_orderbooks[df_orderbooks.side_BTC == \"ask\"]\ndf_ask = df_ask.add_suffix(\"_ask\")\ndf_ask"
      ]
    },
    {
      "cell_type": "code",
      "id": "3b8f0051-cf16-4541-98a7-ef2da42517c6",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_bid = df_orderbooks[df_orderbooks.side_BTC == \"bid\"]\ndf_bid = df_bid.add_suffix(\"_bid\")\ndf_bid\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "243cdd01-4605-4e86-8a4f-9eac282405f4",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2. Resample"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f35c8ec-1e8e-498c-b668-568364478227",
      "metadata": {},
      "outputs": [],
      "source": [
        "Resampling is used in time series data. \nThis is a convenience method for frequency conversion and resampling of time series data. Although it works on the condition that objects must have a datetime-like index for example, DatetimeIndex, PeriodIndex, or TimedeltaIndex. \nIn simpler words, if one wants to arrange the time series data in patterns like monthly, weekly, daily, etc., this function is very useful. \nThis function is available in Pandas library.<br><br>\nWe carry out resample with an interval of 1 hour so that we have a specific measurement of the time for which we take data. You can also perform the operation, for example, by the minute. In this particular case, I took an hour interval so that we don't have NaN"
      ]
    },
    {
      "cell_type": "code",
      "id": "f8e59f5d-f922-4a2f-b6cc-42237e75a5c4",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_ask = df_ask.resample(\"1H\").agg({\"price_BTC_ask\":\"mean\",\"size_BTC_ask\":\"sum\"})\ndf_ask"
      ]
    },
    {
      "cell_type": "code",
      "id": "a1dcf940-dbcf-4b21-9f34-f5f8301c203f",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_bid = df_bid.resample(\"1H\").agg({\"price_BTC_bid\":\"mean\",\"size_BTC_bid\":\"sum\"})\ndf_bid"
      ]
    },
    {
      "cell_type": "code",
      "id": "e7e3644a-d8a3-4266-812b-aed28d9d584d",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_BTC = df_BTC.resample(\"1H\").agg({\"price_BTC\":\"mean\",\"volume_BTC\":\"sum\"})\ndf_BTC\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "07194eb5-3f51-4024-9542-4326a7731001",
      "metadata": {},
      "outputs": [],
      "source": [
        "### Merge, join, concatenate and compare"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c75ee1f-8321-4a17-81cf-fe0cde31e1bc",
      "metadata": {},
      "outputs": [],
      "source": [
        "Pandas provides various facilities for easily combining together Series or DataFrame with various kinds of set logic for the indexes and relational algebra functionality in the case of join / merge-type operations.\n\nIn addition, pandas also provides utilities to compare two Series or DataFrame and summarize their differences.\n\nAlso we need creates a new column named Saldo in df_all and calculates the value using the specified data from df_all. The value in this new column will be the difference between the product of size_BTC_bid and price_BTC_bid and the product of size_BTC_ask and price_BTC_ask.\n\nWe should see this merge first joins the DataFrames df_ask and df_bid using indexes, adding the suffixes '_ask' and '_bid' respectively. This result is then merged with the DataFrame df_BTC using indexes. The result is stored in the variable df_all."
      ]
    },
    {
      "cell_type": "code",
      "id": "39292a17-ac8a-4eb5-ada7-cfae610d3d7b",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_all = pd.merge(df_ask, df_bid, left_index=True, right_index=True, suffixes=('_ask', '_bid'))\ndf_all = pd.merge(df_all, df_BTC, left_index=True, right_index=True)\ndf_all['Saldo'] = df_all['size_BTC_bid'] - df_all['size_BTC_ask'] \ndf_all"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "953b3777-b7d6-46a3-86d2-9cb92afbb30f",
      "metadata": {},
      "outputs": [],
      "source": [
        " <div class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\">\n<h1> Question #2: </h1>\n<b>Find the name of the columns of the dataframe.</b>\n</div>\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "8237ff4b-4c9e-4e47-a6b9-8c2b4681f436",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Write your code below and press Shift+Enter to execute"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd2d7e98-4fe5-4740-802b-8e51677fa01c",
      "metadata": {},
      "outputs": [],
      "source": [
        "<details><summary>Click here for the solution</summary>\n\n```python\nprint(df_BTC.columns)\n```\n\n</details>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa3c29d4-fbd9-4728-9862-fedb56a8aa51",
      "metadata": {},
      "outputs": [],
      "source": [
        "### Set Headers\n\n<p>\nLet's change we have to add headers manually\n</p>\n<p>\nFirst, we create a list \"headers\" that include all column names in order.\nThen, we use <code>dataframe.columns = headers</code> to replace the headers with the list we created.\n</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "96a10f08-2a11-4322-b0b4-0a09ed23049c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# create headers list\nheaders = [\"price ASK\",\"size ASK\",\"price BID\",\"size BID\",\"price BTC\",\"size BTC\",\"Saldo\"]\nprint(\"Headers\\n\", headers)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "81273776-9dbd-40b3-86d9-f6a964118807",
      "metadata": {},
      "outputs": [],
      "source": [
        "We replace headers and recheck our dataframe:\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "90a58394-9299-4f87-ab5f-af33d58b4b31",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_all.columns = headers\ndf_all.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e24f7ef4-80ed-4eb4-85eb-6234ad49f3f2",
      "metadata": {},
      "outputs": [],
      "source": [
        "### Save Dataset\n<p>\nCorrespondingly, Pandas enables us to save the dataset to csv. By using the <code>dataframe.to_csv()</code> method, you can add the file path and name along with quotation marks in the brackets.\n</p>\n<p>\nFor example, if you would save the dataframe <b>df_all</b> as <b>df_all_1H.csv</b> to your local machine, you may use the syntax below, where <code>index = False</code> means the row names will not be written.\n</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "0728facc-572b-4c34-961e-ccfbef175136",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_all.to_csv(\"df_all_1H.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c89c212e-cb0c-475f-a4e8-cc8f7df80036",
      "metadata": {},
      "outputs": [],
      "source": [
        "We can also read and save other file formats. We can use similar functions like **`pd.read_csv()`** and **`df.to_csv()`** for other data formats. The functions are listed in the following table:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0f243de-32f1-46c6-b2d5-588f00ab05f7",
      "metadata": {},
      "outputs": [],
      "source": [
        "### Read/Save Other Data Formats\n\n| Data Formate |        Read       |            Save |\n| ------------ | :---------------: | --------------: |\n| csv          |  `pd.read_csv()`  |   `df.to_csv()` |\n| json         |  `pd.read_json()` |  `df.to_json()` |\n| excel        | `pd.read_excel()` | `df.to_excel()` |\n| hdf          |  `pd.read_hdf()`  |   `df.to_hdf()` |\n| sql          |  `pd.read_sql()`  |   `df.to_sql()` |\n| ...          |        ...        |             ... |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d2f52ad-fd74-407b-9c5b-4e1d0ab977b1",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3. Basic Insight of Dataset\n<p>\nAfter reading data into Pandas dataframe, it is time for us to explore the dataset.<br>\n\nThere are several ways to obtain essential insights of the data to help us better understand our dataset.\n\n</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31751965-efa2-4232-bb29-48cf4e5d8852",
      "metadata": {},
      "outputs": [],
      "source": [
        "### Data Types\n<p>\nData has a variety of types.<br>\n\nThe main types stored in Pandas dataframes are <b>object</b>, <b>float</b>, <b>int</b>, <b>bool</b> and <b>datetime64</b>. In order to better learn about each attribute, it is always good for us to know the data type of each column. In Pandas:\n\n</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "97753c52-f238-461d-818d-65998004f697",
      "metadata": {},
      "outputs": [],
      "source": [
        "# check the data type of data frame \"df\" by .dtypes\nprint(df_all.dtypes)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a5c4c19-95ae-46dc-972d-5258eda68941",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n<p>\nThese data types can be changed; we will learn how to accomplish this in a later module.\n</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed52f332-03c9-42fa-bbf7-4b9559a76e04",
      "metadata": {},
      "outputs": [],
      "source": [
        "### Describe\nIf we would like to get a statistical summary of each column e.g. count, column mean value, column standard deviation, etc., we use the describe method:\n"
      ]
    },
    {
      "cell_type": "raw",
      "id": "ccca4f89-d856-49c3-984a-f8c543fc55da",
      "metadata": {},
      "outputs": [],
      "source": [
        "dataframe.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0d49eea-d080-4ee2-81ed-440671df6e1a",
      "metadata": {},
      "outputs": [],
      "source": [
        "This method will provide various summary statistics, excluding <code>NaN</code> (Not a Number) values.\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "16c1fbb8-1b4a-45bf-9f9a-61e88abcf7fc",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_all.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "619b0cc2-8321-4b73-adf1-fe1f92408c6c",
      "metadata": {},
      "outputs": [],
      "source": [
        "<p>\nThis shows the statistical summary of all numeric-typed (int, float) columns.<br>\n\n\nHowever, what if we would also like to check all the columns including those that are of type object? <br><br>\n\nYou can add an argument <code>include = \"all\"</code> inside the bracket. Let's try it again.\n\n</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "279be539-474f-4dfc-bfbf-55ad490927e7",
      "metadata": {},
      "outputs": [],
      "source": [
        "# describe all the columns in \"df\" \ndf_all.describe(include = \"all\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b36389b-975f-4b61-9d3b-90f01dd75dd0",
      "metadata": {},
      "outputs": [],
      "source": [
        "<p>\nNow it provides the statistical summary of all the columns, including object-typed attributes.<br>\n\nWe can now see how many unique values there, which one is the top value and the frequency of top value in the object-typed columns.<br>\n\n\n</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0bde0abe-63ff-4b07-9b90-4ed4cd759350",
      "metadata": {},
      "outputs": [],
      "source": [
        "<div class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\">\n<h1> Question #3: </h1>\n\n<p>\nYou can select the columns of a dataframe by indicating the name of each column. For example, you can select the three columns as follows:\n</p>\n<p>\n    <code>dataframe[[' column 1 ',column 2', 'column 3']]</code>\n</p>\n<p>\nWhere \"column\" is the name of the column, you can apply the method  \".describe()\" to get the statistics of those columns as follows:\n</p>\n<p>\n    <code>dataframe[[' column 1 ',column 2', 'column 3'] ].describe()</code>\n</p>\n\nApply the  method to \".describe()\" to the columns 'price_BTC' and 'size_ASK'.\n\n</div>\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "22502f90-7762-4f37-8c76-ee317749063a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Write your code below and press Shift+Enter to execute \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e17fb686-8f3e-4208-94f5-1c916da38eb6",
      "metadata": {},
      "outputs": [],
      "source": [
        "<details><summary>Click here for the solution</summary>\n\n```python\ndf_all[['price_BTC', 'size_ASK']].describe()\n```\n\n</details>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32b85687-acfe-4622-ac79-b2806610059c",
      "metadata": {},
      "outputs": [],
      "source": [
        "### Info</h2>\nAnother method you can use to check your dataset is:\n"
      ]
    },
    {
      "cell_type": "raw",
      "id": "3922a4ce-6b63-4933-a08e-15343e0aa604",
      "metadata": {},
      "outputs": [],
      "source": [
        "dataframe.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70970bdf-d271-4115-b0ce-4aa9c3a892fe",
      "metadata": {},
      "outputs": [],
      "source": [
        "It provides a concise summary of your DataFrame.\n\nThis method prints information about a DataFrame including the index dtype and columns, non-null values and memory usage.\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "a7ed6645-dbd2-4aa9-9e30-b567bcad37a5",
      "metadata": {},
      "outputs": [],
      "source": [
        "# look at the info of \"df\"\ndf_all.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1a5339ce-91b4-4274-a31d-aa4089cf5357",
      "metadata": {},
      "outputs": [],
      "source": [
        "## Excellent! You have just completed the  Introduction Notebook!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c2781fa-c580-4db0-bb2d-3a3fc55c74a6",
      "metadata": {},
      "outputs": [],
      "source": [
        "### Thank you for completing this lab!\n\n## Author\n\n<a href=\"https://author.skills.network/instructors/danyil_zhupnyk\">Danyil Zhupnyk</a><br>\n<a href=\"https://author.skills.network/instructors/yaroslav_vyklyuk_2\">Prof. Yaroslav Vyklyuk, DrSc, PhD</a><br>\n<a href=\"https://author.skills.network/instructors/mariya_fleychuk\">Prof. Mariya Fleychuk, DrSc, PhD</a><br>\n\n## Change Log\n\n| Date (YYYY-MM-DD) | Version | Changed By | Change Description                 |\n| ----------------- | ------- | ---------- | ---------------------------------- |\n| 2023-02-28        | 1.0     | D.Zhupnyk  | Created Lab                        |\n\n<hr>\n\n## <h3 align=\"center\"> © IBM Corporation 2023. All rights reserved. <h3/>"
      ]
    },
    {
      "cell_type": "code",
      "id": "1ca93d05-9292-4421-a154-c826548743ec",
      "metadata": {},
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": ""
    },
    "kernelspec": {
      "name": "",
      "display_name": ""
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}