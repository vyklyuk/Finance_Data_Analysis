{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "02eac35f-2a2d-4382-99ea-b6dc935a50d3",
      "metadata": {},
      "outputs": [],
      "source": [
        "<center>\n    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"300\" alt=\"cognitiveclass.ai logo\"  />\n</center>\n\n# Investigation of cryptocurrency exchange rate dynamic (Matic/USD), сalculation and analysis of technical financial indicators, characterizing the cryptocurrency market (ATR, OBV, RSI, AD)\n\n## Lab 3. Exploratoy Data Analysis\n\nEstimated time needed: **30** minutes\n\n## Objectives\n\nAfter completing this lab you will be able to:\n\n*   Explore features or charecteristics to predict volume of Matic\n\n### **Columns**\n\n* #### `Ts` - the timestamp of the record\n* #### `Open` -  the price of the asset at the beginning of the trading period\n* #### `High` -  the highest price of the asset during the trading period\n* #### `Low` - the lowest price of the asset during the trading period.\n* #### `Close` - the price of the asset at the end of the trading period\n* #### `Volume` - the total number of shares or contracts of a particular asset that are traded during a given period\n* #### `Rec_count` -  the number of individual trades or transactions that have been executed during a given time period\n* #### `Avg_price` - the average price at which a particular asset has been bought or sold during a given period\n* #### `ATR` - average true range indicator\n* #### `OBV` - on-balance volume indicator\n* #### `RSI` - relative strength index indicator\n* #### `AD` - accumulation / distribution indicator\n* #### `BTC_price` - the avarage price from BTC/BUSD dataset \n* #### `BNB_price` - the avarage price from BNB/BUSD dataset\n* ##### Additional columns:  'Open_EUR', 'BTC_price_EUR', 'high_EUR', 'High_Normalized', 'Low_Normalized','close_low', 'close_medium', 'close_high', 'rec_count-binned','rec_count_low', 'rec_count_medium', 'rec_count_high'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b36284f-a937-40ce-b035-9f66bcf62733",
      "metadata": {},
      "outputs": [],
      "source": [
        "## Table of Contents\n\n<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n<ol>\n    <li><a href=\"https://#import_data\">Import Data from Module</a></li>\n    <li><a href=\"https://#pattern_visualization\">Analyzing Individual Feature Patterns using Visualization</a></li>\n    <li><a href=\"https://#discriptive_statistics\">Descriptive Statistical Analysis</a></li>\n    <li><a href=\"https://#basic_grouping\">Basics of Grouping</a></li>\n    <li><a href=\"https://#correlation_causation\">Correlation and Causation</a></li>\n    <li><a href=\"https://#anova\">ANOVA</a></li>\n</ol>\n\n</div>\n\n<hr>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a39bd7e7-8a02-4636-a12f-c589ce4c4b1c",
      "metadata": {},
      "outputs": [],
      "source": [
        "### What are the main characteristics that have the most impact on the Matic volume?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8f870b8-1a8f-4f2a-bc15-d5ebaec55151",
      "metadata": {},
      "outputs": [],
      "source": [
        "## 1. Import Data from Module 2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "afba1c06-5208-408f-8913-545c1c1b710a",
      "metadata": {},
      "outputs": [],
      "source": [
        "#### Setup\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a080c0f-9c70-4129-9f2b-4a3790c857be",
      "metadata": {},
      "outputs": [],
      "source": [
        "you are running the lab in your  browser, so we will install the libraries using `piplite`\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "96421c2d-1558-4321-87a9-443500940b2a",
      "metadata": {},
      "outputs": [],
      "source": [
        "! pip install scikit-learn \n! pip install mplfinance"
      ]
    },
    {
      "cell_type": "code",
      "id": "2f817ceb-5ff1-4079-81d1-d92a2ef58c51",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\nimport matplotlib.pylab as plt\nimport seaborn as sns\nimport numpy as np\nimport pandas as pd \nimport numpy as np \nimport mplfinance as fplt\nfrom scipy import stats\nfrom statsmodels.tsa.stattools import grangercausalitytests\nimport statsmodels.api as sm\nfrom statsmodels.stats.stattools import durbin_watson as dwtest\nimport warnings\n\nwarnings.filterwarnings('ignore')\n%matplotlib inline \n#set precision \npd.set_option(\"display.precision\", 2)\n#set precision for float\npd.options.display.float_format = '{:.2f}'.format"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d876a46e-760f-4ffa-9474-5724b3929a70",
      "metadata": {},
      "outputs": [],
      "source": [
        "Import libraries:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3dc65ac8-f58a-4b80-bbaf-bf08e052d5fe",
      "metadata": {},
      "outputs": [],
      "source": [
        "If you run the lab locally using Anaconda, you can load the correct library and versions by uncommenting the following:\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "ef72aed9-dc81-468a-a8af-5241ccb774dd",
      "metadata": {},
      "outputs": [],
      "source": [
        "#If you run the lab locally using Anaconda, you can load the correct library and versions by uncommenting the following:\n#install specific version of libraries used in lab\n#! mamba install pandas==1.3.3\n#! mamba install numpy=1.21.2\n#! mamba install scipy=1.7.1-y\n#!  mamba install seaborn=0.9.0-y"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a9142d65-7f39-4cdf-b1a8-eecfa3c0a830",
      "metadata": {},
      "outputs": [],
      "source": [
        "This function will download the dataset into your browser\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "948f9302-0f1b-495f-9e13-acd8c12d9989",
      "metadata": {},
      "outputs": [],
      "source": [
        "##Now you need to use dataset, you made in he first lab \nfilename = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-GPXX0YYYEN/Lab2DataSet.csv\"\ndf = pd.read_csv(filename,low_memory=False, index_col=0)\ndf"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "63b8171c-6736-4c76-b48c-b7d57430d051",
      "metadata": {},
      "outputs": [],
      "source": [
        "Load the data and store it in dataframe `df`:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf80d733-bff6-401f-af2d-2bd7aa9b2719",
      "metadata": {},
      "outputs": [],
      "source": [
        "This dataset was hosted on IBM Cloud object. Click <a href=\"https://cocl.us/DA101EN_object_storage?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDA0101ENSkillsNetwork20235326-2021-01-01\">HERE</a> for free storage.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a15394b6-5b62-41cc-9987-37f7ef29e158",
      "metadata": {},
      "outputs": [],
      "source": [
        "## 2. Analyzing Individual Feature Patterns Using Visualization\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "815cbf32-a8a4-4bfd-bc64-95e6801c150d",
      "metadata": {},
      "outputs": [],
      "source": [
        "To install Seaborn we use pip, the Python package manager.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6348903e-a34f-43ea-a58d-03a64275cbc2",
      "metadata": {},
      "outputs": [],
      "source": [
        "#### How to choose the right visualization method?\n<p>When visualizing individual variables, it is important to first understand what type of variable you are dealing with. This will help us find the right visualization method for that variable.</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "83c6d1f9-ed2b-471f-91ea-097437933f3b",
      "metadata": {},
      "outputs": [],
      "source": [
        "#set correct types\ndf.index = df.index.astype(\"datetime64[ns]\")\ndf.head()"
      ]
    },
    {
      "cell_type": "code",
      "id": "3a2a0288-f6a3-4a6c-a6d3-e02e9b1583fd",
      "metadata": {},
      "outputs": [],
      "source": [
        "# list the data types for each column\nprint(df.dtypes)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c84a654-6afe-4786-9991-0973c6c4f6a0",
      "metadata": {},
      "outputs": [],
      "source": [
        "Before we start, let's look at the graph of Matic fluctuations. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "070645ac-34e4-4c09-a7f2-e07ac347534f",
      "metadata": {},
      "outputs": [],
      "source": [
        "Make a new dataframe for our graph:"
      ]
    },
    {
      "cell_type": "code",
      "id": "d8fe9c69-99a2-4a7b-8945-b268bacd54b3",
      "metadata": {},
      "outputs": [],
      "source": [
        "# make a dataframe\nbox = pd.DataFrame()\n# set columns\nbox['Open'] = df['Open']\nbox['High'] = df['High']\nbox['Low'] = df['Low']\nbox['Close'] = df['Close']\nbox.index = df.index\n# drop all NaN\nbox = box.dropna()\n# set column 'time' as index\nbox.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e6a38f7-7167-4a80-85ea-7e689c32be93",
      "metadata": {},
      "outputs": [],
      "source": [
        "Use function <code>fplt.plot</code> for our graphic:"
      ]
    },
    {
      "cell_type": "code",
      "id": "0ff12570-6119-40d1-beda-7f2e926ca0e7",
      "metadata": {},
      "outputs": [],
      "source": [
        "fplt.plot(box.head(50),\n          type='candle',\n          style='charles',\n          title='MATIC',\n          ylabel='Price ($)')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4241ac9d-e151-4358-a314-6ec41c9108d2",
      "metadata": {},
      "outputs": [],
      "source": [
        "<div class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\">\n<h3>Question  #1:</h3>\n\n<b>What is the data type of the column \"Volume\"? </b>\n\n</div>\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "04d5d179-c12d-4d2a-88bf-bded47c09d91",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Write your code below and press Shift+Enter to execute \ndf['Volume'].dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4946bd30-fa5e-4458-a35b-3137463538bb",
      "metadata": {},
      "outputs": [],
      "source": [
        "<details><summary>Click here for the solution</summary>\n\n```python\ndf['Volume'].dtypes\n```\n\n</details>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e043b6b1-7305-4aee-8788-1361f9f40dc1",
      "metadata": {},
      "outputs": [],
      "source": [
        "For example, we can calculate the correlation between all variables with different types using the method \"corr\":\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "e9ec56f9-6c9d-4350-b409-3ed55317f47b",
      "metadata": {},
      "outputs": [],
      "source": [
        "corr = df.corr()\ncorr"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40480f1a-ed79-4bdf-aa13-a3ce5d0ad52f",
      "metadata": {},
      "outputs": [],
      "source": [
        "Here is correlation between Matic Volume,Rec_cout, also between BTC and BNB prices:\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "cda57b25-46fe-4fc8-bcf8-bcae2a6149b8",
      "metadata": {},
      "outputs": [],
      "source": [
        "corr = df[[\"Volume\",\"Rec_count\",\"BTC_price\",\"BNB_price\"]].corr()\nsns.heatmap(corr)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1bf4786-a741-419e-afd5-7962769e9579",
      "metadata": {},
      "outputs": [],
      "source": [
        "The diagonal elements are always one; we will study correlation more precisely Pearson correlation in-depth at the end of the notebook.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "654335d4-bd4c-4820-8753-da99bef93f25",
      "metadata": {},
      "outputs": [],
      "source": [
        "<div class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\">\n<h3> Question  #2: </h3>\n\n<p>Find the correlation between the following columns: Volume, Close ; and built a heatmap for them.</p>\n<p>Hint: if you would like to select those columns, use the following syntax:corr = df[[\"Open\",\"Close\"]]</p>\n</div>\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "a430b1bb-f952-4321-8251-99cdde56e428",
      "metadata": {},
      "outputs": [],
      "source": [
        "corr = df[[\"Volume\",\"Close\"]].corr()\nsns.heatmap(corr)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04e794c2-60fd-4b4d-a004-af1c25c60aba",
      "metadata": {},
      "outputs": [],
      "source": [
        "<details><summary>Click here for the solution</summary>\n\n```python\ncorr = df[[\"Volume\",\"Close\"]].corr()\nsns.heatmap(corr)\n```\n\n</details>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4260436-7558-4f86-aea1-83474cf5267e",
      "metadata": {},
      "outputs": [],
      "source": [
        "## Continuous Numerical Variables:\n\n<p>Continuous numerical variables are variables that may contain any value within some range. They can be of type \"int64\" or \"float64\". A great way to visualize these variables is by using scatterplots with fitted lines.</p>\n\n<p>In order to start understanding the (linear) relationship between a Volume and a Rec_count for Matic, we can use \"regplot\" which plots the scatterplot plus the fitted regression line for the data.</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e104f24-e076-4e7c-bd65-c28281abb430",
      "metadata": {},
      "outputs": [],
      "source": [
        "Let's see several examples of different linear relationships:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01e969b1-0a63-4ccc-be8d-ae741ae5f453",
      "metadata": {},
      "outputs": [],
      "source": [
        "<h3>Positive Linear Relationship</h4>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0def5793-edcd-4e83-b346-87b872745e0a",
      "metadata": {},
      "outputs": [],
      "source": [
        "Let's find the scatterplot of \"Rec_count\" and \"Volume\".\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "a09d5abc-41ba-4c84-a0ec-591e122ae1f1",
      "metadata": {},
      "outputs": [],
      "source": [
        "# volume price as potential predictor variable of volume\nsns.regplot(x=\"Rec_count\", y=\"Volume\", data=df,scatter_kws={'s':2})\nplt.ylim(200,)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb1bd7cc-437a-4529-9717-7b9a8506d5e8",
      "metadata": {},
      "outputs": [],
      "source": [
        "<p>As the Rec_count goes up, the Volume goes up: this indicates a positive direct correlation between these two variables. Rec_cont seems like a good predictor of Volume since the regression line is almost a perfect diagonal line.</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c2793f3a-8497-4851-9913-82cb4539fbf8",
      "metadata": {},
      "outputs": [],
      "source": [
        "We can examine the correlation between 'Volume' and 'Rec_count' and see that it's approximately 0.68.\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "74c9f92e-3a29-4349-8b70-4672d18fda9f",
      "metadata": {},
      "outputs": [],
      "source": [
        "df[[\"Rec_count\", \"Volume\"]].corr()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5922c68a-01dd-4c81-ae20-fa4b144ee216",
      "metadata": {},
      "outputs": [],
      "source": [
        "### Weak Linear Relationship\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94c042e8-60fd-4705-beea-60c44d372b15",
      "metadata": {},
      "outputs": [],
      "source": [
        "We have some financial indicators like \"OBV\", \"RSI\", \"AD\" and \"ATR\" in our dataset, lets check the correlation between Volume and indicators:"
      ]
    },
    {
      "cell_type": "code",
      "id": "241bb1fa-756d-4ec0-ac6e-aedd79bb6331",
      "metadata": {},
      "outputs": [],
      "source": [
        "df[[\"Volume\", \"OBV\",\"RSI\",\"AD\",\"ATR\"]].corr()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1a9959ad-df05-4b64-a0a1-763c1f73bd4f",
      "metadata": {},
      "outputs": [],
      "source": [
        "Also make a heatmap:"
      ]
    },
    {
      "cell_type": "code",
      "id": "2cd0a37a-709d-4c74-b88b-c2add0d12793",
      "metadata": {},
      "outputs": [],
      "source": [
        "sns.heatmap(df[[\"Volume\", \"OBV\",\"RSI\",\"AD\",\"ATR\"]].corr())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6150b6d3-bc4c-4030-a9a5-a5204f6986b1",
      "metadata": {},
      "outputs": [],
      "source": [
        "As we can see in the table and on the map, the strongest correlation between the volume and the indicators is ATR with a value of 0.55, which is not an indicator of a strong dependency."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "51919cba-0b4e-4e24-9a83-15fd3ed2cc2e",
      "metadata": {},
      "outputs": [],
      "source": [
        "Let's see if \"BNB_price\" is a predictor variable of \"Volume\".\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "68d79410-3349-41b7-86d0-5146a8d50e01",
      "metadata": {},
      "outputs": [],
      "source": [
        "sns.regplot(x=\"BTC_price\", y=\"Volume\", data=df,scatter_kws={'s':2})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a0b03ac-5893-4ffa-bdde-e797adea4970",
      "metadata": {},
      "outputs": [],
      "source": [
        "<p>BTC_price does not seem like a good predictor of the Volume at all since the regression line is close to horizontal. Also, the data points are very scattered and far from the fitted line, showing lots of variability. Therefore, it's not a reliable variable.</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "879bdb00-684a-4296-87b5-e99019254f62",
      "metadata": {},
      "outputs": [],
      "source": [
        "We can examine the correlation between 'BTC_price' and 'Volume' and see it's approximately -0.20.\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "a5c4c440-5c9e-4d9c-97cd-e05d7d3a023c",
      "metadata": {},
      "outputs": [],
      "source": [
        "df[['BTC_price','Volume']].corr()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27674d4d-b940-4965-b6db-c430814b288b",
      "metadata": {},
      "outputs": [],
      "source": [
        "<div class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\">\n    <b style=\"font-size: 2em; font-weight: bold;\"> Question  3 a): </b><br>\n    <p>Find the correlation  between \"Volume\" and \"ATR\".</p>\n    <p>Hint: if you would like to select those columns, use the following syntax:df[[\"ATR\",\"Volume\"]].corr()  </p>\n</div>\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "dd5af2cb-46aa-4f33-98b1-d0df98bf1eb7",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Write your code below and press Shift+Enter to execute\ndf[[\"ATR\",\"Volume\"]].corr()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee61191e-d59d-4dc3-898c-08e5fe2655c5",
      "metadata": {},
      "outputs": [],
      "source": [
        "<details><summary>Click here for the solution</summary>\n\n```python\n\n#The correlation is 0.491169.\n\ndf[[\"Volume\",\"ATR\"]].corr()\n\n```\n\n</details>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5b4fe90-bda3-47cc-95df-51b32fa0fb5e",
      "metadata": {},
      "outputs": [],
      "source": [
        "<div class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\">\n    <b style=\"font-size: 2em; font-weight: bold;\">Question  3 b):</b><br>\n    <p>Given the correlation results between \"\n    ATR\" and \"Volume\", do you expect a linear relationship?</p> \n    <p>Verify your results using the function \"regplot()\".</p>\n</div>\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "732ac74e-d237-4814-8ff1-03c55c512697",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Write your code below and press Shift+Enter to execute \nsns.regplot(x=\"ATR\", y=\"Volume\", data=df,scatter_kws={'s':2})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c463886-3b9e-4e5a-9807-d6678c252e61",
      "metadata": {},
      "outputs": [],
      "source": [
        "<details><summary>Click here for the solution</summary>\n\n```python\n\nsns.regplot(x=\"ATR\", y=\"Volume\", data=df,scatter_kws={'s':2})\n\n```\n\n</details>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "02b24f7d-5cdc-4e02-b04b-f5843caa885a",
      "metadata": {},
      "outputs": [],
      "source": [
        "### Make Categorical Variables for next point\n<p>Let`s make categorical values as in the past lab.</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9d2ad8b-55dc-4cd5-8137-e6965134afc9",
      "metadata": {},
      "outputs": [],
      "source": [
        "<p>We would like 5 bins of equal size bandwidth so we use numpy's <code>linspace(start_value, end_value, numbers_generated</code> function.</p>\n<p>Since we want to include the minimum value of open, we want to set start_value = min(df[\"open\"]).</p>\n<p>Since we want to include the maximum value of open, we want to set end_value = max(df[\"open\"]).</p>\n<p>Since we are building 5 bins of equal length, there should be 6 dividers, so numbers_generated = 6.</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a9a86e2-bace-4be3-8370-ba040be663e7",
      "metadata": {},
      "outputs": [],
      "source": [
        "We build a bin array with a minimum value to a maximum value by using the bandwidth calculated above. The values will determine when one bin ends and another begins.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0de4b7a1-78c6-4d59-b6b6-1405bfe7a593",
      "metadata": {},
      "outputs": [],
      "source": [
        "We set group  names:\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "f8579597-ee2b-4597-8d46-69aae80e1bbf",
      "metadata": {},
      "outputs": [],
      "source": [
        "group_names = ['Low','Lower Medium' ,'Medium', 'Upper Medium' ,'High']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "67c7836c-177e-475f-b18e-36e7a978a085",
      "metadata": {},
      "outputs": [],
      "source": [
        "We have to make some fields categorical, lets make a function which make it"
      ]
    },
    {
      "cell_type": "code",
      "id": "76ac9065-436c-4a5c-8df5-1452280ff98f",
      "metadata": {},
      "outputs": [],
      "source": [
        "def to_categorical(column: pd.Series, labels: list) -> pd.Series:\n    cat_number = len(labels)\n    bins = np.linspace(min(column), max(column), cat_number+1)\n    #We apply the function \"cut\" to determine what each value of column belongs to.\n    res = pd.cut(column, bins, labels=labels, include_lowest=True)\n    return res"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a00194c-7ef5-47fb-a391-efad70173d28",
      "metadata": {},
      "outputs": [],
      "source": [
        "Now lets use our function with: Avg_price, BTC_price, BNB_price:"
      ]
    },
    {
      "cell_type": "code",
      "id": "3d10b797-9b2d-4051-b26f-3269a2ae698b",
      "metadata": {},
      "outputs": [],
      "source": [
        "df['Avg_price-binned'] = to_categorical(df[\"Avg_price\"],group_names)\ndf[[\"Avg_price\", \"Avg_price-binned\"]].head()"
      ]
    },
    {
      "cell_type": "code",
      "id": "f2400646-5f22-47ed-a22d-e6ece0e8feb6",
      "metadata": {},
      "outputs": [],
      "source": [
        "df['BTC_price-binned'] = to_categorical(df[\"BTC_price\"],group_names)\ndf[[\"BTC_price\", \"BTC_price-binned\"]].head()"
      ]
    },
    {
      "cell_type": "code",
      "id": "0e70df52-63ec-499c-8528-9209fd13052f",
      "metadata": {},
      "outputs": [],
      "source": [
        "df['BNB_price-binned'] = to_categorical(df[\"BNB_price\"],group_names)\ndf[[\"BNB_price\", \"BNB_price-binned\"]].head()"
      ]
    },
    {
      "cell_type": "code",
      "id": "a3af8e33-b0a3-4abb-8489-0dd937162ae4",
      "metadata": {},
      "outputs": [],
      "source": [
        "df['Rec_count-binned'] = to_categorical(df[\"Rec_count\"],group_names)\ndf[[\"Rec_count\", \"Rec_count-binned\"]].head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9233d17-f4e8-416a-9d5a-b46e8932bc7f",
      "metadata": {},
      "outputs": [],
      "source": [
        "<p>These are variables that describe a 'characteristic' of a data unit, and are selected from a small group of categories. The categorical variables can have the type \"object\" or \"int64\". A good way to visualize categorical variables is by using boxplots.</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "60761812-e459-4625-8420-4b643e55e59c",
      "metadata": {},
      "outputs": [],
      "source": [
        "Let's look at the relationship between \"Avg_price-binned\" and \"Volume\".\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "1a42d2c1-a5fb-4248-8359-5e0c02307bf4",
      "metadata": {},
      "outputs": [],
      "source": [
        "sns.boxplot(x=\"Avg_price-binned\", y=\"Volume\", data=df)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8acf88ff-8d0c-4a29-911f-3de13deba8de",
      "metadata": {},
      "outputs": [],
      "source": [
        "<p>Here we see that the distribution of price between these five categories are distinct enough to take in which catagery price will be as a potential good predictor of price. Let's examine engine \"BTC_price-binned\" and \"Volume\":</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "a520061a-697a-4f13-bd4f-f40e2c0febf4",
      "metadata": {},
      "outputs": [],
      "source": [
        "sns.boxplot(x=\"BTC_price-binned\", y=\"Volume\", data=df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9386ebe0-dd67-4f36-a405-b4240c84dc5f",
      "metadata": {},
      "outputs": [],
      "source": [
        "<p>We can see the same.</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f77c508-096d-4ab3-912b-62a1d5520c09",
      "metadata": {},
      "outputs": [],
      "source": [
        "Let's examine \"BNB_price-binned\" and \"Volume\".\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "15ebbc31-15f7-4bb7-9fdc-efa277d49b09",
      "metadata": {},
      "outputs": [],
      "source": [
        "# drive-wheels\nsns.boxplot(x=\"BNB_price-binned\", y=\"Volume\", data=df)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9533a0cd-464c-47a8-b99f-44191492dd7f",
      "metadata": {},
      "outputs": [],
      "source": [
        "<p><p>We see that the distributions of price between the different categories have a significant overlap, so BNB_price-binned would not be a good predictor of Volume. </p>\n</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00fbd017-cb87-47a1-8a77-b43c80b07509",
      "metadata": {},
      "outputs": [],
      "source": [
        "<p>Let's examine \"Rec_count\" and \"Volume\".\n</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "cb1da979-d1d6-4c53-92fb-13fe1087f2bc",
      "metadata": {},
      "outputs": [],
      "source": [
        "# drive-wheels\nsns.boxplot(x=\"Rec_count-binned\", y=\"Volume\", data=df)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f62dcbfd-3345-459d-af94-0c53b92457b1",
      "metadata": {},
      "outputs": [],
      "source": [
        "## 3. Descriptive Statistical Analysis\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "851ca8c6-15eb-45d5-8bdc-cfbc5b158c96",
      "metadata": {},
      "outputs": [],
      "source": [
        "<p>Let's first take a look at the variables by utilizing a description method.</p>\n\n<p>The <b>describe</b> function automatically computes basic statistics for all continuous variables. Any NaN values are automatically skipped in these statistics.</p>\n\nThis will show:\n\n<ul>\n    <li>the count of that variable</li>\n    <li>the mean</li>\n    <li>the standard deviation (std)</li> \n    <li>the minimum value</li>\n    <li>the IQR (Interquartile Range: 25%, 50% and 75%)</li>\n    <li>the maximum value</li>\n<ul>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "717fc504-d04a-44ee-bda6-fcb67ec2fefb",
      "metadata": {},
      "outputs": [],
      "source": [
        "We can apply the method \"describe\" as follows:\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "7be1dd27-3481-41b9-898d-d08bdd4252d8",
      "metadata": {},
      "outputs": [],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7e11a41-f4d3-4fa1-85d8-fb8dc9a31646",
      "metadata": {},
      "outputs": [],
      "source": [
        "The default setting of \"describe\" skips variables of type category. We can apply the method \"describe\" on the variables of type 'category' as follows:\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "1ca3a69c-e778-4b2f-b679-dd4c6e401d32",
      "metadata": {},
      "outputs": [],
      "source": [
        "df.describe(include='category')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e0e34ac-4fef-493e-8e47-f75045b2d6dd",
      "metadata": {},
      "outputs": [],
      "source": [
        "### Value Counts\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e86a9f7-def3-4cea-8e43-12252bb8ca62",
      "metadata": {},
      "outputs": [],
      "source": [
        "<p>Value counts is a good way of understanding how many units of each characteristic/variable we have. We can apply the \"value_counts\" method on the column \"Volume\". Don’t forget the method \"value_counts\" only works on pandas series, not pandas dataframes. As a result, we only include one bracket <code>df['Volume']</code>, not two brackets <code>df[['Volume']]</code>.</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "4a15d3e4-afaf-44f8-839d-b8eba020a6ed",
      "metadata": {},
      "outputs": [],
      "source": [
        "df['Volume'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84a7305b-f25e-4b4e-8873-bfeb0f4878ed",
      "metadata": {},
      "outputs": [],
      "source": [
        "We can convert the series to a dataframe as follows:\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "d86deb69-f632-4a68-8d34-f1629ddfe9c9",
      "metadata": {},
      "outputs": [],
      "source": [
        "df['Volume'].value_counts().to_frame()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "65514513-d2a4-4609-89a0-85a8fc8c107f",
      "metadata": {},
      "outputs": [],
      "source": [
        "Let's repeat the above steps but save the results to the dataframe \"Avg_price_binned_counts\" and rename the column  'Avg_price-binned' to 'value_counts'.\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "5ce0701a-41a7-4261-ae14-c70948cc114f",
      "metadata": {},
      "outputs": [],
      "source": [
        "Volume_counts = df['Volume'].value_counts().to_frame()\nVolume_counts.rename(columns={'Volume': 'volume_counts'}, inplace=True)\nVolume_counts"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d686aa3-5e5b-42d2-ab18-fedb229825ee",
      "metadata": {},
      "outputs": [],
      "source": [
        "Now let's rename the index to 'Avg_price-binned':\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "b7a02238-2f12-4e18-8adf-6a9fccbdf4da",
      "metadata": {},
      "outputs": [],
      "source": [
        "Volume_counts.index.name = 'Volume_counts'\nVolume_counts"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90458c5a-13e6-43dd-ac79-38c2fd17333e",
      "metadata": {},
      "outputs": [],
      "source": [
        "<p>After examining the value counts of the Avg_price-binned, we see that this category would be a good predictor variable for the price. This is because we only have mostly our prices in 'Medium'.</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "943d4a6d-b850-4a8b-a0b6-1e70a40a8713",
      "metadata": {},
      "outputs": [],
      "source": [
        "## 4. Basics of Grouping\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d08a96b-3de1-4e6d-b6ea-f047e9a82423",
      "metadata": {},
      "outputs": [],
      "source": [
        "<p>The \"groupby\" method groups data by different categories. The data is grouped based on one or several variables, and analysis is performed on the individual groups.</p>\n\n<p>For example, let's group by the variable \"Avg_price-binned\". We see that there are 5 different categories of Avg_price-binned.</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "92daf75b-f4ef-4583-9e4e-49f64a362d43",
      "metadata": {},
      "outputs": [],
      "source": [
        "df['Volume'].unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "473f5914-1f59-4a46-8f7d-302e357a5d39",
      "metadata": {},
      "outputs": [],
      "source": [
        "<p>If we want to know, on average, which type of Avg_price-binned is most valuable, we can group \"Avg_price-binned\" and then average them.</p>\n\n<p>We can select the columns 'Avg_price-binned' and 'Avg_price', then assign it to the variable \"df_group_one\".</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "a12bd161-08c3-49a5-a583-9da915634470",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_group_one = df[['Avg_price-binned','Volume']]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3471135f-5989-436f-8d89-ee541a2c964b",
      "metadata": {},
      "outputs": [],
      "source": [
        "We can then calculate the average price for each of the different categories of data.\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "9d550a0c-b497-4128-ad92-37d9c583e74c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# grouping results\ndf_group_one = df_group_one.groupby(['Avg_price-binned'],as_index=False).mean()\ndf_group_one"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "509e63fd-5e88-45e3-b37d-2de538b022c5",
      "metadata": {},
      "outputs": [],
      "source": [
        "<p>From our data, it seems High category are the most expensive.</p>\n\n<p>You can also group by multiple variables. For example, let's group by both 'Avg_price-binned' and 'BTC_price-binned'. This groups the dataframe by the unique combination of 'Avg_price-binned' and 'Avg_price-binned'. We can store the results in the variable 'grouped_test1'.</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "a24dbf3f-ca08-4224-bdcf-515ee0743601",
      "metadata": {},
      "outputs": [],
      "source": [
        "# grouping results\ndf_gptest = df[['BTC_price-binned','Volume']]\ngrouped_test1 = df_gptest.groupby(['BTC_price-binned'],as_index=False).mean()\ngrouped_test1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f17a3b8a-ff1c-46a7-83db-2b4e878b31e8",
      "metadata": {},
      "outputs": [],
      "source": [
        "<p>This grouped data is much easier to visualize when it is made into a pivot table. A pivot table is like an Excel spreadsheet, with one variable along the column and another along the row. We can convert the dataframe to a pivot table using the method \"pivot\" to create a pivot table from the groups.</p>\n\n<p>In this case, we will leave the Avg_price-binned variable as the rows of the table, and BTC_price-binned to become the columns of the table:</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "4a766cdd-08ae-4b49-97f6-3e114bdd339c",
      "metadata": {},
      "outputs": [],
      "source": [
        "grouped_pivot = pd.crosstab(index=grouped_test1['BTC_price-binned'],columns=grouped_test1['Volume'])\ngrouped_pivot"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be621c09-c3f0-4b88-bd70-5969626d4086",
      "metadata": {},
      "outputs": [],
      "source": [
        "<p>Often, we won't have data for some of the pivot cells. We can fill these missing cells with the value 0, but any other value could potentially be used as well. It should be mentioned that missing data is quite a complex subject and is an entire course on its own.</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "019eb236-2d70-4bff-a3c6-4aa43527a3bf",
      "metadata": {},
      "outputs": [],
      "source": [
        "grouped_pivot = grouped_pivot.fillna(0) #fill missing values with 0\ngrouped_pivot"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c085cda-c8cf-4106-8df9-25f0a38528d1",
      "metadata": {},
      "outputs": [],
      "source": [
        "Also we can use a crossed table to see how many values correspond to each other in the table:"
      ]
    },
    {
      "cell_type": "code",
      "id": "a025e1d6-95b3-469e-97f9-93c26aec886b",
      "metadata": {},
      "outputs": [],
      "source": [
        "crossed_table = pd.crosstab(df['Avg_price-binned'],df['Rec_count-binned'])\ncrossed_table"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e74fe460-6aeb-48b8-b30d-3a016be12adb",
      "metadata": {},
      "outputs": [],
      "source": [
        "As we can see, mostly they correspond when bin for BTC is 'Medium' and bin for Avg_price is 'Medium'."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25beb5b8-470f-4e67-911d-6986638f6c7f",
      "metadata": {},
      "outputs": [],
      "source": [
        "<div class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\">\n    <b style=\"font-size: 2em; font-weight: bold;\">Question 4:</b><br>\n    <p>Use the \"groupby\" function to find the average \"BTC_price\" of each trade based on \"BTC_price-binned\".</p>\n</div>\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "83823e20-de22-4564-8dba-f83a41ce4697",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Write your code below and press Shift+Enter to execute \n# grouping results\ndf_gptest2 = df[['BTC_price','Volume']]\ngrouped_test_bodystyle = df_gptest2.groupby(['BTC_price'],as_index= False).mean()\ngrouped_test_bodystyle"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "239f50d6-4385-42cd-9acc-53085fb17a94",
      "metadata": {},
      "outputs": [],
      "source": [
        "<details><summary>Click here for the solution</summary>\n\n```python\ndf_gptest2 = df[['BTC_price','Volume']]\ngrouped_test_bodystyle = df_gptest2.groupby(['BTC_price'],as_index= False).mean()\ngrouped_test_bodystyle\n```\n\n</details>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4391d1f6-b03e-4b2c-9e4d-b83c3d12f851",
      "metadata": {},
      "outputs": [],
      "source": [
        "#### Variables: BTC_price-binned vs. Avg_price-binned\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "969f6947-7073-4742-bcfd-7fa35d75f305",
      "metadata": {},
      "outputs": [],
      "source": [
        "Let's use a heat map to visualize the relationship between BTC_price-binned vs Avg_price-binned."
      ]
    },
    {
      "cell_type": "code",
      "id": "a5d93e0d-f49c-4397-a7fb-5627eed814bd",
      "metadata": {},
      "outputs": [],
      "source": [
        "#use the grouped results\nplt.grid(False)\nplt.pcolor(crossed_table, cmap='RdBu')\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23ee952e-b587-43f9-8020-2589285fb32c",
      "metadata": {},
      "outputs": [],
      "source": [
        "<p>The heatmap plots the target variable (price) proportional to colour with respect to the variables 'Avg_price-binned' and 'BTC_price-binned' on the vertical and horizontal axis, respectively. This allows us to visualize how the price is related to 'BTC_price-binned' and 'Avg_price-binned'.</p>\n\n<p>The default labels convey no useful information to us. Let's change that:</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "123ec501-43e2-4d89-942c-9393928eda8e",
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots()\nplt.grid(False)\n\nim = ax.pcolor(crossed_table, cmap='RdBu')\n\n# Set the row and column labels\nrow_labels = crossed_table.columns\ncol_labels = crossed_table.index\n\n# Set the x and y tick positions to the center of each cell\nax.set_xticks(np.arange(crossed_table.shape[1]) + 0.5)\nax.set_yticks(np.arange(crossed_table.shape[0]) + 0.5)\n\n# Set the tick labels\nax.set_xticklabels(row_labels, rotation=90)\nax.set_yticklabels(col_labels)\n\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "46864d3f-49e2-47a8-bb02-470dfda39d6e",
      "metadata": {},
      "outputs": [],
      "source": [
        "<p>Visualization is very important in data science, and Python visualization packages provide great freedom. We will go more in-depth in a separate Python visualizations course.</p>\n\n<p>The main question we want to answer in this module is, \"What are the main characteristics that have the most impact on the MATIC price?\".</p>\n\n<p>To get a better measure of the important characteristics, we look at the correlation of these variables with the MATIC avg price. In other words: how is the MATIC avg price dependent on this variable?</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e3a6466-88dd-46c0-8ae8-c3ece3fc7137",
      "metadata": {},
      "outputs": [],
      "source": [
        "## 5. Correlation and Causation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ec2dfae-9348-445c-9ac8-078ab5b7b5fd",
      "metadata": {},
      "outputs": [],
      "source": [
        "<p><b>Correlation</b>: a measure of the extent of interdependence between variables.</p>\n\n<p><b>Causation</b>: the relationship between cause and effect between two variables.</p>\n\n<p>It is important to know the difference between these two. Correlation does not imply causation. Determining correlation is much simpler  the determining causation as causation may require independent experimentation.</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cbe09cbf-f2ea-49c7-bf1c-aab53070284b",
      "metadata": {},
      "outputs": [],
      "source": [
        "<p><b>Pearson Correlation</b></p>\n<p>The Pearson Correlation measures the linear dependence between two variables X and Y.</p>\n<p>The resulting coefficient is a value between -1 and 1 inclusive, where:</p>\n<ul>\n    <li><b>1</b>: Perfect positive linear correlation.</li>\n    <li><b>0</b>: No linear correlation, the two variables most likely do not affect each other.</li>\n    <li><b>-1</b>: Perfect negative linear correlation.</li>\n</ul>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72cf8b1f-58f2-4957-9a61-1c639e5944fa",
      "metadata": {},
      "outputs": [],
      "source": [
        "<p>Pearson Correlation is the default method of the function \"corr\". Like before, we can calculate the Pearson Correlation of the of the 'int64' or 'float64'  variables.</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "595b8723-2e30-4a21-a165-cb2267a78dd1",
      "metadata": {},
      "outputs": [],
      "source": [
        "df.corr()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1dd90386-7172-49c1-8fbf-c7cc3a79cb61",
      "metadata": {},
      "outputs": [],
      "source": [
        "Sometimes we would like to know the significant of the correlation estimate.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4eac7cf3-8efb-42eb-849b-36c996452bf5",
      "metadata": {},
      "outputs": [],
      "source": [
        "<b>P-value</b>\n\n<p>What is this P-value? The P-value is the probability value that the correlation between these two variables is statistically significant. Normally, we choose a significance level of 0.05, which means that we are 95% confident that the correlation between the variables is significant.</p>\n\nBy convention, when the\n\n<ul>\n    <li>p-value is $<$ 0.001: we say there is strong evidence that the correlation is significant.</li>\n    <li>the p-value is $<$ 0.05: there is moderate evidence that the correlation is significant.</li>\n    <li>the p-value is $<$ 0.1: there is weak evidence that the correlation is significant.</li>\n    <li>the p-value is $>$ 0.1: there is no evidence that the correlation is significant.</li>\n</ul>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "21518665-62e7-4512-bd77-3be9efed9ab4",
      "metadata": {},
      "outputs": [],
      "source": [
        "<h3>\"Volume\" vs. \"BNB_price\"</h3>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bdeaa51f-77b7-4f91-8386-b45031887525",
      "metadata": {},
      "outputs": [],
      "source": [
        "Let's calculate the  Pearson Correlation Coefficient and P-value of \"Avg_price\" and \"BNB_price\".\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "61c13bc8-74d3-406d-867a-ecf8f4da9620",
      "metadata": {},
      "outputs": [],
      "source": [
        "pearson_coef, p_value = stats.pearsonr(df[\"Volume\"], df[\"BNB_price\"])\nprint(\"The Pearson Correlation Coefficient is\", round(pearson_coef, 2), \" with a P-value of P =\", round(p_value, 2))  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b18aa23-344a-430c-a310-a45ab8d0cf59",
      "metadata": {},
      "outputs": [],
      "source": [
        "#### Conclusion:\n<p>Since the p-value is $<$ 0.001, the correlation between \"Avg_price\" and \"BNB_price\" is statistically significant and the linear relationship is strong enough (≈ 0.63).</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ba705d59-5ed4-461d-8aaa-093c188d6b08",
      "metadata": {},
      "outputs": [],
      "source": [
        "### \"Volume\" vs. \"BTC_price\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "24ee520f-124f-49d0-a7ee-1a40b8b00a14",
      "metadata": {},
      "outputs": [],
      "source": [
        "Let's calculate the  Pearson Correlation Coefficient and P-value of \"Avg_price\" and \"BTC_price\".\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "b3d40bee-670c-4fc0-9615-859bacb3fa9e",
      "metadata": {},
      "outputs": [],
      "source": [
        "pearson_coef, p_value = stats.pearsonr(df[\"Volume\"], df[\"Rec_count\"])\nprint(\"The Pearson Correlation Coefficient is\", round(pearson_coef, 2), \" with a P-value of P = \", p_value)  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dfa5c99c-1124-4347-bcb3-e43547be58cb",
      "metadata": {},
      "outputs": [],
      "source": [
        "<h4>Conclusion:</h4>\n\n<p>Since the p-value is $<$ 0.001, the correlation between \"ETHBUSD_avg_price\" and \"BNBBUSD_avg_price\" is statistically significant, and the linear relationship is quite weak (≈ 0.37).</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4351de69-e1ec-4ea7-a52e-b683fa564967",
      "metadata": {},
      "outputs": [],
      "source": [
        "<b style=\"font-size: 2em; font-weight: bold;\"> Volume\" vs. \"BTC_price\"</b>\n\nLet's calculate the  Pearson Correlation Coefficient and P-value of \"BNB_price\" and \"BTC_price\".\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "223c1d30-cde1-446f-afce-326590454b54",
      "metadata": {},
      "outputs": [],
      "source": [
        "pearson_coef, p_value = stats.pearsonr(df[\"Volume\"], df[\"ATR\"])\nprint(\"The Pearson Correlation Coefficient is\", round(pearson_coef, 2), \" with a P-value of P = \", p_value)  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f9896ea-a45d-4362-9296-95728cc59998",
      "metadata": {},
      "outputs": [],
      "source": [
        "#### Conclusion:\n\nSince the p-value is < 0.001, the correlation between \"BNB_price\" and \"BTC_price\" is statistically significant and the linear relationship is weak (≈ 0.06).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ffbc7d10-3bd3-4eb9-97bd-1608c024b1c3",
      "metadata": {},
      "outputs": [],
      "source": [
        "### \"Volume\" vs. \"ATR\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11d437aa-5501-49df-ba9c-c529608d8a0a",
      "metadata": {},
      "outputs": [],
      "source": [
        "Let's calculate the Pearson Correlation Coefficient and P-value of \"BNBBUSD_avg_price\" and \"APEBUSD_avg_price\":\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "9a7878a8-ceec-4b07-a48e-c9bbe0e2cb5b",
      "metadata": {},
      "outputs": [],
      "source": [
        "pearson_coef, p_value = stats.pearsonr(df[\"Volume\"], df[\"ATR\"])\nprint( \"The Pearson Correlation Coefficient is\", round(pearson_coef, 2), \" with a P-value of P = \", p_value)  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b783bc9-660f-47a0-a7f4-614642b81f24",
      "metadata": {},
      "outputs": [],
      "source": [
        "#### Conclusion:\n<p>Since the p-value is $<$ 0.001, the correlation between \"Avg_price\" and \"ATR\" is statistically significant, and the linear relationship is only moderate (≈ 0.31).</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a9aa4585-7f64-4ac7-90b4-09cfe3efdd40",
      "metadata": {},
      "outputs": [],
      "source": [
        "### \"Volume\" vs. \"OBV\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54aa7d1e-8e49-4ca9-9cb4-916e46067876",
      "metadata": {},
      "outputs": [],
      "source": [
        "Let's calculate the  Pearson Correlation Coefficient and P-value of \"Avg_price\" and \"OBV\":\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "06ab4d8b-1d44-4929-b2a3-5d85b44082b9",
      "metadata": {},
      "outputs": [],
      "source": [
        "pearson_coef, p_value = stats.pearsonr(df[\"Volume\"], df[\"OBV\"])\nprint(\"The Pearson Correlation Coefficient is\", round(pearson_coef, 2), \" with a P-value of P =  \", p_value ) "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f470c13d-23b9-44fa-88ea-8b8df53083bd",
      "metadata": {},
      "outputs": [],
      "source": [
        "#### Conclusion:\n<p>Since the p-value is $<$ 0.001, the correlation between \"Avg_price\" and \"OVB\" is statistically significant and the linear relationship is only moderate(≈ 0.19).</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa8207e1-dace-4a6a-9ea2-db75344d96af",
      "metadata": {},
      "outputs": [],
      "source": [
        "## 6. ANOVA\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b883c0ac-3e93-4ca3-a83a-d7ff52c506dd",
      "metadata": {},
      "outputs": [],
      "source": [
        "### ANOVA: Analysis of Variance\n<p>The Analysis of Variance  (ANOVA) is a statistical method used to test whether there are significant differences between the means of two or more groups. ANOVA returns two parameters:</p>\n\n<p><b>F-test score</b>: ANOVA assumes the means of all groups are the same, calculates how much the actual means deviate from the assumption, and reports it as the F-test score. A larger score means there is a larger difference between the means.</p>\n\n<p><b>P-value</b>:  P-value tells how statistically significant our calculated score value is.</p>\n\n<p>If our price variable is strongly correlated with the variable we are analyzing, we expect ANOVA to return a sizeable F-test score and a small p-value.</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a05fd4b-bde8-476b-96b8-f608d47aa4ac",
      "metadata": {},
      "outputs": [],
      "source": [
        "### BNBBUSD_ap_cat\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6266acc1-fc84-4a2c-8f15-306d768be48c",
      "metadata": {},
      "outputs": [],
      "source": [
        "<p>Since ANOVA analyzes the difference between different groups of the same variable, the groupby function will come in handy. Because the ANOVA algorithm averages the data automatically, we do not need to take the average before hand.</p>"
      ]
    },
    {
      "cell_type": "code",
      "id": "80fbcf1c-2051-407e-93f3-fe9a13ae4e52",
      "metadata": {},
      "outputs": [],
      "source": [
        "grouped_test2 = df[[\"Avg_price-binned\", \"Volume\"]].groupby([\"Avg_price-binned\"])\ngrouped_test2.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb9c6e1d-9382-412e-adb9-e75e1623958d",
      "metadata": {},
      "outputs": [],
      "source": [
        "We can obtain the values of the method group using the method \"get_group\".\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "632cc09b-3c97-49da-8557-35f33f3e96a8",
      "metadata": {},
      "outputs": [],
      "source": [
        "grouped_test2.get_group(\"Medium\")[\"Volume\"]"
      ]
    },
    {
      "cell_type": "code",
      "id": "ebe065a1-edb3-4e41-829f-4a0db7416b15",
      "metadata": {},
      "outputs": [],
      "source": [
        "grouped_test2.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "169490de-0abf-4f6a-8d25-9a7dd5d13cab",
      "metadata": {},
      "outputs": [],
      "source": [
        "We can use the function \"f_oneway\" in the module \"stats\" to obtain the <b>F-test score</b> and <b>P-value</b>.\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "b443603f-552b-49ed-b414-ff2aa3c07951",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ANOVA\nf_val, p_val = stats.f_oneway(grouped_test2.get_group(\"Low\")[\"Volume\"], grouped_test2.get_group(\"Lower Medium\")[\"Volume\"], grouped_test2.get_group(\"Medium\")[\"Volume\"], grouped_test2.get_group(\"Upper Medium\")[\"Volume\"], grouped_test2.get_group(\"High\")[\"Volume\"])  \n \nprint(\"ANOVA results: F=\", round(f_val, 2), \", P =\", round(p_val, 2))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6823eaf7-0d5d-4f1b-8310-5796df52b211",
      "metadata": {},
      "outputs": [],
      "source": [
        "This is a great result with a large F-test score showing a strong correlation and a P-value of 0 implying almost certain statistical significance. But does this mean all five tested groups are all this highly correlated?\n\nLet's examine them separately.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78f342b9-eca5-4de5-b254-e7083457175c",
      "metadata": {},
      "outputs": [],
      "source": [
        "#### Low and Lower Medium\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "95308029-3f4b-4c54-8b00-2fae450a1aba",
      "metadata": {},
      "outputs": [],
      "source": [
        "f_val, p_val = stats.f_oneway(grouped_test2.get_group(\"Low\")[\"Volume\"], grouped_test2.get_group(\"Lower Medium\")[\"Volume\"])  \n \nprint( \"ANOVA results: F=\", round(f_val, 2), \", P =\", round(p_val, 2) )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e2822b4-7a78-408b-8862-06aa11c68043",
      "metadata": {},
      "outputs": [],
      "source": [
        "Let's examine the other groups.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e222f3c-c316-4181-97e4-981700605b47",
      "metadata": {},
      "outputs": [],
      "source": [
        "#### Low and Medium\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "d1e5a637-1397-4a46-9dfe-576ae9319584",
      "metadata": {},
      "outputs": [],
      "source": [
        "f_val, p_val = stats.f_oneway(grouped_test2.get_group(\"Low\")[\"Volume\"], grouped_test2.get_group(\"Medium\")[\"Volume\"])  \n   \nprint( \"ANOVA results: F=\", round(f_val, 2), \", P =\", round(p_val, 2))   "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "297aa594-e600-4d96-aefa-aded745e7dbb",
      "metadata": {},
      "outputs": [],
      "source": [
        "#### Low and Upper Medium\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "d312fd62-69c7-48ed-92d9-e717931315e7",
      "metadata": {},
      "outputs": [],
      "source": [
        "f_val, p_val = stats.f_oneway(grouped_test2.get_group(\"Low\")[\"Volume\"], grouped_test2.get_group(\"Upper Medium\")[\"Volume\"])  \n \nprint(\"ANOVA results: F=\", round(f_val, 2), \", P =\", round(p_val, 2))   "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e46acea6-0b88-40d7-8ed8-09c93697bb59",
      "metadata": {},
      "outputs": [],
      "source": [
        "<h4>Low and High</h4>\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "2b391b52-785b-40fd-be8c-bf7bf6e62cbb",
      "metadata": {},
      "outputs": [],
      "source": [
        "f_val, p_val = stats.f_oneway(grouped_test2.get_group(\"Low\")[\"Volume\"], grouped_test2.get_group(\"High\")[\"Volume\"])  \n \nprint(\"ANOVA results: F=\", round(f_val, 2), \", P =\", p_val)   "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a2e5980-b0c9-4846-84db-680f35bb58b3",
      "metadata": {},
      "outputs": [],
      "source": [
        "#### Lower Medium and Medium\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "933c09e7-daff-4dfe-9051-589bcb27ee1a",
      "metadata": {},
      "outputs": [],
      "source": [
        "f_val, p_val = stats.f_oneway(grouped_test2.get_group(\"Lower Medium\")[\"Volume\"], grouped_test2.get_group(\"Medium\")[\"Volume\"])  \n \nprint(\"ANOVA results: F=\", round(f_val, 2), \", P =\", round(p_val, 2))   "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e10b798-3e56-48b2-a74b-4e696689ca3e",
      "metadata": {},
      "outputs": [],
      "source": [
        "#### Lower Medium and Upper Medium\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "ea3bec94-8451-4f3f-879b-fdb87ed716cf",
      "metadata": {},
      "outputs": [],
      "source": [
        "f_val, p_val = stats.f_oneway(grouped_test2.get_group(\"Lower Medium\")[\"Volume\"], grouped_test2.get_group(\"Upper Medium\")[\"Volume\"])  \n \nprint(\"ANOVA results: F=\", round(f_val, 2), \", P =\", p_val)   "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84c70285-800b-4d46-ad47-b799a1f6b5d9",
      "metadata": {},
      "outputs": [],
      "source": [
        "#### Lower Medium and High\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "746e53e3-377b-41d3-a657-68368acc7682",
      "metadata": {},
      "outputs": [],
      "source": [
        "f_val, p_val = stats.f_oneway(grouped_test2.get_group(\"Lower Medium\")[\"Volume\"], grouped_test2.get_group(\"High\")[\"Volume\"])  \n \nprint(\"ANOVA results: F=\", round(f_val, 2), \", P =\", round(p_val, 2))   "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "018b4362-eb74-4b43-8db9-3c9621297509",
      "metadata": {},
      "outputs": [],
      "source": [
        "#### Medium and Upper Medium\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "01936b6f-e697-47af-80b0-ce4d1d001af3",
      "metadata": {},
      "outputs": [],
      "source": [
        "f_val, p_val = stats.f_oneway(grouped_test2.get_group(\"Medium\")[\"Volume\"], grouped_test2.get_group(\"Upper Medium\")[\"Volume\"])  \n \nprint(\"ANOVA results: F=\", round(f_val, 2), \", P =\", round(p_val, 2))   "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d4f858a-c911-44c7-9047-76258d3e46a1",
      "metadata": {},
      "outputs": [],
      "source": [
        "#### Medium and High\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "30d75cdf-0cd0-4a6f-bb55-19bb63534000",
      "metadata": {},
      "outputs": [],
      "source": [
        "f_val, p_val = stats.f_oneway(grouped_test2.get_group(\"Medium\")[\"Volume\"], grouped_test2.get_group(\"High\")[\"Volume\"])  \n \nprint(\"ANOVA results: F=\", f_val, \", P =\", round(p_val, 2))   "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49017972-8c1d-4f54-8e5c-2f00ee2fe00d",
      "metadata": {},
      "outputs": [],
      "source": [
        "#### Upper Medium and High\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "79a928f3-67af-40cf-a6bd-f8b993203921",
      "metadata": {},
      "outputs": [],
      "source": [
        "f_val, p_val = stats.f_oneway(grouped_test2.get_group(\"Upper Medium\")[\"Volume\"], grouped_test2.get_group(\"High\")[\"Volume\"])  \n \nprint(\"ANOVA results: F=\", round(f_val, 2), \", P =\", round(p_val, 2))   "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "478212ba-45d9-4677-90bf-38551aed09b8",
      "metadata": {},
      "outputs": [],
      "source": [
        "## 7. Durbin-Watson Test"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4801115-a4fa-4f8d-94d8-b9305e816abf",
      "metadata": {},
      "outputs": [],
      "source": [
        "#### What is Durbin-Watson Test?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3fb2f240-87b7-438e-8629-f88fd981b712",
      "metadata": {},
      "outputs": [],
      "source": [
        "In regression analysis, Durbin-Watson (DW) is useful for checking the first-order autocorrelation (serial correlation). It analyzes the residuals for independence over time points (autocorrelation). The autocorrelation varies from -1 (negative autocorrelation) to 1 (positive autocorrelation).\n\nDurbin-Watson test analyzes the following hypotheses,\n\nNull hypothesis (H<sub>0</sub>): Residuals from the regression are not autocorrelated (autocorrelation coefficient, ρ = 0)\nAlternative hypothesis (H<sub>a</sub>): Residuals from the regression are autocorrelated (autocorrelation coefficient, ρ > 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e449d96-e208-40db-804d-335d4e0d701d",
      "metadata": {},
      "outputs": [],
      "source": [
        "We will use <b>durbin_watson</b> for Durbin-Watson Test and <b>OLS</b> to get residuals from \"statsmodels\" library"
      ]
    },
    {
      "cell_type": "code",
      "id": "63e80132-3488-4fef-a348-78934fc0b9d5",
      "metadata": {},
      "outputs": [],
      "source": [
        "X = df[\"Avg_price\"] # independent\ny = df[\"Volume\"] # dependent\n# to get intercept\nX = sm.add_constant(X)\n# fit the regression model\nreg = sm.OLS(y, X).fit()"
      ]
    },
    {
      "cell_type": "code",
      "id": "6aa7c6bf-4fe4-4ff1-a94f-448f8691ee58",
      "metadata": {},
      "outputs": [],
      "source": [
        "dwtest(resids=np.array(reg.resid))"
      ]
    },
    {
      "cell_type": "code",
      "id": "4724c20b-c186-4be3-844f-3873292dede9",
      "metadata": {},
      "outputs": [],
      "source": [
        "\ncurrs = [\"Volume\", \"BTC_price\", \"BNB_price\"]\nimport itertools\n\ncols = [curr for curr in currs]\nidxs = [curr for curr in currs]\n\ndw_df = pd.DataFrame(columns=cols, index=idxs)\n\nfor (curr1, curr2) in itertools.permutations(currs, 2):\n    X = df[{curr1}] # independent\n    y = df[{curr2}] # dependent\n    # to get intercept\n    X = sm.add_constant(X)\n    # fit the regression model\n    reg = sm.OLS(y, X).fit()\n    dw = dwtest(resids=np.array(reg.resid))\n    dw_df.loc[curr2 ,curr1] = dw\n    \nnp.fill_diagonal(dw_df.values, \"—\")\n    \ndw_df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a615b3b-4ad4-4605-a20b-f95a421a8a30",
      "metadata": {},
      "outputs": [],
      "source": [
        "Above we can see a matrix that consists of all the p-values. How to interpret these values? We take any value, its column will be responsible for the dependent value, and the row - for the independent value"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5fd26a40-86dc-4d4a-a937-f35b24c31b42",
      "metadata": {},
      "outputs": [],
      "source": [
        "## 8. Granger Causality Test"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ca5ca48-2c92-4993-8f05-4d6c9e24d34a",
      "metadata": {},
      "outputs": [],
      "source": [
        "#### What is Granger Causality Test?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c103e863-c269-4592-b033-7847bd0501b9",
      "metadata": {},
      "outputs": [],
      "source": [
        "Granger Causality test is a statistical test that is used to determine if a given time series and it’s lags is helpful in explaining the value of another series. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d0ddfc2-22f9-4ee0-bfd0-a73bfaa33030",
      "metadata": {},
      "outputs": [],
      "source": [
        "The Null hypothesis for grangercausalitytests is that the time series in\nthe second column, x<sub>2</sub>, does NOT Granger cause the time series in the first\ncolumn, x<sub>1</sub>. Grange causality means that past values of x<sub>2</sub> have a\nstatistically significant effect on the current value of x<sub>1</sub>, taking past\nvalues of x<sub>1</sub> into account as regressors. We reject the null hypothesis\nthat x<sub>2</sub> does not Granger cause x<sub>1</sub> if the p-values are below a desired size\nof the test."
      ]
    },
    {
      "cell_type": "code",
      "id": "c29260d3-a198-433c-a1b7-beaf517630e2",
      "metadata": {},
      "outputs": [],
      "source": [
        "df[df[\"Volume\"]>0.1][[\"Volume\", \"BTC_price\"]]"
      ]
    },
    {
      "cell_type": "code",
      "id": "e8cfd33a-ee8b-4cf8-a32b-4521f2963fe5",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_to_test = df[[\"Volume\", \"BTC_price\"]]\nx = df_to_test.index\ny1 = df_to_test[\"Volume\"]\ny2 = df_to_test[\"BTC_price\"]\n\n# Plot Line1 (Left Y Axis)\nfig, ax1 = plt.subplots(1,1,figsize=(16,9), dpi= 80)\nax1.plot(x, y1, color='tab:red')\n\n# Plot Line2 (Right Y Axis)\nax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\nax2.plot(x, y2, color='tab:blue')\n\n# Decorations\n# ax1 (left Y axis)\nax1.set_xlabel('Date', fontsize=20)\nax1.tick_params(axis='x', rotation=0, labelsize=12)\nax1.set_ylabel('VOLUME', color='tab:red', fontsize=20)\nax1.tick_params(axis='y', rotation=0, labelcolor='tab:red' )\nax1.grid(alpha=.4)\n\n# ax2 (right Y axis)\nax2.set_ylabel(\"BTC\", color='tab:blue', fontsize=20)\nax2.tick_params(axis='y', labelcolor='tab:blue')\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be0a726e-4aa3-447c-a926-c67da7ffc360",
      "metadata": {},
      "outputs": [],
      "source": [
        "We will use <b>granger causalitytests</b> for Granger Causality Test from \"statsmodels\" library"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca8faaca-ba53-4dc5-88f8-4be4300e1525",
      "metadata": {},
      "outputs": [],
      "source": [
        "Now let's define custom function which will do Granger Causality Test and return result as <b>pd.DataFrame</b>"
      ]
    },
    {
      "cell_type": "code",
      "id": "8364b70d-dcb4-4fb1-88ed-794412b74aa4",
      "metadata": {},
      "outputs": [],
      "source": [
        "def grangers_causation_matrix(data, maxlag, variables, test='ssr_chi2test', verbose=False):    \n    \"\"\"Check Granger Causality of all possible combinations of the Time series.\n    The rows are the response variable, columns are predictors. The values in the table \n    are the P-Values. P-Values lesser than the significance level (0.05), implies \n    the Null Hypothesis that the coefficients of the corresponding past values is \n    zero, that is, the X does not cause Y can be rejected.\n\n    data      : pandas dataframe containing the time series variables\n    variables : list containing names of the time series variables.\n    \"\"\"\n    df = pd.DataFrame(np.zeros((len(variables), len(variables))), columns=variables, index=variables)\n    for c in df.columns:\n        for r in df.index:\n            test_result = grangercausalitytests(data[[r, c]], maxlag=maxlag, verbose=False)\n            p_values = [round(test_result[i+1][0][test][1],4) for i in range(maxlag)]\n            if verbose: print(f'Y = {r}, X = {c}, P Values = {p_values}')\n            min_p_value = np.min(p_values)\n            df.loc[r, c] = min_p_value\n    df.columns = [var + '_x' for var in variables]\n    df.index = [var + '_y' for var in variables]\n    return df"
      ]
    },
    {
      "cell_type": "code",
      "id": "4fff8420-4f5e-477b-bb2a-27f320dab911",
      "metadata": {},
      "outputs": [],
      "source": [
        "grangers_causation_matrix(df_to_test, 1, variables=df_to_test.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "51da0e65-eaa1-4766-816e-3a6e258790ad",
      "metadata": {},
      "outputs": [],
      "source": [
        "How to interpret the p-values?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bad93f71-0012-4c42-b7b5-3b70dda47bd2",
      "metadata": {},
      "outputs": [],
      "source": [
        "Assuming a significance level of 0.05, if the p-value is lesser than 0.05, then we do NOT reject the null hypothesis that X does NOT granger cause Y.\n\nSo, in the above table, the p-value for Avg_price_x and BTC_price_y is 0.02. So we accept the null hypothesis and conclude that (Avg_price) does not granger causes (BTC_price).\n\nThat means, Avg_price will not be helpful in predicting the BTC_price."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e773207e-30b9-4713-a507-120e5245c154",
      "metadata": {},
      "outputs": [],
      "source": [
        "The p-value for Volume and BTC_price_x is 0. \n\nSince the p-value isn’t less than 0.05, we can’t reject the null hypothesis. That is, \"Avg_price_x\" isn’t predictive of \"BTC_price_y\"."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ecf1d1e3-2093-47b5-a6bb-12b92e0337f1",
      "metadata": {},
      "outputs": [],
      "source": [
        "Let's calculate Granger Causality Test for all available pairs"
      ]
    },
    {
      "cell_type": "code",
      "id": "fe7e339c-2ece-441e-98e0-5566d335f22f",
      "metadata": {},
      "outputs": [],
      "source": [
        "currs = [\"Volume\",\"BTC_price\",\"BNB_price\"]\ncols = [f\"{curr}_x\" for curr in currs]\nidxs = [f\"{curr}_y\" for curr in currs]\n\ngc_df = pd.DataFrame(columns=cols, index=idxs)\n\nfor (curr1, curr2) in itertools.combinations(currs, 2):\n    df_to_test_2 = df[[curr1,curr2]]\n    res_df = grangers_causation_matrix(df_to_test_2, 1, variables=df_to_test_2.columns)\n    p1 = res_df[f\"{curr1}_x\"][f\"{curr2}_y\"]\n    p2 = res_df[f\"{curr2}_x\"][f\"{curr1}_y\"]\n    gc_df.loc[f\"{curr1}_y\", f\"{curr2}_x\"] = p1\n    gc_df.loc[f\"{curr2}_y\", f\"{curr1}_x\"] = p2\n    \nnp.fill_diagonal(gc_df.values, \"—\")\n    \ngc_df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ba03b626-3b3d-443e-9224-3dbdd2382c39",
      "metadata": {},
      "outputs": [],
      "source": [
        "Above we can see a matrix that consists of all the p-values. How to interpret these values? We take any value, its column will be responsible for the dependent value (X), and the row - for the independent value (Y). If that value < 0.05 then that means X granger-causes Y"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "198b2382-91af-4562-a468-d2a51a357124",
      "metadata": {},
      "outputs": [],
      "source": [
        "<p>We now have a better idea of what our data looks like and which variables are more related to our main currency <b>MATIC</b></p>\n\nCorrelation between Matic Volume and currencies :\n\n<ul>\n    <li>BNB ~ 0.06</li>\n</ul>\n<ul>\n    <li>BNB ~ -0.20</li>\n</ul>\n\nBest correlation fields:\n\n<ul>\n    <li>Rec_count ~ 0.69</li>\n</ul>\n<ul>\n    <li>ATR ~ 0.55</li>\n</ul>\n\nLets create new dataset with other currencies and best fields\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "0ccbe0cf-a9c8-4b54-979c-cc5f5a119faa",
      "metadata": {},
      "outputs": [],
      "source": [
        "df[[\"Volume\",\"Rec_count\",\"BTC_price\", \"ATR\", \"BNB_price\"]].to_csv(\"DataSet_final.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5912ed92-8bc0-4aa2-baa8-cf0d49377de2",
      "metadata": {},
      "outputs": [],
      "source": [
        "# **Thank you for completing this lab!**\n\n## Author\n\n<a href=\"https://author.skills.network/instructors/ostap_liashenyk\" target=\"_blank\" >Ostap Liashenyk</a>\n\n<a href=\"https://author.skills.network/instructors/yaroslav_vyklyuk_2?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkGuidedProjectsIBMSkillsNetworkGPXX0QGDEN2306-2023-01-01\">Prof. Yaroslav Vyklyuk, DrSc, PhD</a>\n\n<a href=\"https://author.skills.network/instructors/mariya_fleychuk?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkGuidedProjectsIBMSkillsNetworkGPXX0QGDEN2306-2023-01-01\">Prof. Mariya Fleychuk, DrSc, PhD</a>\n\n\n\n\n## Change Log\n\n| Date (YYYY-MM-DD) | Version | Changed By      | Change Description                                         |\n| ----------------- | ------- | ----------------| ---------------------------------------------------------- |\n|     2023-04-01    |   1.0   | Ostap Liashenyk | Creation of the lab                                        |\n\n<hr>\n\n## <h3 align=\"center\"> © IBM Corporation 2023. All rights reserved. </h3>"
      ]
    },
    {
      "cell_type": "code",
      "id": "f7390a9b-0e01-4d73-9f14-8da21e6c8692",
      "metadata": {},
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": ""
    },
    "kernelspec": {
      "name": "",
      "display_name": ""
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}