{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "326bd1a0-74a3-4d45-b0a7-8215e2fb745a",
      "metadata": {},
      "outputs": [],
      "source": [
        "<center>\n    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"400\" alt=\"cognitiveclass.ai logo\"  />\n</center>\n\n# **??** \n\n\n## **Lab 1. ???**\n\nEstimated time needed: **15** minutes\n\n## **The tasks**\n\n\n\n## **Objectives**\n\nIn this project, we will learn how to analyze time series data using Python. We will use various libraries and methods to visualize the data, identify patterns and anomalies, and build a linear regression model. Time series analysis is a powerful tool for understanding and predicting trends in various fields, and Python provides a flexible and efficient platform for conducting this analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "581eb464-e629-4eb8-9460-a5fac78ab1b2",
      "metadata": {},
      "outputs": [],
      "source": [
        "## **Table of Contents**\n\n<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n    <ol>\n        <li>Loading the CSV File</li>\n        <li>Setting Indexes and Data Types</li>\n        <li>Sorting and Resampling the Data</li>\n        <li>Visualizing the Data</li>\n        <li>Dropping and Interpolating Data</li>\n        <li>Checking for Missing Data</li>\n        <li>Decomposing the Time Series</li>\n        <li>Interpreting Autocorrelation</li>\n        <li>Finding Correlations</li>\n        <li>Finding the Best Correlation</li>\n        <li>Building a Linear Regression Model</li>\n    </ol>\n</div>\n<hr>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10768593-94c9-4ff8-a141-dc61922595dd",
      "metadata": {},
      "outputs": [],
      "source": [
        "## **Dataset Structure**\n<details><summary>Click here for the structure</summary>\n\n* ### **NAME** -   \n* #### `'COLUMN'`: meaning of column\n* #### `'COLUMN'`: meaning of column\n* #### `'COLUMN'`: meaning of column\n* #### `'COLUMN'`: meaning of column\n* #### `'COLUMN'`: meaning of column\n* #### `'COLUMN'`: meaning of column\n\n```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1477fd20-6c93-43bc-8f24-6c19a930c289",
      "metadata": {},
      "outputs": [],
      "source": [
        "### Introduction\nIn this project, we will learn how to analyze time series data using Python. We will use various libraries and methods to visualize the data, identify patterns and anomalies, and build a linear regression model. Time series analysis is a powerful tool for understanding and predicting trends in various fields, and Python provides a flexible and efficient platform for conducting this analysis."
      ]
    },
    {
      "cell_type": "code",
      "id": "6e871162-3f24-4057-b575-231a5b47d0e4",
      "metadata": {},
      "outputs": [],
      "source": [
        "! conda install -c conda-forge ta -y\n! conda install scikit-learn -y"
      ]
    },
    {
      "cell_type": "code",
      "id": "c9ee7a0d-a557-4590-bb04-bfd45cd08ca2",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\nimport numpy as np\nimport seaborn as sns \n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n#set precision \npd.set_option(\"display.precision\", 2)\n#set precision for float\npd.options.display.float_format = '{:.2f}'.format"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a6050f87-3882-4d34-bd52-7d90547d2f17",
      "metadata": {},
      "outputs": [],
      "source": [
        "### Downloading and Loading the CSV File"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b3f2bb9-63df-450f-a45d-2068d7e3dc44",
      "metadata": {},
      "outputs": [],
      "source": [
        "Next, we will download dataset in CSV format and load it into a Pandas DataFrame. We will use the `read_csv()` function to load the data and the `head()` method to display the first few rows of the DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "id": "9a54454e-6a6e-4838-9532-486a61deeb81",
      "metadata": {},
      "outputs": [],
      "source": [
        "path = 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-GPXX0VZCEN/LuxuryLoanPortfolio.csv'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd07361d-0c66-44c0-b29b-cdd47aba0e47",
      "metadata": {},
      "outputs": [],
      "source": [
        "Load the csv:\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "fd957302-92ca-49a4-be8f-c569f7561800",
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv(path,low_memory=False)\ndf = df\ndf.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c2acbbeb-c09a-4375-99e3-5f2dd38734a7",
      "metadata": {},
      "outputs": [],
      "source": [
        "### Setting Indexes and Data Types"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00c50834-7e56-4117-9aa7-19fb7508a5ac",
      "metadata": {},
      "outputs": [],
      "source": [
        "To work with time series data, we need to set the index of the DataFrame to the time column. Use `df.set_index()`. Also we can to convert columns to needed type using `astype()`."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "279a6bf0-95cf-47bc-b167-0ed4ca74145a",
      "metadata": {},
      "outputs": [],
      "source": [
        "We create new Dataframe to get only needed column from our base DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "id": "8ca5431a-125e-473e-b122-8f281d50bf38",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_n = df[[\"funded_amount\",\"funded_date\"]]\ndf_n.set_index('funded_date',inplace = True)\ndf_n.head()"
      ]
    },
    {
      "cell_type": "code",
      "id": "aa99d8dc-473b-4db4-9604-a858378d6f51",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_n[\"funded_amount\"] = df_n[\"funded_amount\"].astype(float)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c7c696d-a61d-4b8e-b13b-4dd0bac17fd9",
      "metadata": {},
      "outputs": [],
      "source": [
        "### Sorting and Resampling the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d701636b-8212-495a-8b70-de737fb427dd",
      "metadata": {},
      "outputs": [],
      "source": [
        "We will sort the DataFrame by the index using `df.sort_index()` and resample the data to a needed frequency using the `resample` method. This will allow us to aggregate the data over a specific time period, such as daily, weekly, or monthly."
      ]
    },
    {
      "cell_type": "code",
      "id": "a6369e03-56e0-4b20-9dc3-3ae1f368a48e",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_n = df_n.sort_index()\ndf_n.head(50)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c1c9c49e-8ee5-4b68-be25-a265d64b8d8b",
      "metadata": {},
      "outputs": [],
      "source": [
        "Here is example of resampling to 1 Day frequency:"
      ]
    },
    {
      "cell_type": "code",
      "id": "e6d1d20b-dfaf-44a5-aca5-ba5cfcbfb46d",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_n.index = pd.to_datetime(df_n.index)\ndf_n = df_n.resample(\"1D\").sum()"
      ]
    },
    {
      "cell_type": "code",
      "id": "8c58792e-b982-42fb-af46-9702ca4adbe7",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_n.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a53a5f8b-f32e-48f7-95b8-55034571e9a7",
      "metadata": {},
      "outputs": [],
      "source": [
        "### Visualizing the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb79ecba-c1d4-4c00-b3c9-1cfb5f8b26be",
      "metadata": {},
      "outputs": [],
      "source": [
        "We will use \"Matplotlib\" to create line plots of the time series data. We will `plot` the our data as well as the resampled data."
      ]
    },
    {
      "cell_type": "code",
      "id": "aad52700-8761-430c-ab2b-6c6783944e83",
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\nimport matplotlib as mpl\n\ndf_n.plot()\nplt.xlabel(\"Date\")\nplt.ylabel(\"Amount\")\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09bf0651-7e19-4556-a2f6-b7bd7d5ae422",
      "metadata": {},
      "outputs": [],
      "source": [
        "We can see the anomaly value, so we have to delete it."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "41a6ee69-1a1e-452d-8623-d9dfbeb709a4",
      "metadata": {},
      "outputs": [],
      "source": [
        "### Dropping and Interpolating Data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2863f75-a8d0-45cd-9624-ffdff6f8143b",
      "metadata": {},
      "outputs": [],
      "source": [
        "Sometimes time series data may have missing values, which can affect our analysis. We will use the `interpolate()` method to fill in the missing values with estimated values based on the surrounding data points."
      ]
    },
    {
      "cell_type": "code",
      "id": "0669d618-eb0f-4722-bd8f-486990e58d6b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Find the index of the maximum value in the 'funded_amount' column\nmax_index = df_n['funded_amount'].idxmax()\n# Replace the maximum value with NaN\ndf_n.loc[max_index, 'funded_amount'] = np.nan\n# Interpolate the missing value using the linear method\ndf_n['funded_amount'].interpolate(method='linear', inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b45ba90-c01b-430f-a5f3-d62e6076e7c9",
      "metadata": {},
      "outputs": [],
      "source": [
        "Lets create new `plot` to see the result"
      ]
    },
    {
      "cell_type": "code",
      "id": "2a9aa32c-5762-4101-80f8-ad29d3e4a902",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_n.plot()\nplt.xlabel(\"Date\")\nplt.ylabel(\"Amount\")\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5309e740-111c-44bf-babd-6c868e49a104",
      "metadata": {},
      "outputs": [],
      "source": [
        "### Checking for Missing Data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "053aa26e-7985-4d29-a9dd-6e76370d7fff",
      "metadata": {},
      "outputs": [],
      "source": [
        "We will use the `df.isnull()` method to check for missing data in the DataFrame.Also we use `df.value_counts()` to see the count of data"
      ]
    },
    {
      "cell_type": "code",
      "id": "f363198d-697b-4097-a773-3c3e6e573ab8",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_n.isnull().value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c4882fe6-6088-4e1d-9ac1-ac71501a18e5",
      "metadata": {},
      "outputs": [],
      "source": [
        "`isnull` returns \"True\" if here is \"Null\" and \"False\" if its some data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "224ab48f-a568-4d84-867a-f9747566407c",
      "metadata": {},
      "outputs": [],
      "source": [
        "### Decomposing the Time Series"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be5a565b-8b7b-413d-b127-3ba9ecc93d5b",
      "metadata": {},
      "outputs": [],
      "source": [
        "We will use the `seasonal_decompose` function from the Statsmodels library to decompose the time series into its trend, seasonal, and residual components. This will allow us to analyze the individual components and identify any patterns or anomalies."
      ]
    },
    {
      "cell_type": "code",
      "id": "9e164978-bc4d-408a-ab2c-827096846941",
      "metadata": {},
      "outputs": [],
      "source": [
        "from statsmodels.tsa.seasonal import seasonal_decompose\n\ndecomposition = seasonal_decompose(df_n['funded_amount'], model='additive', period=8)\n\nplt.figure(figsize=(12, 8))\nplt.subplot(411)\nplt.plot(df_n['funded_amount'], label='Original')\nplt.legend(loc='upper left')\nplt.subplot(412)\nplt.plot(decomposition.trend, label='Trend')\nplt.legend(loc='upper left')\nplt.subplot(413)\nplt.plot(decomposition.seasonal, label='Seasonality')\nplt.legend(loc='upper left')\nplt.subplot(414)\nplt.plot(decomposition.resid, label='Residuals')\nplt.legend(loc='upper left')\nplt.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "745ae23b-765d-4f20-a2b1-f2471427f881",
      "metadata": {},
      "outputs": [],
      "source": [
        "<div class=\"alert alert-block alert-success\">\n    <b>❓Question:</b><br>\n        Use period 30 in decomposition.\n</div>"
      ]
    },
    {
      "cell_type": "code",
      "id": "e98add51-c940-457d-ad59-7092419ce8f8",
      "metadata": {},
      "outputs": [],
      "source": [
        "decomposition_q = seasonal_decompose(df_n['funded_amount'], model='additive', period=30)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "21aec103-b05b-4418-9dee-bdb3e5a01c06",
      "metadata": {},
      "outputs": [],
      "source": [
        "<details><summary>Click here to see the answer</summary>\n    decomposition_q = seasonal_decompose(df_n['funded_amount'], model='additive', period=30)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a412bd0a-4e3b-47ad-9200-99d2d84186b3",
      "metadata": {},
      "outputs": [],
      "source": [
        "<div class=\"alert alert-block alert-success\">\n    <b>❓Question:</b><br>\n        Build decomposition plot\n</div>"
      ]
    },
    {
      "cell_type": "code",
      "id": "84b3fbff-d1c8-46fb-9fa1-999b0a22af51",
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 8))\nplt.subplot(411)\nplt.plot(df_n['funded_amount'], label='Original')\nplt.legend(loc='upper left')\nplt.subplot(412)\nplt.plot(decomposition_q.trend, label='Trend')\nplt.legend(loc='upper left')\nplt.subplot(413)\nplt.plot(decomposition_q.seasonal, label='Seasonality')\nplt.legend(loc='upper left')\nplt.subplot(414)\nplt.plot(decomposition_q.resid, label='Residuals')\nplt.legend(loc='upper left')\nplt.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01a8d7b1-f76c-4c68-beb1-6bbcb7c3029b",
      "metadata": {},
      "outputs": [],
      "source": [
        "<details><summary>Click here to see the answer</summary>\nplt.figure(figsize=(12, 8))<br>\nplt.subplot(411) <br>\nplt.plot(df_n['funded_amount'], label='Original') <br>\nplt.legend(loc='upper left')<br>\nplt.subplot(412)<br>\nplt.plot(decomposition_q.trend, label='Trend')<br>\nplt.legend(loc='upper left')<br>\nplt.subplot(413)<br>\nplt.plot(decomposition_q.seasonal, label='Seasonality')<br>\nplt.legend(loc='upper left')<br>\nplt.subplot(414)<br>\nplt.plot(decomposition_q.resid, label='Residuals')<br>\nplt.legend(loc='upper left')<br>\nplt.tight_layout()<br>\nplt.show()"
      ]
    },
    {
      "cell_type": "code",
      "id": "39bc6e2a-15c8-4ec2-9117-19b588e70688",
      "metadata": {},
      "outputs": [],
      "source": [
        "df2 = pd.DataFrame()\ndf2['residual'] = decomposition.resid\ndf2 = df2.dropna()\ndf2.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f845318b-ad20-41ca-ae92-19292ab50b6e",
      "metadata": {},
      "outputs": [],
      "source": [
        "<div class=\"alert alert-block alert-success\">\n<b>❓Question:</b><br>\n    Use residual column from your decomposition to create new Data Frame\n</div>"
      ]
    },
    {
      "cell_type": "code",
      "id": "22937625-98bd-4c4c-ac90-e75b98d1037a",
      "metadata": {},
      "outputs": [],
      "source": [
        "df2_q = pd.DataFrame()\ndf2_q['residual'] = decomposition_q.resid\ndf2_q = df2_q.dropna()\ndf2_q.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27f02304-2140-46f2-8556-b0ee8d2c3934",
      "metadata": {},
      "outputs": [],
      "source": [
        "<details><summary>Click here to see the answer</summary>\ndf2_q = pd.DataFrame()<br>\ndf2_q['residual'] = decomposition_q.resid<br>\ndf2_q = df2_q.dropna()<br>\ndf2_q.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da988d78-aa51-4a16-9087-086eb56adf78",
      "metadata": {},
      "outputs": [],
      "source": [
        "### Interpreting Autocorrelation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1cc73da3-a956-4119-873c-3057f3bbc121",
      "metadata": {},
      "outputs": [],
      "source": [
        "We will use the `plot_acf` function from the Statsmodels library to visualize the autocorrelation in the time series data. This function plots the autocorrelation function (ACF) for a given time series and lag range. We will use the `lags` parameter to specify the maximum number of lags to include in the plot."
      ]
    },
    {
      "cell_type": "code",
      "id": "51117fb7-b348-4b56-81f0-da1de0284e57",
      "metadata": {},
      "outputs": [],
      "source": [
        "import statsmodels.api as sm\nsm.graphics.tsa.plot_acf(df2.values.squeeze(), lags=50)\nplt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b766bb6-9bd6-419d-a686-08d266c7dcd5",
      "metadata": {},
      "outputs": [],
      "source": [
        "<div class=\"alert alert-block alert-success\">\n<b>❓Question:</b><br>\n    Build autocorrelation plot (plot_acf) using your dataframe. (Build only 10 lags)\n</div>"
      ]
    },
    {
      "cell_type": "code",
      "id": "5e8b5378-5c07-43e0-b070-acd96f292055",
      "metadata": {},
      "outputs": [],
      "source": [
        "sm.graphics.tsa.plot_acf(df2_q.values.squeeze(), lags=50)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be6b863c-6a84-499d-97de-1eaeb072f4f3",
      "metadata": {},
      "outputs": [],
      "source": [
        "<details><summary>Click here to see the answer</summary>\n    sm.graphics.tsa.plot_acf(df2_q.values.squeeze(), lags=50)<br>\n    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d93619c4-6ff3-42a9-b2a0-55abb98ea8f8",
      "metadata": {},
      "outputs": [],
      "source": [
        "### Finding Correlations"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83933355-35aa-4c35-ad5c-6aa8ad2ea127",
      "metadata": {},
      "outputs": [],
      "source": [
        "We will use the `corr` method to calculate the correlation coefficients between the time series data and its shifted versions. This will allow us to identify any lagged relationships between the variables."
      ]
    },
    {
      "cell_type": "code",
      "id": "4d193e28-8d97-48ff-81f5-2e63349dec35",
      "metadata": {},
      "outputs": [],
      "source": [
        "for shift in range(1, 20):\n    df2[f'shift_{shift}'] = df2['residual'].shift(shift)\ncorrelations = df2.corr()    \ncorrelations"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "38b4bdfe-32f1-4715-8b6d-e1e62d6a001a",
      "metadata": {},
      "outputs": [],
      "source": [
        "### Finding the Best Correlation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b386f6b4-4550-4db0-8ba0-c3e20ed3ba1d",
      "metadata": {},
      "outputs": [],
      "source": [
        "We will use the `abs` method to calculate the absolute correlation coefficients and find the maximum value. We will also preserve the sign of the correlation coefficients to identify any negative relationships."
      ]
    },
    {
      "cell_type": "code",
      "id": "4b8d7b38-5305-43df-9de2-b9b4a950612e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate the absolute correlation between the original 'funded_amount' and its shifted versions\nabs_correlations = df2.corrwith(df2['residual']).abs()\n\n# Find the top 3 best absolute correlations (preserving the sign)\ntop_abs_correlations = abs_correlations.drop('residual').nlargest(3)\n\n# Get the sign of the top 3 best correlations\nsigns = df2.corrwith(df2['residual']).drop('residual').loc[top_abs_correlations.index].apply(np.sign)\n\n# Multiply the top 3 best correlations by their respective signs\ntop_abs_correlations *= signs\ntop_abs_correlations"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d59aaef-c3e4-4535-b67d-b9566f87d040",
      "metadata": {},
      "outputs": [],
      "source": [
        "<div class=\"alert alert-block alert-success\">\n<b>❓Question:</b><br>\n    Take any 3 shifts from your Dataframe \n</div>"
      ]
    },
    {
      "cell_type": "code",
      "id": "a90cb473-f96c-4676-84d6-f7a8dfaefc17",
      "metadata": {},
      "outputs": [],
      "source": [
        "shifts = pd.DataFrame()\n\nshifts['shift_1'] = df2_q['residual'].shift(1)\nshifts['shift_2'] = df2_q['residual'].shift(2)\nshifts['shift_3'] = df2_q['residual'].shift(3)\n\nshifts = shifts.dropna()\nshifts"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "07952050-a9fd-448b-8f28-d65fdcc20bae",
      "metadata": {},
      "outputs": [],
      "source": [
        "<details><summary>Click here to see the answer</summary>\n    shifts = pd.DataFrame() \n\n    shifts['shift_1'] = df2_q['residual'].shift(1) \n    shifts['shift_2'] = df2_q['residual'].shift(2)\n    shifts['shift_3'] = df2_q['residual'].shift(3)\n\n    shifts = shifts.dropna()\n    shifts"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2c4c7a3-3351-472a-bc3c-fdfb0bcafd01",
      "metadata": {},
      "outputs": [],
      "source": [
        "### Building a Linear Regression Model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "345a5c6d-1078-459c-928f-679df2758119",
      "metadata": {},
      "outputs": [],
      "source": [
        "We will use the `LinearRegression` class from the Scikit-learn library to build a linear regression model using the best correlated shifts as features. We will split the data into training and testing sets, fit the model, and evaluate its performance using the mean squared error and R-squared score."
      ]
    },
    {
      "cell_type": "code",
      "id": "e109acec-5efb-4ac9-8090-3158f6b89f3f",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, r2_score\n\n# Create a new DataFrame with the top 3 best correlated shifts as features\ndf3 = df2[top_abs_correlations.index].dropna()\n\n# Set the target variable as the 'residual' column\ntarget = df2.loc[df3.index, 'residual']\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(df3, target, test_size=0.2, shuffle = False)\n\n# Create and fit the linear regression model\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\n\n# Make predictions on the test set\ny_pred_test = model.predict(X_test)\ny_pred_train = model.predict(X_train)\n\n# Calculate the mean squared error and R-squared score\nmse = mean_squared_error(y_test, y_pred_test)\nr2 = r2_score(y_test, y_pred_test)\n\nprint(\"Mean Squared Error:\", mse)\nprint(\"R-squared Score:\", r2)"
      ]
    },
    {
      "cell_type": "code",
      "id": "e6019d9a-327c-4762-9ca1-037fc2995aca",
      "metadata": {},
      "outputs": [],
      "source": [
        "y_test = pd.DataFrame(y_test)\ny_train = pd.DataFrame(y_train)\ny_test[\"pred\"] = y_pred_test\ny_train[\"pred\"] = y_pred_train"
      ]
    },
    {
      "cell_type": "code",
      "id": "08ba837f-bff2-4a76-b1dd-abc52ede5db8",
      "metadata": {},
      "outputs": [],
      "source": [
        "width = 12\nheight = 10\nplt.figure(figsize=(width, height))\n\nplt.plot(y_test, label='validation data')\nplt.plot(y_train,  label='training Data')\nplt.xlabel('Time')\nplt.ylabel('')\nplt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0542123b-a64d-4d47-8eca-fd3d5b949319",
      "metadata": {},
      "outputs": [],
      "source": [
        "<a href=\"https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/share-notebooks.html/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDA0101ENSkillsNetwork20235326-2021-01-01\"> CLICK HERE</a> to see how to share your notebook\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "997ada06-9498-4162-b03e-49c2cb5b91e6",
      "metadata": {},
      "outputs": [],
      "source": [
        "# **Thank you for completing this lab!**\n\n## Author\n\n<a href=\"https://author.skills.network/instructors/ostap_liashenyk\" target=\"_blank\" >Ostap Liashenyk</a>\n\n<a href=\"https://author.skills.network/instructors/yaroslav_vyklyuk_2?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkGuidedProjectsIBMSkillsNetworkGPXX0QGDEN2306-2023-01-01\">Prof. Yaroslav Vyklyuk, DrSc, PhD</a>\n\n<a href=\"https://author.skills.network/instructors/mariya_fleychuk?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkGuidedProjectsIBMSkillsNetworkGPXX0QGDEN2306-2023-01-01\">Prof. Mariya Fleychuk, DrSc, PhD</a>\n\n## Change Log\n\n| Date (YYYY-MM-DD) | Version | Changed By      | Change Description                                         |\n| ----------------- | ------- | ----------------| ---------------------------------------------------------- |\n|     2023-04-01    |   1.0   | Ostap Liashenyk | Creation of the lab                                        |\n\n<hr>\n\n## <h3 align=\"center\"> © IBM Corporation 2023. All rights reserved. </h3>\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "11a488f7-16f2-4e37-970a-1d9d5e3827e1",
      "metadata": {},
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": ""
    },
    "kernelspec": {
      "name": "",
      "display_name": ""
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}