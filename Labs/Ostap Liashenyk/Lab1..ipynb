{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d499dd43-c698-4a2e-9701-7a01f1add51e",
      "metadata": {},
      "outputs": [],
      "source": [
        "<center>\n    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"400\" alt=\"cognitiveclass.ai logo\"  />\n</center>\n\n# Investigation of cryptocurrency exchange rate dynamic (Matic/USD), сalculation and analysis of technical financial indicators, characterizing the cryptocurrency market (ATR, OBV, RSI, AD)\n\nEstimated time needed: **30** minutes\n\nThe tasks:\n* Download and process statistical time series of cryptocurrency pair Matic/USD, describing the dynamics of the cryptocurrency market;\n* Upload statistical data from the Pandas library;\n* Calculate and analyze technical financial indicators for cryptocurrecny indicators analysis (ATR, OBV, ADV, RSI, AD)\n\n\n## Objectives\n\nAfter completing this lab you will be able to:\n\n*  Acquire data in various ways;\n*  Obtain insights from data with Pandas library;\n*  Calculating technical financial indicators.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f85375a-caf7-4aa7-a9f1-86a6d5172e72",
      "metadata": {},
      "outputs": [],
      "source": [
        "<h2>Table of Contents</h2>\n\n<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n<ol>\n    <li><a href=\"https://#data_acquisition\">Data Acquisition</a>\n    <li><a href=\"https://#basic_insight\">Basic Insight of Dataset</a></li>\n    <li><a href=\"https://#indicators\">Calculating technical financial (cryptocurrency) indicators</a> <ul> <li>ATR <li>OBV <li>ADV <li>RSI <li>AD </ul>\n</ol>\n\n</div>\n<hr>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e06ca275-8ee8-46a5-adf5-3d76c8210f12",
      "metadata": {},
      "outputs": [],
      "source": [
        "<h1 id=\"data_acquisition\">Data Acquisition</h1>\n<p>\nThere are various formats for a dataset: .csv, .json, .xlsx  etc. The dataset can be stored in different places, on your local machine or sometimes online.<br>\n\nIn this section, you will learn how to load a dataset into our Jupyter Notebook.<br>\n\nIn our case, the Cryptocurrency Dataset is an online source, and it is in a CSV (comma separated value) format. Let's use this dataset as an example to practice data reading.\n\n<ul>\n    <li>Data source: <a href=\"https://1824251045.rsc.cdn77.org/web/algohouse/data/BTCBUSD_trades_1m.csv\" target=\"_blank\">https://1824251045.rsc.cdn77.org/web/algohouse/data/BTCBUSD_trades_1m.csv</a>\n    <a href=\"https://1824251045.rsc.cdn77.org/web/algohouse/data/MATICBUSD_trades_1m.csv\" target=\"_blank\">https://1824251045.rsc.cdn77.org/web/algohouse/data/MATICBUSD_trades_1m.csv</a>\n    <a href=\"https://1824251045.rsc.cdn77.org/web/algohouse/data/BNBBUSD_trades_1m.csv\" target=\"_blank\">https://1824251045.rsc.cdn77.org/web/algohouse/data/BNBBUSD_trades_1m.csv</a></li>\n    <li>Data type: csv</li>\n</ul>\nThe Pandas Library is a useful tool that enables us to read various datasets into a dataframe; our Jupyter notebook platforms have a built-in <b>Pandas Library</b> so that all we need to do is import Pandas without installing.\n</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "dba15dea-7213-4095-9f5e-128aada9ecbd",
      "metadata": {},
      "outputs": [],
      "source": [
        "#install specific version of libraries used in  lab\n#! mamba install pandas -y\n#! mamba install numpy -y"
      ]
    },
    {
      "cell_type": "code",
      "id": "ed7827a6-890e-4ada-8bbe-1668f8e40a58",
      "metadata": {},
      "outputs": [],
      "source": [
        "# import pandas library\nimport pandas as pd\nimport numpy as np\npd.set_option(\"display.precision\", 2)\npd.options.display.float_format = '{:.2f}'.format"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "abf15d51-d6ca-4597-af8b-9ffabf56ecdb",
      "metadata": {},
      "outputs": [],
      "source": [
        "<h2>Read Data</h2>\n<p>\nWe use <code>pandas.read_csv()</code> function to read the csv file. In the brackets, we put the file path along with a quotation mark so that pandas will read the file into a dataframe from that address. The file path can be either an URL or your local file address.<br>\n\nBecause the data does not include headers, we can add an argument <code>headers = None</code> inside the <code>read_csv()</code> method so that pandas will not automatically set the first row as a header.<br>\n\nYou can also assign the dataset to any variable you create.\n\n</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e4a830b-b0f1-4b74-a754-958afb65682b",
      "metadata": {},
      "outputs": [],
      "source": [
        "This dataset was hosted on IBM Cloud object. Click <a href=\"https://cocl.us/DA101EN_object_storage?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDA0101ENSkillsNetwork20235326-2021-01-01\">HERE</a> for free storage.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "426cfa73-9dce-4128-bb85-dc17fca654a3",
      "metadata": {},
      "outputs": [],
      "source": [
        "In this lab, we will be using three different datasets to create one that we will use in future labs. We will load three datasets and add the 'avg_price' columns from two of them to our main one.\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "47686716-7254-4a3c-bda8-9f07287965de",
      "metadata": {},
      "outputs": [],
      "source": [
        "path = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-GPXX0XHOEN/MATICBUSD_trades_1m.csv\"\ndf = pd.read_csv(path,low_memory=False, index_col=0)\n\n# Download additional datasets with \"price\" columns\nbtc_url = 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-GPXX0XHOEN/BTCBUSD_trades_1m.csv'\nbtc_df = pd.read_csv(btc_url,low_memory=False, index_col=0)\n\n\nbnb_url = 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-GPXX0XHOEN/BNBBUSD_trades_1m%20(4).csv'\nbnb_df = pd.read_csv(bnb_url,low_memory=False, index_col=0)\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c6bd6e2-9b61-4130-b922-1ffa0e71adaf",
      "metadata": {},
      "outputs": [],
      "source": [
        "After reading the dataset, we can use the <code>dataframe.head(n)</code> method to check the top n rows of the dataframe, where n is an integer. Contrary to <code>dataframe.head(n)</code>, <code>dataframe.tail(n)</code> will show you the bottom n rows of the dataframe.\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "b59adaf9-8945-45b5-8898-489af4ae900b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# show the first 5 rows using dataframe.head() method\nprint(\"The first 5 rows of the dataframe\") \ndf.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ba977ced-0a13-4de5-bd5a-c00a5300c149",
      "metadata": {},
      "outputs": [],
      "source": [
        "We have to rename the columns \"avg_price\" so that they don't repeat in the main dataset using dataframe.rename()"
      ]
    },
    {
      "cell_type": "code",
      "id": "708657ff-dc80-4669-ac75-013c5ebd2e22",
      "metadata": {},
      "outputs": [],
      "source": [
        "btc_df = btc_df.rename(columns = {\"avg_price\" : \"BTC_price\"})\nbtc_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "id": "50703464-7a47-40cb-8543-78044c90e0c7",
      "metadata": {},
      "outputs": [],
      "source": [
        "bnb_df = bnb_df.rename(columns = {\"avg_price\" : \"BNB_price\"})\nbnb_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5983a1d-29c3-4c2f-a92b-48c905c59663",
      "metadata": {},
      "outputs": [],
      "source": [
        "Now we add \"avg_price\" from BTC and BNB datasets to our main one. We can use pandas.concat()"
      ]
    },
    {
      "cell_type": "code",
      "id": "b5c8b32a-9ea1-4b1e-abb3-95de0923d72a",
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.concat([df, btc_df[\"BTC_price\"],bnb_df[\"BNB_price\"]], axis =1)\ndf.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0db6dbc2-7809-400b-9857-2b91f413cc42",
      "metadata": {},
      "outputs": [],
      "source": [
        "<div class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\">\n<h1> Question #1: </h1>\n<b>Check the bottom 10 rows of data frame \"df\".</b>\n</div>\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "0c2baac0-8e83-4ded-9261-2fd1e728ff48",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Write your code below and press Shift+Enter to execute \nprint(\"The last 10 rows of the dataframe\\n\")\ndf.tail(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1c7ca62-7612-4912-84cc-6c0bf3b6b1a2",
      "metadata": {},
      "outputs": [],
      "source": [
        "Here we can see a lot of NaN values, which appear due to different dimensions of the datasets."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5354b377-03d8-421f-88c9-c216fe9814e0",
      "metadata": {},
      "outputs": [],
      "source": [
        "<details><summary>Click here for the solution</summary>\n\n```python\nprint(\"The last 10 rows of the dataframe\\n\")\ndf.tail(10)\n```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2313a065-13ac-4b92-8921-bb56a852b592",
      "metadata": {},
      "outputs": [],
      "source": [
        "<h3>Add Headers</h3>\n<p>\nTake a look at our dataset. Pandas automatically set the header with an integer starting from 0.\n</p>\n\n<p>\nThus, we have to add headers manually.\n</p>\n<p>\nFirst, we create a list \"headers\" that include all column names in order.\nThen, we use <code>dataframe.columns = headers</code> to replace the headers with the list we created.\n</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "1643f037-194d-44ed-8f6e-7477640a3acb",
      "metadata": {},
      "outputs": [],
      "source": [
        "# create headers list\nheaders = [\"Ts\",\"Open\",\"High\",\"Low\",\"Close\",\"Volume\",\"Rec_count\",\"Avg_price\",\"BTC_price\",\"BNB_price\"]\nprint(\"headers\\n\", headers)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e514ced2-1b40-4436-be31-cbed20317bd3",
      "metadata": {},
      "outputs": [],
      "source": [
        "We replace headers and recheck our dataframe:\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "4d6505e0-29ec-4e71-bfdd-69c89f8b8468",
      "metadata": {},
      "outputs": [],
      "source": [
        "df.columns = headers\ndf.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aca0c872-e2c9-4316-95f3-5710a853d814",
      "metadata": {},
      "outputs": [],
      "source": [
        "We can remove the missing values using dropna() \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9e7e817-61aa-4f0f-bbfb-fcfa8198d41b",
      "metadata": {},
      "outputs": [],
      "source": [
        "We can drop missing values along the column \"open\" as follows:\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "3688ab65-1abd-4d3a-bcab-015603afe29c",
      "metadata": {},
      "outputs": [],
      "source": [
        "df=df.dropna(subset=[\"Open\"], axis=0)\ndf.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1aba18c1-8824-4f78-9b78-2b0c4407b91d",
      "metadata": {},
      "outputs": [],
      "source": [
        "Now, we have successfully read the raw dataset and added the correct headers into the dataframe.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d1bc656-9a0d-4dce-bd8a-0ef3e78a3909",
      "metadata": {},
      "outputs": [],
      "source": [
        " <div class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\">\n<h1> Question #2: </h1>\n<b>Find the name of the columns of the dataframe.</b>\n</div>\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "77f226e4-3461-474f-8411-14980895ca83",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Write your code below and press Shift+Enter to execute \nprint(df.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2721829-77f8-4697-a677-728a83d14ba2",
      "metadata": {},
      "outputs": [],
      "source": [
        "<details><summary>Click here for the solution</summary>\n\n```python\nprint(df.columns)\n```\n\n</details>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df4d1bd1-664c-4c62-bfd4-d10306946228",
      "metadata": {},
      "outputs": [],
      "source": [
        "<h2>Save Dataset</h2>\n<p>\nCorrespondingly, Pandas enables us to save the dataset to csv. By using the <code>dataframe.to_csv()</code> method, you can add the file path and name along with quotation marks in the brackets.\n</p>\n<p>\nFor example, if you would save the dataframe <b>df</b> as <b>bnb.csv</b> to your local machine, you may use the syntax below, where <code>index = False</code> means the row names will not be written.\n</p>\n"
      ]
    },
    {
      "cell_type": "raw",
      "id": "c3ef7959-b930-49a2-9dd7-6c84ce994759",
      "metadata": {},
      "outputs": [],
      "source": [
        "df.to_csv(\"bnb.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7607bfba-b965-4e64-896e-89d41123027c",
      "metadata": {},
      "outputs": [],
      "source": [
        "We can also read and save other file formats. We can use similar functions like **`pd.read_csv()`** and **`df.to_csv()`** for other data formats. The functions are listed in the following table:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "477e5d5d-d429-4138-97a9-93f9ad755326",
      "metadata": {},
      "outputs": [],
      "source": [
        "<h2>Read/Save Other Data Formats</h2>\n\n| Data Formate |        Read       |            Save |\n| ------------ | :---------------: | --------------: |\n| csv          |  `pd.read_csv()`  |   `df.to_csv()` |\n| json         |  `pd.read_json()` |  `df.to_json()` |\n| excel        | `pd.read_excel()` | `df.to_excel()` |\n| hdf          |  `pd.read_hdf()`  |   `df.to_hdf()` |\n| sql          |  `pd.read_sql()`  |   `df.to_sql()` |\n| ...          |        ...        |             ... |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a4edb80-9455-42e1-af42-6fa2f53d1830",
      "metadata": {},
      "outputs": [],
      "source": [
        "<h1 id=\"basic_insight\">Basic Insight of Dataset</h1>\n<p>\nAfter reading data into Pandas dataframe, it is time for us to explore the dataset.<br>\n\nThere are several ways to obtain essential insights of the data to help us better understand our dataset.\n\n</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a706b62b-f096-4625-907b-185ddd7de8be",
      "metadata": {},
      "outputs": [],
      "source": [
        "<h2>Data Types</h2>\n<p>\nData has a variety of types.<br>\n\nThe main types stored in Pandas dataframes are <b>object</b>, <b>float</b>, <b>int</b>, <b>bool</b> and <b>datetime64</b>. In order to better learn about each attribute, it is always good for us to know the data type of each column. In Pandas:\n\n</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "7b73464b-ec3e-4292-8544-dfc87c5d6620",
      "metadata": {},
      "outputs": [],
      "source": [
        "# check the data type of data frame \"df\" by .dtypes\ndf.dtypes\n#If it doesnt work use, you can use  \"print()\" function\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "345dd043-6bc0-4b01-8046-1fb22f824a90",
      "metadata": {},
      "outputs": [],
      "source": [
        "A series with the data type of each column is returned.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b4c4df3-d984-4ab5-bfd0-c1cfcd79d068",
      "metadata": {},
      "outputs": [],
      "source": [
        "<p>\nAs shown above, it is clear to see that the data type of \"open\" and \"high\" is <code>float64</code>, \"ts\" is object <code>object</code>, etc.\n</p>\n<p>\nThese data types can be changed; we will learn how to accomplish this in a later module.\n</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f65fa17-645c-417a-85de-c64a0b524da0",
      "metadata": {},
      "outputs": [],
      "source": [
        "<h2>Describe</h2>\nIf we would like to get a statistical summary of each column e.g. count, column mean value, column standard deviation, etc., we use the describe method:\n"
      ]
    },
    {
      "cell_type": "raw",
      "id": "0ea5d47b-0748-4b09-bad5-1aa70f1b1d8d",
      "metadata": {},
      "outputs": [],
      "source": [
        "dataframe.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d00c7d08-ceff-4fee-bc51-a1c785350d1e",
      "metadata": {},
      "outputs": [],
      "source": [
        "This method will provide various summary statistics, excluding <code>NaN</code> (Not a Number) values.\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "46d9a5cb-82b2-41d3-960e-32585bb18d86",
      "metadata": {},
      "outputs": [],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a7fecb7-fef4-491a-a2f1-582a087e24cc",
      "metadata": {},
      "outputs": [],
      "source": [
        "<p>\nThis shows the statistical summary of all numeric-typed (int, float) columns.<br>\n\nFor example, the attribute \"id\" has 67212 counts, the mean value of this column is 33605.5, the standard deviation is 19402.6, the minimum value is 0, 25th percentile is 16802, 50th percentile is 33605, 75th percentile is 50408, and the maximum value is 67211. <br>\n\nHowever, what if we would also like to check all the columns including those that are of type object? <br><br>\n\nYou can add an argument <code>include = \"all\"</code> inside the bracket. Let's try it again.\n\n</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "eb7f0f7e-5c61-46ec-a051-1e73ff2639f5",
      "metadata": {},
      "outputs": [],
      "source": [
        "# describe all the columns in \"df\" \ndf.describe(include = \"all\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85246da3-6534-4919-8d33-6a52af66f150",
      "metadata": {},
      "outputs": [],
      "source": [
        "<p>\nNow it provides the statistical summary of all the columns, including object-typed attributes.<br>\n\nWe can now see how many unique values there, which one is the top value and the frequency of top value in the object-typed columns.<br>\n\nSome values in the table above show as \"NaN\". This is because those numbers are not available regarding a particular column type.<br>\n\n</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27cf1113-f23c-4535-9f26-95f306ae2d59",
      "metadata": {},
      "outputs": [],
      "source": [
        "<div class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\">\n<h1> Question #3: </h1>\n\n<p>\nYou can select the columns of a dataframe by indicating the name of each column. For example, you can select the three columns as follows:\n</p>\n<p>\n    <code>dataframe[[' column 1 ',column 2', 'column 3']]</code>\n</p>\n<p>\nWhere \"column\" is the name of the column, you can apply the method  \".describe()\" to get the statistics of those columns as follows:\n</p>\n<p>\n    <code>dataframe[[' column 1 ',column 2', 'column 3'] ].describe()</code>\n</p>\n\nApply the  method to \".describe()\" to the columns 'length' and 'compression-ratio'.\n\n</div>\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "c8525a28-f30a-44f2-ab35-03be7dc11844",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Write your code below and press Shift+Enter to execute \ndf[['Ts', 'Volume']].describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2d0796b-431a-47ae-8eb7-4b708b981732",
      "metadata": {},
      "outputs": [],
      "source": [
        "<details><summary>Click here for the solution</summary>\n\n```python\ndf[['ts', 'volume']].describe()\n```\n\n</details>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "58a1e3b9-595d-457b-ac86-10dd423cda24",
      "metadata": {},
      "outputs": [],
      "source": [
        "<h2>Info</h2>\nAnother method you can use to check your dataset is:\n"
      ]
    },
    {
      "cell_type": "raw",
      "id": "dc0e380c-e6ec-40a0-a6ea-aab0980c5195",
      "metadata": {},
      "outputs": [],
      "source": [
        "dataframe.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f89a89d2-46f7-406b-94a6-3231aa086af2",
      "metadata": {},
      "outputs": [],
      "source": [
        "It provides a concise summary of your DataFrame.\n\nThis method prints information about a DataFrame including the index dtype and columns, non-null values and memory usage.\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "3d01a4d0-a44a-41a1-8373-b267eee785ac",
      "metadata": {},
      "outputs": [],
      "source": [
        "# look at the info of \"df\"\ndf.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39c4fc7d-f3da-4690-aabb-facbb14024e8",
      "metadata": {},
      "outputs": [],
      "source": [
        "<h2>Calculating indicators: ATR, OBV, ADV, RSI, AD indicators calculating</h1>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c8cd1916-8187-41a1-ba01-3a4148adcb63",
      "metadata": {},
      "outputs": [],
      "source": [
        "<h3>ATR: Avarage true range</h3>\n<h4>What Is the Average True Range (ATR)?</h4>\nThe average true range (ATR) is a technical analysis indicator introduced by market technician J. Welles Wilder Jr. in his book New Concepts in Technical Trading Systems that measures market volatility by decomposing the entire range of an asset price for that period\n\n1. Calculate $True\\ Range\\ (TR)$:\n$$\nTR = \\textrm{max}[ \\ ( \\ High\\ - Low\\ ),\\ | \\ High\\ - Close_p \\ |,\\ |\\ Low\\ - Close_p \\ | \\ ],\n$$\n<center>where $p$ — previous<center>\n\n2. Calculate $ATR$:\n$$\nATR = \\frac{1}{n} \\sum \\limits _{i=1} ^{n} TR_i,\n$$ \n"
      ]
    },
    {
      "cell_type": "code",
      "id": "0b9dd197-1814-48b7-acab-f17cb73d9833",
      "metadata": {},
      "outputs": [],
      "source": [
        "\ndef atr(df, n):\n    # Create a new DataFrame to hold the True Range (TR) values\n    tr = pd.DataFrame()\n\n    # Calculate the three components of the True Range for each period\n    tr['h-l'] = df['High'] - df['Low']  # High - Low\n    tr['h-pc'] = abs(df['High'] - df['Close'].shift())  # absolute value (High - Previous Close)\n    tr['l-pc'] = abs(df['Low'] - df['Close'].shift())  # absolute value (Low - Previous Close)\n    # Take the maximum of the three components for each period to get the True Range (TR)\n    tr['max'] = tr.max(axis=1)\n    # Calculate the rolling mean of the True Range (TR) over n periods to get the Average True Range (ATR)\n    atr = tr['max'].rolling(n).mean()\n    # Return the Average True Range (ATR) as a pandas Series\n    return atr\ndf[\"ATR\"] = atr(df, 14)\ndf.tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b68c63b-8571-4847-b720-6cd3cf65d825",
      "metadata": {},
      "outputs": [],
      "source": [
        "<h3>OBV: On-balance volume</h3>\n<h4>What Is On-Balance Volume (OBV)?</h4>\nOn-balance volume (OBV) is a technical trading momentum indicator that uses volume flow to predict changes in stock price. Joseph Granville first developed the OBV metric in the 1963 book Granville's New Key to Stock Market Profits."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c2b8fccc-4d18-434b-b8ea-5110064abd47",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n$$\nOBV = OBVp + \\left\\{\n    \\begin{array}\\\\\n        volume & \\mbox{if } \\  CLOSE > CLOSEp \\\\\n        0 & \\mbox{if } \\   CLOSE = CLOSEp\\\\\n        -volume &\\mbox{if } \\   CLOSE < CLOSEp\\\\\n    \\end{array}\n\\right.\n$$\n\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "e29f8192-7b76-497d-b4d4-e2386bf1fba7",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define a function to calculate OBV values\ndef calculate_obv(data):\n    obv = []  # Initialize the OBV list\n    obv.append(0)  # The first OBV value is always 0\n    for i in range(1, len(data)):\n        # If the current closing price is higher than the previous closing price,\n        # add the current volume to the previous OBV value\n        if data['Close'][i] > data['Close'][i-1]:\n            obv.append(obv[-1] + data['Volume'][i])\n        # If the current closing price is lower than the previous closing price,\n        # subtract the current volume from the previous OBV value\n        elif data['Close'][i] < data['Close'][i-1]:\n            obv.append(obv[-1] - data['Volume'][i])\n        # If the current closing price is equal to the previous closing price,\n        # use the previous OBV value\n        else:\n            obv.append(obv[-1])\n    return obv\n# Calculate the OBV values and add a new column to the DataFrame\ndf['OBV'] = calculate_obv(df)\ndf['OBV'].head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "717c37b2-f3e1-4c0d-a9cf-6af68ab50bf9",
      "metadata": {},
      "outputs": [],
      "source": [
        "<h3>ADV:Average Daily Trading Volume</h3>\nAverage daily trading volume (ADTV) is the average number of shares traded within a day in a given stock. Daily volume is how many shares are traded each day, but this can be averaged over a number of days to find the average daily volume. Average daily trading volume is an important metric because high or low trading volume attracts different types of traders and investors. Many traders and investors prefer higher average daily trading volume compared to low trading volume, because with high volume it is easier to get into and out positions. Low volume assets have fewer buyers and sellers, and therefore it may be harder to enter or exit at a desired price.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "02166dfa-f2c9-4e8d-a7ef-cbc67aec1912",
      "metadata": {},
      "outputs": [],
      "source": [
        "adv = df[\"Volume\"].mean()\nprint(f\"Avarage Dailu Volume is : {adv}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2d5dcdb-9a9f-420c-9cb0-482a656f3128",
      "metadata": {},
      "outputs": [],
      "source": [
        "<h3>RSI: Relative Strength Index </h3>\n<h4>What Is the Relative Strength Index (RSI)?</h4>\nThe relative strength index (RSI) is a momentum indicator used in technical analysis. RSI measures the speed and magnitude of a security's recent price changes to evaluate overvalued or undervalued conditions in the price of that security."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "606a92bf-b654-4d53-b90a-cdbcfd2c9984",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n$$\nRSI_{step \\ one} = 100 - [ \\frac{100}{1 + \\frac{Avg \\ gain}{Avg \\ loss}} ]\n$$\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "a742deb6-271c-4beb-b636-914f3c1809c0",
      "metadata": {},
      "outputs": [],
      "source": [
        "\ndef rsi(df, n=14):\n    # Get the closing price data from the DataFrame\n    close = df['Close']\n    \n    # Calculate the price differences between each day\n    delta = close.diff()\n\n    # Define the up and down days\n    up, down = delta.copy(), delta.copy()\n    up[up < 0] = 0  # If the price difference is negative, set it to 0 (up days)\n    down[down > 0] = 0  # If the price difference is positive, set it to 0 (down days)\n\n    # Calculate the exponential moving averages of the up and down days\n    roll_up = up.ewm(com=n, min_periods=n).mean()\n    roll_down = down.abs().ewm(com=n, min_periods=n).mean()\n\n    # Calculate the Relative Strength Index (RSI)\n    rs = roll_up / roll_down  # Calculate the relative strength\n    rsi = 100.0 - (100.0 / (1.0 + rs))  # Calculate the RSI using the relative strength\n\n    return rsi  # Return the RSI values as a pandas Series\n\ndf['RSI'] = rsi(df)\ndf.tail(10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "839203b8-f38b-4ac3-a4a6-b8900bce94bc",
      "metadata": {},
      "outputs": [],
      "source": [
        "<h3>AD : Accumulation/Distribution</h3>\nThe accumulation/distribution line was created by Marc Chaikin to determine the flow of money into or out of a security.\n It should not be confused with the advance/decline line. While their initials might be the same, these are entirely different indicators, as are their users. The advance/decline line provides insight into market movements and the accumulation/distribution line is of use to traders seeking to measure buy/sell pressure on a security or confirm the strength of a trend.  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "129aada0-e22e-4081-96f0-ac2e15a1855b",
      "metadata": {},
      "outputs": [],
      "source": [
        "<h4>Calculatig MFM (Money Flow Multiplier)</h4>\n$$\nMFM =  \\frac{(Close - Low) - (High - Close)}{High - Low}\n$$\n<h4>Now use MFM to calculate AD</h4>\n$$\nAD = Prev. AD + MFM\n$$"
      ]
    },
    {
      "cell_type": "code",
      "id": "766a5c19-6ed0-429e-8988-ceb99b35f1ac",
      "metadata": {},
      "outputs": [],
      "source": [
        "#Calculating MFM\ndf['AD'] = ((df['Close'] - df['Low']) - (df['High'] - df['Close'])) / (df['High'] - df['Low']) * df['Volume'] \n#Calculating AD\ndf['AD'] +=  df['AD'].shift(1)\ndf.head(50)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a89cc188-32aa-4f85-94bf-385eb2f629ee",
      "metadata": {},
      "outputs": [],
      "source": [
        "Let's save obtained DataSet to the file:"
      ]
    },
    {
      "cell_type": "code",
      "id": "3400bedc-9e38-4367-af74-642e2ee6242a",
      "metadata": {},
      "outputs": [],
      "source": [
        "df.to_csv(\"Lab1DataSet.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "153d61d6-514c-427b-a365-b0c83a4fa5ff",
      "metadata": {},
      "outputs": [],
      "source": [
        "<h5>Here is more information about indicators <a href = \"https://www.investopedia.com/\">investopedia</a></h5>\n\n\n\n  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b7004ff-2017-4a0e-aad9-e9edb4933214",
      "metadata": {},
      "outputs": [],
      "source": [
        "<h1>Excellent! You have just completed the  Introduction Notebook!</h1>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e5856ce-ba60-4432-8459-0862d09f1578",
      "metadata": {},
      "outputs": [],
      "source": [
        "# **Thank you for completing this lab!**\n\n## Author\n\n<a href=\"https://author.skills.network/instructors/ostap_liashenyk\" target=\"_blank\" >Ostap Liashenyk</a>\n\n<a href=\"https://author.skills.network/instructors/yaroslav_vyklyuk_2?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkGuidedProjectsIBMSkillsNetworkGPXX0QGDEN2306-2023-01-01\">Prof. Yaroslav Vyklyuk, DrSc, PhD</a>\n\n<a href=\"https://author.skills.network/instructors/mariya_fleychuk?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkGuidedProjectsIBMSkillsNetworkGPXX0QGDEN2306-2023-01-01\">Prof. Mariya Fleychuk, DrSc, PhD</a>\n\n\n\n\n## Change Log\n\n| Date (YYYY-MM-DD) | Version | Changed By      | Change Description                                         |\n| ----------------- | ------- | ----------------| ---------------------------------------------------------- |\n|     2023-04-01    |   1.0   | Ostap Liashenyk | Creation of the lab                                        |\n\n<hr>\n\n## <h3 align=\"center\"> © IBM Corporation 2023. All rights reserved. </h3>"
      ]
    },
    {
      "cell_type": "code",
      "id": "317d090c-400d-403d-bf43-5414264b7e6d",
      "metadata": {},
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": ""
    },
    "kernelspec": {
      "name": "",
      "display_name": ""
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}