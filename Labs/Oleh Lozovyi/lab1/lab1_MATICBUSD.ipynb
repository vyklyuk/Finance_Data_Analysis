{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "580260e6-d409-42e5-ae02-322ad994ca30",
      "metadata": {},
      "outputs": [],
      "source": [
        "<center>\n    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"300\" alt=\"cognitiveclass.ai logo\"  />\n</center>\n\n# Financial services: Lab 1.Investigation of cryptocurrency exchange rate dynamic (on the example of cryptocurrency pair MATIC/BUSD), сalculation and analysis of technical financial indicators, characterizing the cryptocurrency market (on the example of ADOSC, NATR, TRANGE)\n\nEstimated time needed: **30** minutes\n\nThe tasks:\n* Download and process statistical time series of cryptocurrency pair MATIC/BUSD, describing the dynamics of the cryptocurrency market;\n* Upload statistical data (framework) from the Pandas library;\n* Calculate and analyze technical financial indicators for cryptocurrecny indicators analysis (ATR, OBV, ADV, RSI, AD)\n\n## Objectives\n\nAfter completing this lab you will be able to:\n\n*   Acquire data in various ways\n*   Obtain insights from data with Pandas library\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4fc9ee38-acdb-4a8e-8fbd-ec40872dfd59",
      "metadata": {},
      "outputs": [],
      "source": [
        "## Table of Contents\n\n<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n<ol>\n    <li>Data Acquisition</li> \n    <li>Use some indicators</li>    \n    <li>Basic Insight of Dataset</li>\n</ol>\n\n    \n</div>\n<hr>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b511312b-242c-4acc-a506-85172e8ae113",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data Acquisition\n<p>\nThere are various formats for a dataset: .csv, .json, .xlsx  etc. The dataset can be stored in different places, on your local machine or sometimes online.<br>\n\nIn this section, you will learn how to load a dataset into our Jupyter Notebook.<br>\n\nIn our case, the Trading Dataset is an online source, and it is in a CSV (comma separated value) format. Let's use this dataset as an example to practice data reading.\n\n<ul>\n    <li>Data source: <a href=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-GPXX0UXWEN/labs/MATICBUSD_trades.csv\" target=\"_blank\">https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-GPXX0UXWEN/labs/MATICBUSD_trades.csv</a></li>\n    <li>Data type: csv</li>\n</ul>\n\nThe Pandas Library is a useful tool that enables us to read various datasets into a dataframe; our Jupyter notebook platforms have a built-in <b>Pandas Library</b> so that all we need to do is import Pandas without installing.\n</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "eddc1088-1217-49e0-aab9-efebcb99de53",
      "metadata": {},
      "outputs": [],
      "source": [
        "#install specific version of libraries used in  lab\n# ! conda install pandas  -y\n# ! conda install numpy -y\n! conda install -c conda-forge ta-lib -y"
      ]
    },
    {
      "cell_type": "code",
      "id": "1fa4beea-77c7-47c0-97e2-f44980cbe908",
      "metadata": {},
      "outputs": [],
      "source": [
        "# import pandas library\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport talib as tb\n#Further specify the value of the precision parameter equal to 3 to display three decimal signs (instead of 6 as default).\npd.set_option(\"display.precision\", 3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8bcdebd5-eb05-4dc0-ab0b-8cc4d371b341",
      "metadata": {},
      "outputs": [],
      "source": [
        "## Read Data\n<p>\nWe use <code>pandas.read_csv()</code> function to read the csv file. In the brackets, we put the file path along with a quotation mark so that pandas will read the file into a dataframe from that address. The file path can be either an URL or your local file address.<br>\n\nYou can also assign the dataset to any variable you create.\n\n</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "3bc6d8e2-f81b-4dfe-8afb-9d6560acd8cf",
      "metadata": {},
      "outputs": [],
      "source": [
        "path = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-GPXX0UXWEN/labs/MATICBUSD_trades.csv\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ccd235c-afd6-4037-9868-d181819cc46f",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n\nThis dataset was hosted on IBM Cloud object. Click <a href=\"https://cocl.us/DA101EN_object_storage?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDA0101ENSkillsNetwork20235326-2021-01-01\">HERE</a> for free storage.\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "96c1105a-4be4-488c-9bd7-d90220304045",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Read the online file by the URL provides above, and assign it to variable \"df\"\nwdf = pd.read_csv(path, index_col=0)\nwdf"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c96710d1-ca0a-4de9-aa3d-d6bde1dcea70",
      "metadata": {},
      "outputs": [],
      "source": [
        "After reading the dataset, we can use the <code>dataframe.head(n)</code> method to check the top n rows of the dataframe, where n is an integer. Contrary to <code>dataframe.head(n)</code>, <code>dataframe.tail(n)</code> will show you the bottom n rows of the dataframe.\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "d0e55d15-8d3d-4bd7-8e18-e6bd27645444",
      "metadata": {},
      "outputs": [],
      "source": [
        "#create new dataset\ndf = pd.DataFrame()\n#set time as index\nwdf['ts'] = pd.to_datetime(wdf['ts'])\nwdf.set_index('ts', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "id": "45548245-bb6b-48a7-a73b-7b440675aa75",
      "metadata": {},
      "outputs": [],
      "source": [
        "df['open'] = wdf['price'].resample('1min').first()\ndf['high'] = wdf['price'].resample('1min').max()\ndf['low'] = wdf['price'].resample('1min').min()\ndf['close'] = wdf['price'].resample('1min').last()\ndf['volume'] = wdf['volume'].resample('1min').sum()\ndf['avg_price'] = wdf['price'].resample('1min').mean()"
      ]
    },
    {
      "cell_type": "code",
      "id": "723b5f9b-929b-410b-b3ee-40ec1106e36d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# show the first 5 rows using dataframe.head() method\ndf.index = pd.to_datetime(df.index)\nprint(\"The first 5 rows of the dataframe\") \ndf.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d3d5edb-b16d-4e51-b1ca-98412f0ff539",
      "metadata": {},
      "outputs": [],
      "source": [
        "<div class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\">\n<h1> Question #1: </h1>\n<b>Check the bottom 10 rows of data frame \"df\".</b>\n</div>\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "83598fbf-4d23-4fa2-a1e4-78c03a0e0a2e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Write your code below and press Shift+Enter to execute \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c67ae6c-5aa7-461e-9107-1ad48b89e380",
      "metadata": {},
      "outputs": [],
      "source": [
        "<details><summary>Click here for the solution</summary>\n\n```python\nprint(\"The last 10 rows of the dataframe\\n\")\ndf.tail(10)\n```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d2cd060a-0048-4a9c-973e-91c19df01cd9",
      "metadata": {},
      "outputs": [],
      "source": [
        "### Add Headers\n<p>\nTake a look at our dataset. Pandas automatically set the header with an integer starting from 0.\n</p>\n\nTo better describe our data, we can introduce a header.\n</p>\n\n<p>\nThus, we have to add headers manually.\n</p>\n\n<p>\nFirst, we create a list \"headers\" that include all column names in order.\nThen, we use <code>dataframe.columns = headers</code> to replace the headers with the list we created.\n</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "390afbd7-3536-44bf-9771-08f50f7b33ff",
      "metadata": {},
      "outputs": [],
      "source": [
        "# create headers list\nheaders = [\"Open\", \"High\", \"Low\", \"Close\", \"Volume\", \"Avg_price\"]\nprint(\"headers\\n\", headers)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f95999ff-6e0b-4231-b695-e8476765e8a9",
      "metadata": {},
      "outputs": [],
      "source": [
        "We replace headers and recheck our dataframe:\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "6544cf36-f1b1-4a6c-a300-d49277e1a252",
      "metadata": {},
      "outputs": [],
      "source": [
        "df.columns = headers\ndf.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "id": "88951ac5-3e3c-4f59-a45c-63f3ee84ffb7",
      "metadata": {},
      "outputs": [],
      "source": [
        "df.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "079e9f1b-21f5-46f5-9f66-552082f71803",
      "metadata": {},
      "outputs": [],
      "source": [
        "We can drop missing values along the column \"Open\" by uncommenting the following:\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "456f123a-a5a1-4f8a-bbb9-1fbb03990da4",
      "metadata": {},
      "outputs": [],
      "source": [
        "#df=df1.dropna(subset=[\"Open\"], axis=0)\ndf.head(20)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb056432-402a-4ebc-a9d9-a33fe58910f5",
      "metadata": {},
      "outputs": [],
      "source": [
        "Now, we have successfully read the raw dataset and added the correct headers into the dataframe.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0dc2ce3-d2dc-483a-b004-a35ba7b8ed98",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Use some indicators"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "964d763d-b7d7-4885-beec-56a63b333fa7",
      "metadata": {},
      "outputs": [],
      "source": [
        "## ADOSC\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "905ab189-85f2-43f9-98bd-5652dd1aba27",
      "metadata": {},
      "outputs": [],
      "source": [
        "The Accumulation/Distribution Oscillator is also known as the Chaikin Oscillator after its inventor.\n\nLike other momentum indicators, this indicator is designed to anticipate directional changes in the Accumulation Distribution Line by measuring the momentum behind the movements. A momentum change is the first step to a trend change. Anticipating trend changes in the Accumulation Distribution Line can help chartists anticipate trend changes in the underlying security. The Chaikin Oscillator generates signals with crosses above/below the zero line or with bullish/bearish divergences.\n\nWe calculate ADOSC like: \n\n\n$$ N= \\frac{(Close−Low)−(High−Close)}{(High−Low)}$$\n\n$$M=N * Volume(Period)$$\n\n$$ADL=M(Period−1)+M(Period)$$\n\n$$CO=(3-dayEMAofADL)−(10-dayEMAofADL)$$\nwhere:\n$$N = Money flow multiplier$$\n$$M = Money flow volume$$\n$$ADL = Accumulation distribution line$$\n$$CO = Chaikin oscillator$$\n\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "3813f69a-229a-43d9-88d2-ce87985d9817",
      "metadata": {},
      "outputs": [],
      "source": [
        "co = tb.ADOSC(df.High, df.Low, df.Close, df.Volume)\ndf = df.merge(co.rename('ADOSC'), left_index=True, right_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "id": "d932f4b7-686a-4587-8130-9466c49ec963",
      "metadata": {},
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt, dates\n\nfig, ax = plt.subplots()\nax.plot(co, label = 'ADOSC')\n\nax.xaxis.set_major_formatter(dates.DateFormatter('%y-%m-%d'))\nfig.autofmt_xdate(rotation=45)\nplt.legend(loc = 'upper right')\nax.set_xlabel('DateTime')\nax.set_ylabel('ADOSC')\n\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83cf05ad-8c1d-4531-b91a-b5667e65fcd5",
      "metadata": {},
      "outputs": [],
      "source": [
        "## TRANGE"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22eb55c2-77c2-4131-9ee7-98d05155058a",
      "metadata": {},
      "outputs": [],
      "source": [
        "TRANGE (True range) is an indicator which measures the daily range plus any gap from the closing price of the preceding day.\n\nTrue Range is calculated as the greater of:\n\n<li>High for the period less the Low for the period.</li>\n<li>High for the period less the Close for the previous period.</li>\n<li>Close for the previous period and the Low for the current period.</li>"
      ]
    },
    {
      "cell_type": "code",
      "id": "9abac925-8c81-4d3c-b1dc-ebabe9d4b4fc",
      "metadata": {},
      "outputs": [],
      "source": [
        "true_range = tb.TRANGE(df.High, df.Low, df.Close)\ndf = df.merge(true_range.rename('TRANGE'), left_index=True, right_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "id": "07f67e68-340c-47d3-b9b8-3f995cf49821",
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots()\nax.plot(true_range, label = 'True range')\n\nax.xaxis.set_major_formatter(dates.DateFormatter('%y-%m-%d'))\nfig.autofmt_xdate(rotation=45)\nplt.legend(loc = 'upper right')\nax.set_xlabel('DateTime')\nax.set_ylabel('TRANGE')\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d300c4b8-102e-4273-b855-33b1f962dc32",
      "metadata": {},
      "outputs": [],
      "source": [
        "## NATR"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dbb6c93e-508d-404b-b61c-91ea73eabe70",
      "metadata": {},
      "outputs": [],
      "source": [
        "ATR Normalized is an instrument, which is used in the technical analysis for measuring the volatility level. In contrast to other modern and popular indicators it is not used for identifying the direction of price movement. It is used only for measuring the volatility level, especially the volatility, which is caused by price gaps or slow refreshing of the chart. ATR Normalized is a normalized version of the ATR indicator, which is calculated according to the formula $$NATR = 100*ATR(t) / Close(t)$$"
      ]
    },
    {
      "cell_type": "code",
      "id": "008a85f0-17d6-4d18-bcf7-513cf6417e81",
      "metadata": {},
      "outputs": [],
      "source": [
        "#calculate ATR\natr = true_range.rolling(10).sum() / 10\n#calculate ATR normalized\nnatr = atr * 100 / df['Close']\ndf = df.merge(natr.rename('NATR'), left_index=True, right_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "id": "baa4e2da-ab2e-4b4c-9bf8-72d8ad8b6e35",
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots()\nax.plot(natr, label = 'ATR normalized')\n\nax.xaxis.set_major_formatter(dates.DateFormatter('%y-%m-%d'))\nfig.autofmt_xdate(rotation=45)\nplt.legend(loc = 'upper right')\nax.set_xlabel('DateTime')\nax.set_ylabel('NATR')\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eba1f6ac-6c03-48e1-8707-68a747a69f53",
      "metadata": {},
      "outputs": [],
      "source": [
        " <div class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\">\n<h1> Question #2: </h1>\n<b>Build an ATR to DateTime graph.</b>\n</div>\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "060ade65-f098-4df9-a932-083e8045eb5c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Write your code below and press Shift+Enter to execute \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad34b37a-076d-4996-a7fd-6ff091f4f9f0",
      "metadata": {},
      "outputs": [],
      "source": [
        "<details><summary>Click here for the solution</summary>\n\n```python\nfig, ax = plt.subplots()\nax.plot(atr, label = 'ATR')\n\nax.xaxis.set_major_formatter(dates.DateFormatter('%y-%m-%d'))\nfig.autofmt_xdate(rotation=45)\nplt.legend(loc = 'upper right')\nax.set_xlabel('DateTime')\nax.set_ylabel('ATR')\nplt.show()\n```\n\n</details>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d95eb29a-b331-4128-9955-cb8a46562adf",
      "metadata": {},
      "outputs": [],
      "source": [
        "## Save Dataset\n<p>\nCorrespondingly, Pandas enables us to save the dataset to csv. By using the <code>dataframe.to_csv()</code> method, you can add the file path and name along with quotation marks in the brackets.\n</p>\n<p>\nFor example, if you would save the dataframe <b>df</b> as <b>MATICBUSD_trades_1m.csv</b> to your local machine, you may use the syntax below, where <code>index = False</code> means the row names will not be written.\n</p>\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "cf21c891-21d4-4507-b003-49a3baa97d6a",
      "metadata": {},
      "outputs": [],
      "source": [
        "df.tail()"
      ]
    },
    {
      "cell_type": "code",
      "id": "5b0a5b7a-d488-4af7-a599-795bed1465f0",
      "metadata": {},
      "outputs": [],
      "source": [
        "df.reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "id": "1d71a642-1a17-474a-ab75-eb9a37013fbd",
      "metadata": {},
      "outputs": [],
      "source": [
        "df.to_csv(\"MATICBUSD_trades_1m.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c7d33b59-60d9-4709-ab27-c502a100defa",
      "metadata": {},
      "outputs": [],
      "source": [
        "We can also read and save other file formats. We can use similar functions like **`pd.read_csv()`** and **`df.to_csv()`** for other data formats. The functions are listed in the following table:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "275a00c9-1655-4e53-8952-a9131534a8e9",
      "metadata": {},
      "outputs": [],
      "source": [
        "## Read/Save Other Data Formats\n\n| Data Formate |        Read       |            Save |\n| ------------ | :---------------: | --------------: |\n| csv          |  `pd.read_csv()`  |   `df.to_csv()` |\n| json         |  `pd.read_json()` |  `df.to_json()` |\n| excel        | `pd.read_excel()` | `df.to_excel()` |\n| hdf          |  `pd.read_hdf()`  |   `df.to_hdf()` |\n| sql          |  `pd.read_sql()`  |   `df.to_sql()` |\n| ...          |        ...        |             ... |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "38ae65a8-49c4-4be0-94c0-576ad49e2dad",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Basic Insight of Dataset\n<p>\nAfter reading data into Pandas dataframe, it is time for us to explore the dataset.<br>\n\nThere are several ways to obtain essential insights of the data to help us better understand our dataset.\n\n</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d18599cb-190e-4291-ba53-43c1945bc5c6",
      "metadata": {},
      "outputs": [],
      "source": [
        "## Data Types\n<p>\nData has a variety of types.<br>\n\nThe main types stored in Pandas dataframes are <b>object</b>, <b>float</b>, <b>int</b>, <b>bool</b> and <b>datetime64</b>. In order to better learn about each attribute, it is always good for us to know the data type of each column. In Pandas:\n\n</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "0b937044-561b-4365-901a-2c04a200f80b",
      "metadata": {},
      "outputs": [],
      "source": [
        "df.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bcd87c5e-4e86-4d09-8fa8-8073c6bd79d8",
      "metadata": {},
      "outputs": [],
      "source": [
        "<p>\nAs shown above, it is clear to see that the data type of \"Open\" and \"Close\" are <code>float64</code>, \"Ts\" is <code>object</code>, and \"Rec_count\" is <code>int64</code>, etc.\n</p>\n<p>\nThese data types can be changed; we will learn how to accomplish this in a later module.\n</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b450b04-af88-432e-a8a2-cd91c0dd2959",
      "metadata": {},
      "outputs": [],
      "source": [
        "## Describe\nIf we would like to get a statistical summary of each column e.g. count, column mean value, column standard deviation, etc., we use the describe method:\n"
      ]
    },
    {
      "cell_type": "raw",
      "id": "b160ad2b-ff85-408d-a79c-d6b4f7ec0904",
      "metadata": {},
      "outputs": [],
      "source": [
        "dataframe.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "88448f81-4db1-4ae3-8417-e9ae7975c88d",
      "metadata": {},
      "outputs": [],
      "source": [
        "This method will provide various summary statistics, excluding <code>NaN</code> (Not a Number) values.\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "12488e2f-6bf4-48c4-8a14-b89ef989700c",
      "metadata": {},
      "outputs": [],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad4c234b-c05b-47e1-9a5f-f5b326779e73",
      "metadata": {},
      "outputs": [],
      "source": [
        "<p>\nThis shows the statistical summary of all numeric-typed (int, float) columns.<br>\n\nFor example, the attribute \"Open\" has 66861 counts, the mean value of this column is 0.865, the standard deviation is 0.055, the minimum value is 0.761, 25th percentile is 0.808, 50th percentile is 0.870, 75th percentile is 0.910, and the maximum value is 1.066. <br>\n\nHowever, what if we would also like to check all the columns including those that are of type object? <br><br>\n\nYou can add an argument <code>include = \"all\"</code> inside the bracket. Let's try it again.\n\n</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "db132e99-e1b0-46d9-9bbb-7444a1cbcc26",
      "metadata": {},
      "outputs": [],
      "source": [
        "# describe all the columns in \"df\" \ndf.describe(include = \"all\", datetime_is_numeric = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8cbc5dd7-837f-4646-a1df-52cda634d063",
      "metadata": {},
      "outputs": [],
      "source": [
        "<p>\nNow it provides the statistical summary of all the columns, including object-typed attributes.<br>\n\nWe can now see how many unique values there, which one is the top value and the frequency of top value in the object-typed columns.<br>\n\nSome values in the table above show as \"NaN\". This is because those numbers are not available regarding a particular column type.<br>\n\n</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c10694e-c3e8-4c38-b27a-fb4ce6c3096b",
      "metadata": {},
      "outputs": [],
      "source": [
        "<div class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\">\n<h1> Question #3: </h1>\n\n<p>\nYou can select the columns of a dataframe by indicating the name of each column. For example, you can select the three columns as follows:\n</p>\n<p>\n    <code>dataframe[[' column 1 ',column 2', 'column 3']]</code>\n</p>\n<p>\nWhere \"column\" is the name of the column, you can apply the method  \".describe()\" to get the statistics of those columns as follows:\n</p>\n<p>\n    <code>dataframe[[' column 1 ',column 2', 'column 3'] ].describe()</code>\n</p>\n\nApply the  method to \".describe()\" to the columns 'length' and 'compression-ratio'.\n\n</div>\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "4cb92279-2ad0-4df2-afd9-e7a349ac1b86",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Write your code below and press Shift+Enter to execute \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "298f5469-d769-4594-a164-e9215cb3b324",
      "metadata": {},
      "outputs": [],
      "source": [
        "<details><summary>Click here for the solution</summary>\n\n```python\ndf[['Open', 'Close']].describe()\n```\n\n</details>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "397d9d06-a4d3-48bf-bc77-e476d5bb9385",
      "metadata": {},
      "outputs": [],
      "source": [
        "## Info \nAnother method you can use to check your dataset is:\n"
      ]
    },
    {
      "cell_type": "raw",
      "id": "9147b7a8-05b9-4ee2-a071-8023c4876c48",
      "metadata": {},
      "outputs": [],
      "source": [
        "dataframe.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c1beebb-eebe-430f-9b31-23ed03e8ec2e",
      "metadata": {},
      "outputs": [],
      "source": [
        "It provides a concise summary of your DataFrame.\n\nThis method prints information about a DataFrame including the index dtype and columns, non-null values and memory usage.\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "933dd3b4-2af8-43ff-a0b1-f19eefaf0b5c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# look at the info of \"df\"\ndf.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "867cdfa7-9f4c-4f6d-87c3-c8bb02620e5e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Excellent! You have just completed the Introduction Notebook!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "addbe022-c1cb-43c1-8d3a-5fad4a6ed718",
      "metadata": {},
      "outputs": [],
      "source": [
        "# **Thank you for completing Lab 1!**\n\n## Authors\n\n<a href=\"https://author.skills.network/instructors/oleh_lozovyi?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkGuidedProjectsIBMSkillsNetworkGPXX0QGDEN2306-2023-01-01\">Oleh Lozovyi</a>\n\n<a href=\"https://author.skills.network/instructors/yaroslav_vyklyuk_2?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkGuidedProjectsIBMSkillsNetworkGPXX0QGDEN2306-2023-01-01\">Prof. Yaroslav Vyklyuk, DrSc, PhD</a>\n\n<a href=\"https://author.skills.network/instructors/mariya_fleychuk?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkGuidedProjectsIBMSkillsNetworkGPXX0QGDEN2306-2023-01-01\">Prof. Mariya Fleychuk, DrSc, PhD</a>\n\n<a href=\"https://www.linkedin.com/in/joseph-s-50398b136/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDA0101ENSkillsNetwork20235326-2021-01-01\">Joseph Santarcangelo</a>\n\n\n<a href=\"https://www.linkedin.com/in/fiorellawever/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDA0101ENSkillsNetwork20235326-2021-01-01\">Fiorella Wenver</a>\n\n<a href=\"https:// https://www.linkedin.com/in/yi-leng-yao-84451275/ \" target=\"_blank\" >Yi Yao</a>\n\n\n## Change Log\n\n| Date (YYYY-MM-DD) | Version | Changed By   | Change Description                                         |\n| ----------------- | ------- | -------------| ---------------------------------------------------------- |\n|     2023-03-01    |   1.0   | Oleh Lozovyi | Lab created                                                |\n\n<hr>\n\n## <h3 align=\"center\"> © IBM Corporation 2023. All rights reserved. <h3/>\n\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "e2a49ac6-540f-4505-bf40-d5ffe87831b9",
      "metadata": {},
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": ""
    },
    "kernelspec": {
      "name": "",
      "display_name": ""
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}