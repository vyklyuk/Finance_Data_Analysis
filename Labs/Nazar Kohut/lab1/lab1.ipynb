{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a5e4fa0a-84d8-4d07-a612-9021567d0a3f",
      "metadata": {},
      "outputs": [],
      "source": [
        "<center>\n    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-GPXX09DGEN/SN_web_lightmode.png?1676849283261\" width=\"300\" alt=\"cognitiveclass.ai logo\">\n</center>\n\n# *Investigation of BTC/BUSD cryptocurrency using ADOSC, NATR, TRANGE indicators, and other cryptocurrencies.*\n\n\n## Lab 1. Dataset creation\n\nEstimated time needed: **30** minutes\n\n<div class=\"alert alert-danger alertdanger\">\nТут має дописати Марія\n</div>\n\n\n## Objectives\n\nAfter completing this lab you will be able to:\n\n*   Acquire data in various ways\n*   Obtain insights from data with Pandas library\n*   Resample data\n*   Calculate Indicators for cryptocurrency market analysis \n\n\n<h3>Table of Contents</h3>\n\n<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n<ol>\n    <li><u>Data Acquisition</u></li>\n        <ul>\n            <li><u>Read Data</u></li>\n            <li><u>Resample Data</u></li>\n        </ul>\n    <li><u>Financial Indicators</u></li>\n        <ul>\n            <li><u>ADOSC</u></li>\n            <li><u>NATR</u></li>\n            <li><u>TRANGE</u></li>\n            <li><u>Save Dataset</u></li>\n        </ul>\n    <li><u>Basic Insight of Dataset</u></li>\n        <ul>\n            <li><u>Data Types</u></li>\n            <li><u>Describe</u></li>\n            <li><u>Info</u></li>\n        </ul>\n</ol>\n\n</div>\n<hr>\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f39ce096-d0f2-413c-b6ff-68509bcf240d",
      "metadata": {},
      "outputs": [],
      "source": [
        "***Dataset description***\n\n*Our dataset contains data on individual trades of BTC, rather than aggregated data such as daily prices or volume.*\n\n**Attributes:**\n* bs: The buy/sell indicator, which indicates whether a trade was initiated by a buyer or a seller. This may be useful for understanding market sentiment and trends.\n* price: The price of BTC at the time of the trade.\n* volume: The total number of BTC that were exchanged during a single trade or transaction.\n\n\n\n***Note:*** other datasets(that were used in this lab) are similar to this one in terms of attributes"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d473c24-7c5d-492c-bd80-b58f4dc82d7b",
      "metadata": {},
      "outputs": [],
      "source": [
        "## Data Acquisition\n\n<p>\nThere are various formats for a dataset: .csv, .json, .xlsx  etc. The dataset can be stored in different places, on your local machine or sometimes online.<br>\n\nIn this section, you will learn how to load a dataset into our Jupyter Notebook.<br>\n\nIn our case, the Finance Dataset is an online source, and it is in a CSV (comma separated value) format. Let's use this dataset as an example to practice data reading.\n\n<ul>\n    <li>Data source: <a href=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IND-GPXX0HOEEN/ADABUSD_trades_1m.csv\" target=\"_blank\">https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IND-GPXX0HOEEN/ADABUSD_trades_1m.csv</a></li>\n    <li>Data type: csv</li>\n</ul>\nThe Pandas Library is a useful tool that enables us to read various datasets into a dataframe; our Jupyter notebook platforms have a built-in <b>Pandas Library</b> so that all we need to do is import Pandas without installing.\n</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "b7472b90-2e71-4b01-83d4-000115646739",
      "metadata": {},
      "outputs": [],
      "source": [
        "# import sys\n# !conda install --yes --prefix {sys.prefix} pandas\n# !conda install --yes --prefix {sys.prefix} numpy\n# !conda install --yes --prefix {sys.prefix} matplotlib\n# !conda install --yes --prefix {sys.prefix} scipy\n# !conda install --yes --prefix {sys.prefix} seaborn"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e792431e-38fe-466f-9bd4-9c61f8f72ede",
      "metadata": {},
      "outputs": [],
      "source": [
        "Let's install <code>talib</code>, which has various methods used to calculate indicators."
      ]
    },
    {
      "cell_type": "code",
      "id": "36c5847f-f7bc-435b-bc7d-1ada57c65333",
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install talib-binary"
      ]
    },
    {
      "cell_type": "code",
      "id": "37e8ad63-ddaa-4f8e-833f-992d8e77a67b",
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install pandas-ta"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "130a59e0-5513-4512-a1e8-a6c24272fe46",
      "metadata": {},
      "outputs": [],
      "source": [
        "Execution of the code below may take some time."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c77040f-d1fb-4790-ac54-c42a6cf5dbe5",
      "metadata": {},
      "outputs": [],
      "source": [
        "Now, let's import libraries that we are going to use\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "e60ef2ea-73f9-4a61-b28b-7863dd5c7a15",
      "metadata": {},
      "outputs": [],
      "source": [
        "# import pandas library\nimport pandas as pd\nimport numpy as np\n# indicators calculation libraries\nimport talib"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c7db0c24-5707-4677-af7b-503dbd88683a",
      "metadata": {},
      "outputs": [],
      "source": [
        "### Read Data\n<p>\nWe use <code>pandas.read_csv()</code> function to read the csv file. In the brackets, we put the file path along with a quotation mark so that pandas will read the file into a dataframe from that address. The file path can be either an URL or your local file address.<br>\n\nIn our dataset we already have an index column, so let's use <code>index_col=0</code> parameter inside the <code>read_csv()</code> method to use first row from dataset as an index.\n\nYou can also assign the dataset to any variable you create.\n\n</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "b543223c-aa59-44e5-96fc-c6647ebff457",
      "metadata": {},
      "outputs": [],
      "source": [
        "path = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-GPXX09DGEN/BTCBUSD_trades.csv\""
      ]
    },
    {
      "cell_type": "code",
      "id": "64ea34c0-6409-445d-a610-028188b6b8ff",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Read the online file by the URL provides above, and assign it to variable \"df\"\n# columns_to_use = ['ts', 'bs', 'price', 'volume']\ndf = pd.read_csv(path, index_col=\"ts\")\n# ranming and droping redundant column\ndf.rename({\"Unnamed: 0\":\"col_to_drop\"}, axis=\"columns\", inplace=True)\ndf.drop([\"col_to_drop\"], axis=1, inplace=True)\n# casting index type to datetime\ndf.index = pd.to_datetime(df.index)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9b67984-b765-404d-8b28-462de6ba2bf5",
      "metadata": {},
      "outputs": [],
      "source": [
        "After reading the dataset, we can use the <code>dataframe.head(n)</code> method to check the top n rows of the dataframe, where n is an integer. Contrary to <code>dataframe.head(n)</code>, <code>dataframe.tail(n)</code> will show you the bottom n rows of the dataframe.\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "3f79a796-8590-4800-873c-26f5796f0aba",
      "metadata": {},
      "outputs": [],
      "source": [
        "# show the first 5 rows using dataframe.head() method\nprint(\"The first 5 rows of the dataframe\")\ndf.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "717ea76a-b498-4706-a11a-33da7d1e3b89",
      "metadata": {},
      "outputs": [],
      "source": [
        "Let's capitalize names of the columns\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "e66d62ef-b62a-4d2d-a443-b1c868acfb2a",
      "metadata": {},
      "outputs": [],
      "source": [
        "current_columns = df.columns\n\ncapitalized_columns = [v.capitalize() for v in current_columns]\ncapitalized_columns"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e940069-c06a-44a2-9c99-95eafad9b715",
      "metadata": {},
      "outputs": [],
      "source": [
        "And replace old names inside dataframe\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "55aec778-dff1-4412-8c05-2d9408f9f0bb",
      "metadata": {},
      "outputs": [],
      "source": [
        "df.columns = capitalized_columns\ndf"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8c74bde-e43c-4cb7-8363-80756e42d4b5",
      "metadata": {},
      "outputs": [],
      "source": [
        "<div class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\">\n  <b style=\"font-size: 2em; font-weight: bold;\">Question #1:</b>\n\n  <b>Check the bottom 10 rows of data frame `df`.</b>\n    \n</div>"
      ]
    },
    {
      "cell_type": "code",
      "id": "51bd9fe0-95f4-4ce9-a1dc-e70f7db62461",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Write your code below and press Shift+Enter to execute \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43341bdb-f3c8-4082-b086-1dca2182c864",
      "metadata": {},
      "outputs": [],
      "source": [
        "<details><summary>Click here for the solution</summary>\n\n```python\nprint(\"The last 10 rows of the dataframe\\n\")\ndf.tail(10)\n```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f86b8607-cdde-48b2-a833-59a04eb714a0",
      "metadata": {},
      "outputs": [],
      "source": [
        "<div class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\">\n  <b style=\"font-size: 2em; font-weight: bold;\">Question #2:</b>\n\n  <b>Retrieve the names of the columns in a dataframe.</b>\n    \n</div>"
      ]
    },
    {
      "cell_type": "code",
      "id": "07ff52e3-b914-428d-b4d0-cd653f3dbd9b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Write your code below and press Shift+Enter to execute \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23f4971b-3626-4f2d-b7c7-60b53d003c1e",
      "metadata": {},
      "outputs": [],
      "source": [
        "<details><summary>Click here for the solution</summary>\n\n```python\nprint(df.columns)\n```\n\n</details>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0130757-f0bc-43f8-a804-93b0de6c29e7",
      "metadata": {},
      "outputs": [],
      "source": [
        "## Financial Indicators\n(Indicators calculation(ADOSC, NATR, TRANGE))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a4db0dde-5dcf-48c5-b914-2036e47f8013",
      "metadata": {},
      "outputs": [],
      "source": [
        "These indicators must be calculated on aggregated data; we also need to figure 'open', 'close', 'low', 'high'(ohcl) as they are required for calculation of our indicators. Aggregation can be performed using <code>pandas</code> <code>resample</code> method, while ohlc parameters can be retrieved using <code>ohlc(_method='ohlc')</code>"
      ]
    },
    {
      "cell_type": "code",
      "id": "a1c89af9-151c-4270-ab00-8027f0132db8",
      "metadata": {},
      "outputs": [],
      "source": [
        "resampled_df = df['Price'].resample('1Min').ohlc(_method='ohlc')\nresampled_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b7bbe64-1d58-48d7-8a06-4ac1ad0b9461",
      "metadata": {},
      "outputs": [],
      "source": [
        "Now, let's calculate other values."
      ]
    },
    {
      "cell_type": "code",
      "id": "fbddc80c-896c-42fe-9e94-0905d1419c48",
      "metadata": {},
      "outputs": [],
      "source": [
        "resampled_df['rec_count'] = df['Volume'].resample('1Min').count()\nresampled_df['volume'] = df['Volume'].resample('1Min').sum()\nresampled_df['avg_price'] = df['Price'].resample('1Min').mean()\nresampled_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c1dcaabf-9a6e-4444-8d64-ff3644400c2f",
      "metadata": {},
      "outputs": [],
      "source": [
        "Now that we know how to aggregate data in 1-minute intervals, let's implement a method for different time intervals."
      ]
    },
    {
      "cell_type": "code",
      "id": "d5fe7e3a-dfcc-4050-abd9-cfd837de5596",
      "metadata": {},
      "outputs": [],
      "source": [
        "def resample_dataframe(df, period='10Min'):\n  res = df.copy()\n  res = res.resample(period).agg({\n    'open': 'first',\n    'high': 'max',\n    'low': 'min',\n    'close': 'last',\n    'rec_count': 'sum',\n    'volume': 'sum'\n  })\n  return res\n\nresampled_15_min_df = resample_dataframe(resampled_df, period='15Min')\nresampled_15_min_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0200b2be-18cf-4059-bb8f-73b70505d114",
      "metadata": {},
      "outputs": [],
      "source": [
        "We are all setup, the only thing left is indicators calculation."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2918572-b125-4e3d-affe-49ca94ee783c",
      "metadata": {},
      "outputs": [],
      "source": [
        "### ADOSC - Chaikin A/D Oscillator"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75ba7006-1124-47ba-bdae-372a52b40689",
      "metadata": {},
      "outputs": [],
      "source": [
        "<b>The Chaikin Oscillator(ADOSC)</b> is the difference between the 3-day and 10-day EMAs of the Accumulation Distribution Line. Like other momentum indicators, this indicator is designed to anticipate directional changes in the Accumulation Distribution Line by measuring the momentum behind the movements. \n\nBelow you can see the <b>formulas for Chaikin Oscillator</b>:\n\n$1.Money Flow Multiplier = [(Close  -  Low) - (High - Close)] /(High - Low)$\n\n$2. Money Flow Volume = Money Flow Multiplier * Volume for the Period.$\n\n$3. ADL = Previous ADL + Current Period's Money Flow Volume.$\n\n$4. Chaikin Oscillator = (3-day EMA of ADL)  -  (10-day EMA of ADL)$"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7011fe1-8ddd-4274-959f-12056c905577",
      "metadata": {},
      "outputs": [],
      "source": [
        "For more information follow: \n<ul>\n\n<li>\n<a href='https://school.stockcharts.com/doku.php?id=technical_indicators:chaikin_oscillator#:~:text=The%20Chaikin%20Oscillator%20is%20the,the%20momentum%20behind%20the%20movements'>https://school.stockcharts.com/doku.php?id=technical_indicators:chaikin_oscillator#:~:text=The%20Chaikin%20Oscillator%20is%20the,the%20momentum%20behind%20the%20movements</a>\n</li>\n\n<li>\n<a href='https://www.investopedia.com/articles/active-trading/031914/understanding-chaikin-oscillator.asp'>https://www.investopedia.com/articles/active-trading/031914/understanding-chaikin-oscillator.asp</a>\n</li>\n\n<li>\n<a href='https://www.investopedia.com/terms/c/chaikinoscillator.asp'>https://www.investopedia.com/terms/c/chaikinoscillator.asp</a>\n</li>\n\n</ul>"
      ]
    },
    {
      "cell_type": "code",
      "id": "74615f62-c452-422e-b68a-b2a231ec31f4",
      "metadata": {},
      "outputs": [],
      "source": [
        "def ADOSC(df, N1=3, N2=10) -> pd.DataFrame:\n    res = talib.ADOSC(df['high'], df['low'],\n                      df['close'], df['volume'], N1, N2)\n    return pd.DataFrame({'ADOSC': res}, index=df.index) \n\nadosc_df = ADOSC(resampled_df)\nadosc_df.head(25)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc5ab7a8-12d4-483e-9e3c-e6ab9a4b1023",
      "metadata": {},
      "outputs": [],
      "source": [
        "Our new dataset has the same index, so assign new column in our current dataframe."
      ]
    },
    {
      "cell_type": "code",
      "id": "0ddd0f7f-9b7c-4b75-8b9c-05591156c18f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# creating new column called 'ADOSC' in our current dataframe\nresampled_df['ADOSC'] = adosc_df['ADOSC']"
      ]
    },
    {
      "cell_type": "code",
      "id": "b4c2233a-8db2-4c61-bbc7-6af4d2e0a2f4",
      "metadata": {},
      "outputs": [],
      "source": [
        "resampled_df.head(25)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d41ee95f-f582-4e09-8e42-ec8f6d30e826",
      "metadata": {},
      "outputs": [],
      "source": [
        "### ATR Normalized (NATR)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d2ec1d84-13de-4664-8404-a0df040f5769",
      "metadata": {},
      "outputs": [],
      "source": [
        "<b>ATR Normalized</b> is an instrument, which is used in the technical analysis for measuring the volatility level. In contrast to other modern and popular indicators it is not used for identifying the direction of price movement. It is used only for measuring the volatility level, especially the volatility, which is caused by price gaps or slow refreshing of the chart.\n\n<b>ATR</b> Normalized is a normalized version of the ATR indicator, which is calculated according to the formula:\n\n$$100*\\frac{ATR(t)}{Close(t)}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "754d5489-69c4-4db7-ad0b-91e10e64eafa",
      "metadata": {},
      "outputs": [],
      "source": [
        "For more information follow: \n<ul>\n<li>\n<a href='https://support.atas.net/en/knowledge-bases/2/articles/43436-atr-normalized#:~:text=ATR%20Normalized%20is%20an%20instrument,the%20direction%20of%20price%20movement.'>https://support.atas.net/en/knowledge-bases/2/articles/43436-atr-normalized#:~:text=ATR%20Normalized%20is%20an%20instrument,the%20direction%20of%20price%20movement.</a>\n</li>\n</ul>"
      ]
    },
    {
      "cell_type": "code",
      "id": "dd9dc8b4-5252-49c2-bdf7-0794afa3674e",
      "metadata": {},
      "outputs": [],
      "source": [
        "def TALIB_NATR(df, timeperiod=14) -> pd.DataFrame:\n    \"\"\" Function for ATR Normalized (NATR) indicator using ```talib``` library.\n    \"\"\"\n    res = talib.NATR(df['high'], df['low'], df['close'], timeperiod=timeperiod)\n    return pd.DataFrame({'NATR': res}, index=df.index)\n\ndef PANDAS_TA_NATR(df, timeperiod=14) -> pd.DataFrame:\n    \"\"\" Function for ATR Normalized (NATR) indicator using ```pandas_ta``` library.\n    \"\"\"\n    res = natr(df['high'], df['low'], df['close'], timeperiod=timeperiod)\n    return pd.DataFrame({'NATR': res}, index=df.index)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7607a66d-2cb3-49e6-81fc-1a5d5d3589ec",
      "metadata": {},
      "outputs": [],
      "source": [
        "Let's call <code>TALIB_NATR</code> and <code>PANDAS_TA_NATR</code> methods and review the results they give us."
      ]
    },
    {
      "cell_type": "code",
      "id": "02e2716a-69ae-46c4-bc90-aca6beaa5e8c",
      "metadata": {},
      "outputs": [],
      "source": [
        "talib_natr_df = TALIB_NATR(resampled_df)\ntalib_natr_df.head(25)"
      ]
    },
    {
      "cell_type": "code",
      "id": "b26ea920-447f-4440-8a78-214d60a951e8",
      "metadata": {},
      "outputs": [],
      "source": [
        "pandas_ta_natr_df = PANDAS_TA_NATR(resampled_df)\npandas_ta_natr_df.head(25)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e58e967-85e5-4fb0-aa42-85eca95e0d6c",
      "metadata": {},
      "outputs": [],
      "source": [
        "The results from above methods can differ, as it is not uncommon to observe different results while using different libraries to calculate technical analysis indicators. Both pandas_ta and talib are widely used libraries for calculating technical indicators, but they may use different methods and algorithms to calculate the same indicator."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d7ae5054-29e1-480b-9d33-455dd1c90ab2",
      "metadata": {},
      "outputs": [],
      "source": [
        "Let's define custom function to calculate NATR indicator."
      ]
    },
    {
      "cell_type": "code",
      "id": "5ff15b22-e0d7-4f98-8cd5-5ca072ef058f",
      "metadata": {},
      "outputs": [],
      "source": [
        "def NATR(df: pd.DataFrame, period: int=14) -> pd.DataFrame:\n    \"\"\" Custom function for ATR Normalized (NATR) indicator.\n    \"\"\"\n    # calculate values\n    high, low, close = df['high'], df['low'], df['close']\n\n    high_low = high - low\n    high_close = np.abs(high - close.shift())\n    low_close = np.abs(low - close.shift())\n\n    # calculate True Range\n    ranges = pd.concat([high_low, high_close, low_close], axis=1)\n    true_range = np.max(ranges, axis=1)\n\n    # calculate previous ATR\n    atr_prev = true_range.rolling(period).sum() / period\n\n    # calculate current ATR\n    atr = (atr_prev*(period - 1) + true_range) / period\n\n    # normalize ATR \n    natr = (100 * atr) / df['close']\n    return pd.DataFrame({'NATR': natr})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4bb040ad-0134-45ab-aa34-1dde9e2bf4cb",
      "metadata": {},
      "outputs": [],
      "source": [
        "We will use NATR calculated by our custom function."
      ]
    },
    {
      "cell_type": "code",
      "id": "38eb74a4-a0a1-4e7d-b109-fe853562add8",
      "metadata": {},
      "outputs": [],
      "source": [
        "natr_df = NATR(resampled_df)\nnatr_df.head(25)"
      ]
    },
    {
      "cell_type": "code",
      "id": "3d6c567c-1aff-44ef-935a-16af4ac6cf2f",
      "metadata": {},
      "outputs": [],
      "source": [
        "resampled_df['NATR'] = natr_df['NATR']"
      ]
    },
    {
      "cell_type": "code",
      "id": "7b351108-0cef-4112-8b2d-02c04ed90f4a",
      "metadata": {},
      "outputs": [],
      "source": [
        "resampled_df.head(25)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e3ff1acb-8201-4dad-9190-a29e63e05cd3",
      "metadata": {},
      "outputs": [],
      "source": [
        "### True Range (TRANGE)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a45146c-0125-44e8-9d7b-7875309d55da",
      "metadata": {},
      "outputs": [],
      "source": [
        "<b>True Range</b> is a technical indicator. It is calculated as the maximum among the following values:\n\n$$max(High(t) - Low(t), |High(t) - Close(t-1)|,|Low(t) - Close(t-1)|)$$"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "33b18077-6490-4867-80d7-9ab64dc1cc99",
      "metadata": {},
      "outputs": [],
      "source": [
        "For more information follow:\n<ul>\n <li>\n <a href='https://www.linnsoft.com/techind/true-range-tr'>https://www.linnsoft.com/techind/true-range-tr</a>\n</li>\n\n<li>\n  <a href='https://support.atas.net/en/knowledge-bases/2/articles/45183-true-range'>https://support.atas.net/en/knowledge-bases/2/articles/45183-true-range</a>\n</li>\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "476057fd-4a2b-4c11-9584-84845503e04d",
      "metadata": {},
      "outputs": [],
      "source": [
        "def TRANGE(df) -> pd.DataFrame:\n    res = talib.TRANGE(df['high'], df['low'], df['close'])\n    return pd.DataFrame({'TRANGE': res}, index=df.index) \n\ntrange_df = TRANGE(resampled_df)\ntrange_df.head(25)"
      ]
    },
    {
      "cell_type": "code",
      "id": "19cebdf9-6cfa-47f9-afd4-351acb9da360",
      "metadata": {},
      "outputs": [],
      "source": [
        "resampled_df['TRANGE'] = trange_df['TRANGE']"
      ]
    },
    {
      "cell_type": "code",
      "id": "77ce41bf-a3b4-4b30-ba89-81752986f038",
      "metadata": {},
      "outputs": [],
      "source": [
        "resampled_df.head(25)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb7c0da5-5b90-45af-8039-d331676ddf9c",
      "metadata": {},
      "outputs": [],
      "source": [
        "Later, we will use other cryptocurrencies to determine if and how they affect our cryptocurrency. Let's add new columns to our dataframe."
      ]
    },
    {
      "cell_type": "code",
      "id": "694e4e30-7b84-491b-acb1-3af12bfc0a4c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# creating path variables to easily retrieve data\nape_path = 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-GPXX09DGEN/APEBUSD_trades_1m.csv'\nbnb_path = 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-GPXX09DGEN/BNBBUSD_trades_1m.csv'\ndoge_path = 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-GPXX09DGEN/DOGEBUSD_trades_1m.csv'\neth_path = 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-GPXX09DGEN/ETHBUSD_trades_1m.csv'\nxrp_path = 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-GPXX09DGEN/XRPBUSD_trades_1m.csv'\nmatic_path = 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-GPXX09DGEN/MATICBUSD_trades_1m.csv'"
      ]
    },
    {
      "cell_type": "code",
      "id": "b4e0a34d-8911-4e89-bac7-d4a8e2c0b433",
      "metadata": {},
      "outputs": [],
      "source": [
        "paths = [('ape', ape_path), ('bnb', bnb_path), ('doge', doge_path), ('eth', eth_path), ('xrp', xrp_path), ('matic', matic_path)]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "02d1bb28-d7c9-463b-965d-9b94be29fb05",
      "metadata": {},
      "outputs": [],
      "source": [
        "Our other datasets might have different 'ts', so we need to join(inner) them using <code>pandas</code> <code>merge</code> method."
      ]
    },
    {
      "cell_type": "code",
      "id": "077e9628-9478-498e-932c-679651592125",
      "metadata": {},
      "outputs": [],
      "source": [
        "merged_df = resampled_df.copy()\nfor name, path in paths:\n    # Read the online file by the URL provides above, and assign it to variable \"df\"\n    # we only need 'avg_price' and 'ts' fields, so we specify it in usecols\n    current_currency_df = pd.read_csv(path, index_col='ts', usecols=['ts', 'avg_price'])\n    current_currency_df.index = pd.to_datetime(current_currency_df.index)\n    # renaming 'avg_price'\n    current_currency_df.rename({'avg_price':f'{name}_avg_price'}, axis='columns', inplace=True)\n    merged_df = merged_df.merge(current_currency_df, on='ts')\n    \nmerged_df.head(15)"
      ]
    },
    {
      "cell_type": "code",
      "id": "ada4f543-6ca3-41c8-a4bd-a20cb6c2dbbd",
      "metadata": {},
      "outputs": [],
      "source": [
        "resampled_df = merged_df.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b114724a-c1d5-46dd-b09a-d861bb915f31",
      "metadata": {},
      "outputs": [],
      "source": [
        "### Save Dataset\n<p>\nCorrespondingly, Pandas enables us to save the dataset to csv. By using the <code>dataframe.to_csv()</code> method, you can add the file path and name along with quotation marks in the brackets.\n</p>\n<p>\nFor example, if you would save the dataframe <b>df</b> as <b>file_name.csv</b> to your local machine, you may use the syntax below, where <code>index = False</code> means the row names will not be written.\n</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "c5b28491-7e7f-4fee-ba32-94a5a731e748",
      "metadata": {},
      "outputs": [],
      "source": [
        "resampled_df.to_csv(\"BTCBUSD_resampled_1min.csv\", index=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0f09e43-58b7-4537-8c09-7e41a89ee290",
      "metadata": {},
      "outputs": [],
      "source": [
        "We can also read and save other file formats. We can use similar functions like **`pd.read_csv()`** and **`df.to_csv()`** for other data formats. The functions are listed in the following table:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "686e26a4-28d8-405d-88d4-37ff2e2e49e6",
      "metadata": {},
      "outputs": [],
      "source": [
        "<h2>Read/Save Other Data Formats</h2>\n\n| Data Formate |        Read       |            Save |\n| ------------ | :---------------: | --------------: |\n| csv          |  `pd.read_csv()`  |   `df.to_csv()` |\n| json         |  `pd.read_json()` |  `df.to_json()` |\n| excel        | `pd.read_excel()` | `df.to_excel()` |\n| hdf          |  `pd.read_hdf()`  |   `df.to_hdf()` |\n| sql          |  `pd.read_sql()`  |   `df.to_sql()` |\n| ...          |        ...        |             ... |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "58a6a7aa-3dda-42fa-8aa4-cc3fc89340cf",
      "metadata": {},
      "outputs": [],
      "source": [
        "## Basic Insight of Dataset\n<p>\nAfter reading data into Pandas dataframe, it is time for us to explore the dataset.<br>\n\nThere are several ways to obtain essential insights of the data to help us better understand our dataset.\n\n</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5005e546-e86e-4129-b6e2-1a0925fd71b8",
      "metadata": {},
      "outputs": [],
      "source": [
        "### Data Types\n<p>\nData has a variety of types.<br>\n\nThe main types stored in Pandas dataframes are <b>object</b>, <b>float</b>, <b>int</b>, <b>bool</b> and <b>datetime64</b>. In order to better learn about each attribute, it is always good for us to know the data type of each column. In Pandas:\n\n</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "1691d733-2d44-45a2-9ad2-e15278b2847d",
      "metadata": {},
      "outputs": [],
      "source": [
        "resampled_df.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "126ff280-dfcc-4557-99f6-f4c9ac29a74f",
      "metadata": {},
      "outputs": [],
      "source": [
        "A series with the data type of each column is returned.\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "5d162127-4b09-4264-94ca-38c4c26a4a7d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# check the data type of data frame \"df\" by .dtypes\nprint(resampled_df.dtypes)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0533c50-8d0a-40de-be9f-ff7d37ea768b",
      "metadata": {},
      "outputs": [],
      "source": [
        "### Describe\nIf we would like to get a statistical summary of each column e.g. count, column mean value, column standard deviation, etc., we use the describe method:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb6e228a-332c-48d6-be99-9e822205f9c3",
      "metadata": {},
      "outputs": [],
      "source": [
        "<code>dataframe.describe()</code>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "03ec3dc2-8bb9-4bf5-9615-0ec51957022e",
      "metadata": {},
      "outputs": [],
      "source": [
        "This method will provide various summary statistics, excluding <code>NaN</code> (Not a Number) values.\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "f9f2d7ca-6b0d-48d6-a6db-622fb4fa567a",
      "metadata": {},
      "outputs": [],
      "source": [
        "resampled_df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61fabc82-d18a-43eb-aa5b-12895be168b1",
      "metadata": {},
      "outputs": [],
      "source": [
        "<p>\nThis shows the statistical summary of all numeric-typed (int, float) columns.<br>\n\nFor example, the attribute 'Rec_count' has 65303 counts, the mean value of this column is 9.28, the standard deviation is 9.53, the minimum value is 1, 25th percentile is 4, 50th percentile is 6, 75th percentile is 12, and the maximum value is 114. <br>\n\nHowever, what if we would also like to check all the columns including those that are of type object, datetime or any other non numeric-type? <br><br>\n\nYou can add an argument <code>include = \"all\"</code> inside the bracket. Let's try it again.\n\n</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "049fb697-c649-4928-94c6-4bc33f79dd26",
      "metadata": {},
      "outputs": [],
      "source": [
        "# describe all the columns in \"df\" \nresampled_df.describe(include = \"all\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "faa512b2-3c62-4772-bfff-fb42c57c4238",
      "metadata": {},
      "outputs": [],
      "source": [
        "<p>\nNow it provides the statistical summary of all the columns, including attributes that are not numeric.<br>\n\nWe can now see how many unique values there, which one is the top value and the frequency of top value in the object-typed columns.<br>\n\nSome values in the table above show as \"NaN\". This is because those numbers are not available regarding a particular column type.<br>\n\n</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a07ea10e-62c3-4879-a495-1bca8eda07ba",
      "metadata": {},
      "outputs": [],
      "source": [
        "Note: you can change the precision for values using <code>pd.set_option(\"display.precision\", 2)</code> to display only 2 numbers after the <code>.</code>\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "dd47b2d2-2bec-4645-916f-eff81bd2f380",
      "metadata": {},
      "outputs": [],
      "source": [
        "precision = 2\npd.set_option(\"display.precision\", precision)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "271597eb-b9ad-4154-9c8e-48f17bc01e8a",
      "metadata": {},
      "outputs": [],
      "source": [
        "Now let's run <code>describe()</code> method one more time to make sure the precision was changed \n"
      ]
    },
    {
      "cell_type": "code",
      "id": "d9c5b857-1196-4a44-abe3-e28754497f75",
      "metadata": {},
      "outputs": [],
      "source": [
        "resampled_df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c943474a-b290-4cab-b1c8-2563fefaf9f7",
      "metadata": {},
      "outputs": [],
      "source": [
        "<div class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\">\n<h1> Question #3: </h1>\n\n<p>\nYou can select the columns of a dataframe by indicating the name of each column. For example, you can select the three columns as follows:\n</p>\n<p>\n    <code>dataframe[['column 1 ',column 2', 'column 3']]</code>\n</p>\n<p>\nWhere \"column\" is the name of the column, you can apply the method  \".describe()\" to get the statistics of those columns as follows:\n</p>\n<p>\n    <code>dataframe[['column 1 ',column 2', 'column 3'] ].describe()</code>\n</p>\n\nApply the  method to \".describe()\" to the columns 'low' and 'high'.\n\n</div>\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "d0801b3c-2f92-4add-ba06-1f3d30f2ac5d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Write your code below and press Shift+Enter to execute \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94d7160c-fd1c-49ff-b59e-36a027e29e8a",
      "metadata": {},
      "outputs": [],
      "source": [
        "<details><summary>Click here for the solution</summary>\n\n```python\nresampled_df[['low', 'high']].describe()\n```\n\n</details>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c6b71b8-b32b-4e80-b259-96d5452bac2b",
      "metadata": {},
      "outputs": [],
      "source": [
        "### Info\nAnother method you can use to check your dataset is:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "74021ea1-2e39-4533-9907-26945873fd2b",
      "metadata": {},
      "outputs": [],
      "source": [
        "<code>dataframe.info()</code>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "919070d2-fba7-4d06-be65-9e44035f04f6",
      "metadata": {},
      "outputs": [],
      "source": [
        "It provides a concise summary of your DataFrame.\n\nThis method prints information about a DataFrame including the index dtype and columns, non-null values and memory usage.\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "f7ef3627-dfc0-423d-a1d5-8de9aa646d5b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# look at the info of \"df\"\nresampled_df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f3b9d37e-8241-493a-87a9-ad96ebb3b23d",
      "metadata": {},
      "outputs": [],
      "source": [
        "## Excellent! You have just completed the  Introduction Notebook!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bda38c0e-66b3-48c4-87f5-acd1e03a2771",
      "metadata": {},
      "outputs": [],
      "source": [
        "# **Thank you for completing Lab 1!**\n\n## Authors\n\n<a href=\"https://author.skills.network/instructors/nazar_kohut\">Nazar Kohut</a>\n\n<a href=\"https://author.skills.network/instructors/yaroslav_vyklyuk_2?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkGuidedProjectsIBMSkillsNetworkGPXX0QGDEN2306-2023-01-01\">Prof. Yaroslav Vyklyuk, DrSc, PhD</a>\n\n<a href=\"https://author.skills.network/instructors/mariya_fleychuk?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkGuidedProjectsIBMSkillsNetworkGPXX0QGDEN2306-2023-01-01\">Prof. Mariya Fleychuk, DrSc, PhD</a>\n\n\n## Change Log\n\n| Date (YYYY-MM-DD) | Version | Changed By   | Change Description                                         |\n| ----------------- | ------- | -------------| ---------------------------------------------------------- |\n|     2023-02-25    |   1.0   | Nazar Kohut  | Lab created                                                |\n\n<hr>\n\n## <h3 align=\"center\"> © IBM Corporation 2023. All rights reserved. <h3/>"
      ]
    },
    {
      "cell_type": "code",
      "id": "e930089a-e5e0-4d13-8e9e-6fd17ce6a866",
      "metadata": {},
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": ""
    },
    "kernelspec": {
      "name": "",
      "display_name": ""
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}