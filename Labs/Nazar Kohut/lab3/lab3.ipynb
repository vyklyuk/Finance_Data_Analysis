{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e45918b4-7d02-4e23-917f-62e44d435871",
      "metadata": {},
      "outputs": [],
      "source": [
        "<center>\n    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-GPXX0YB4EN/SN_web_lightmode.png?1677516598099\" width=\"300\" alt=\"cognitiveclass.ai logo\"  />\n</center>\n\n# *Investigation of BTC/BUSD cryptocurrency using ADOSC, NATR, TRANGE indicators, and other cryptocurrencies.*\n\n# Lab 3. Exploratory Data Analysis\n\nEstimated time needed: **30** minutes\n\n## Objectives\n\nAfter completing this lab you will be able to:\n\n*   Explore features or charecteristics of your main cryptocurrency\n*   Explore features and charecteristics of your main cryptocurrency based on other cryptocurrencies\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ebc1addb-af3b-4b51-a642-728f59a6e8ce",
      "metadata": {},
      "outputs": [],
      "source": [
        "<h2>Table of Contents</h2>\n\n<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n<ol>\n    <li><u> Import Data from Module</u></li>\n    <li><u>Analyzing Individual Feature Patterns using Visualization</u></li>\n    <li><u>Descriptive Statistical Analysis</u></li>\n    <li><u>Basics of Grouping</u></li>\n    <li><u>Correlation and Causation</u></li>\n    <li><u>ANOVA</u></li>\n    <li><u>Granger Causality Test</u></li>\n</ol>\n\n</div>\n\n<hr>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0726b34-322e-41c1-96e8-c3679a6e4f63",
      "metadata": {},
      "outputs": [],
      "source": [
        "#### ***Dataset description***\n\nThe dataset used in this lab contains time-series data on various attributes related to Bitcoin (BTC) and other cryptocurrencies, aggregated at 1-minute intervals. The dataset index represents the time period for which the data is reported(1 minute).\n\n<hr>\n\n**Attributes:**\n\n* ***General:***\n    * `open` - the opening price of a **BTC** during a specific time period.\n    * `high` - the highest price of a **BTC** during a specific time period.\n    * `low` - the lowest price of a **BTC** during a specific time period.\n    * `close` - the closing price of a **BTC** during a specific time period.\n    * `rec_count` - the number of records or data points in the dataset for a given time period.\n    * `volume` - the total amount of trading activity (buying and selling) for a **BTC** during a specific time period.\n    * `avg_price` - the average price of a **BTC** during a specific time period.\n\n\n* ***Indicators***\n    * `ADOSC` - an indicator used in technical analysis to measure the momentum of buying and selling pressure for ***Bitcoin***.\n    * `NATR` - an indicator used in technical analysis to measure the volatility of ***Bitcoin***.\n    * `TRANGE` - an indicator used in technical analysis to measure the range of prices (from high to low) for ***Bitcoin*** during a specific time period.\n\n\n* ***Other cryptocurrencies:***\n    * `ape_avg_price` - the average price of ***APE*** during a specific time period.\n    * `bnb_avg_price` - the average price of ***BNB*** during a specific time period.\n    * `doge_avg_price` - the average price of ***DOGE coin*** during a specific time period.\n    * `eth_avg_price` - the average price of ***Ethereum*** during a specific time period.\n    * `xrp_avg_price` - the average price of ***XRP*** during a specific time period.\n    * `matic_avg_price` - the average price of ***MATIC*** during a specific time period.\n\n<hr>\n\n*The indicators `ADOSC`, `NATR`, and `TRANGE` are used in technical analysis to provide insights into the momentum, volatility, and price ranges of financial instruments or assets. The other attributes represent the average prices of different cryptocurrencies during a specific time period.*\n\n<hr>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7461b3a9-17bb-4276-a4ae-0883b13dbaa8",
      "metadata": {},
      "outputs": [],
      "source": [
        "### **What are the main characteristics that have the most impact on the average price of cryptocurrency?**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5fe709c-1465-4ec8-85f5-98505e664067",
      "metadata": {},
      "outputs": [],
      "source": [
        "## 1. Import Data from Module 2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a9922e21-a837-44bc-ba1c-7bf90b837a05",
      "metadata": {},
      "outputs": [],
      "source": [
        "<h4>Setup</h4>\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "94fddad5-a308-4227-bde3-e5022f19afc2",
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install pandas\n!pip install --upgrade pandas\n!pip install matplotlib\n!pip install scipy\n!pip install seaborn\n!pip install mplfinance\n!pip install xyzservices\n!pip install jupyter_bokeh\n!pip install astropy"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "65ef55b0-6939-47a6-915c-b34d252491ff",
      "metadata": {},
      "outputs": [],
      "source": [
        "Import libraries:\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "581b630c-4b9e-441f-aacd-c1f971a4c5ef",
      "metadata": {},
      "outputs": [],
      "source": [
        "import warnings\nimport itertools\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport mplfinance as fplt\nimport statsmodels.api as sm\n\nfrom astropy.visualization import astropy_mpl_style # \nfrom scipy import stats\nfrom statsmodels.stats.stattools import durbin_watson\nfrom statsmodels.tsa.stattools import grangercausalitytests\nfrom typing import List\n%matplotlib inline "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b54283a0-5c87-49f1-bbbb-c91903e730aa",
      "metadata": {},
      "outputs": [],
      "source": [
        "Specifying link to the dataset that we obtained in the previous lab."
      ]
    },
    {
      "cell_type": "code",
      "id": "72774458-cefd-4642-b4e9-0fb4768eb4ae",
      "metadata": {},
      "outputs": [],
      "source": [
        "data_path = 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-GPXX0YB4EN/BTCBUSD_1min.csv'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b840b8c-304a-4fb0-bb40-250d8b3c66c6",
      "metadata": {},
      "outputs": [],
      "source": [
        "Read dataframe from previous lab."
      ]
    },
    {
      "cell_type": "code",
      "id": "5718d3f9-6b17-4eea-b155-5283c2eb93af",
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv(data_path, index_col='ts')\n# converting index to datetime\ndf.index = pd.to_datetime(df.index)\ndf.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "42492b8c-c987-4443-9c0a-253e0f26c74a",
      "metadata": {},
      "outputs": [],
      "source": [
        "Initialize list of currencies which we have in our dataframe."
      ]
    },
    {
      "cell_type": "code",
      "id": "fcbc82e8-07b8-4f14-bcd3-868e21af0ff2",
      "metadata": {},
      "outputs": [],
      "source": [
        "currencies = ['ape', 'bnb','doge', 'eth', 'xrp', 'matic']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c4e40a9-c5a2-46f0-8a27-6462768be4c8",
      "metadata": {},
      "outputs": [],
      "source": [
        "We will use this list later on."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d3dc1e0-0071-42cd-97c8-107d8213b807",
      "metadata": {},
      "outputs": [],
      "source": [
        "## 2. Analyzing Individual Feature Patterns Using Visualization\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7af1509-bf2e-40b5-80a8-adabdf4c6df0",
      "metadata": {},
      "outputs": [],
      "source": [
        "For visualization, we will use 'Matplotlib', 'Seaborn', 'mplfinance', but you may use other tools. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "38e79dcf-4ddb-4472-a31b-3912fb28c3d7",
      "metadata": {},
      "outputs": [],
      "source": [
        "<h4>How to choose the right visualization method?</h4>\n<p>When visualizing individual variables, it is important to first understand what type of variable you are dealing with. This will help us find the right visualization method for that variable.</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "79955d06-c65a-4f64-9659-b087a5d1d422",
      "metadata": {},
      "outputs": [],
      "source": [
        "# list the data types for each column\nprint(df.dtypes)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "58e35800-46b9-4bd0-8dc5-f4ccf37b0e98",
      "metadata": {},
      "outputs": [],
      "source": [
        "<div class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\">\n  <b style=\"font-size: 2em; font-weight: bold;\">Question #1:</b>\n\n  <b>What is the data type of the column 'open'?</b>\n    \n</div>"
      ]
    },
    {
      "cell_type": "code",
      "id": "ede30913-7457-4827-9c8b-a75319b4b9ea",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Write your code below and press Shift+Enter to execute \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5199d0ae-cccc-44ab-b0ba-24bbf9d65eb6",
      "metadata": {},
      "outputs": [],
      "source": [
        "<details><summary>Click here for the solution</summary>\n\n```python\ndf['open'].dtypes\n```\n\n</details>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57fa0722-ac0d-4669-bd11-ccc58bee4be6",
      "metadata": {},
      "outputs": [],
      "source": [
        "For example, we can calculate the correlation between variables of type \"int64\" or \"float64\" using the method \"corr\"(for more information refer to https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.corr.html , also note that we explain correlation later in this notebook, so do not worry if it is not clear at the moment):\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "bf4e4bae-2ade-42f2-a1b0-bce4469b3134",
      "metadata": {},
      "outputs": [],
      "source": [
        "corr = df.corr()\ncorr"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72a9474f-95a6-4a01-9088-0492acf4cf6d",
      "metadata": {},
      "outputs": [],
      "source": [
        "Now to improve representation of correlation table we can use <code>heatmap</code> from 'Seaborn'."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "38e76154-c86f-4669-b987-42bfaf51bd36",
      "metadata": {},
      "outputs": [],
      "source": [
        "The diagonal elements are always one; we will study correlation more precisely Pearson correlation in-depth at the end of the notebook.\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "c8b429d2-68ee-4341-ba6a-3daeaa3f25d1",
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(20,20))\nsns.heatmap(corr, cmap='RdBu', vmin=-1, vmax=1, annot=True, ax=ax)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d62e28dd-e71e-416a-a71f-115b0f9607af",
      "metadata": {},
      "outputs": [],
      "source": [
        "<div class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\">\n<b style=\"font-size: 2em; font-weight: bold;\">Question #2:</b>\n\n<p>Find the correlation between the following columns: open, volume, rec_count, and avg_price.</p>\n<p>Hint: if you would like to select those columns, use the following syntax: df[['open', 'volume', 'rec_count', 'avg_price']]</p>\n</div>\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "ecad3ea5-c95d-42f7-92da-72c1c586bc87",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Write your code below and press Shift+Enter to execute \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f8ad0e2e-aae8-4af7-99c0-e51d9d704099",
      "metadata": {},
      "outputs": [],
      "source": [
        "<details><summary>Click here for the solution</summary>\n\n```python\ndf[['open', 'volume', 'rec_count', 'avg_price']].corr()\n```\n\n</details>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f65cf2e0-4ec7-4a3c-926e-da169a6a22d0",
      "metadata": {},
      "outputs": [],
      "source": [
        "Now let's calculate correlation only between our main currency and other cryptocurrencies."
      ]
    },
    {
      "cell_type": "code",
      "id": "3901d258-36c2-45ff-b879-4d59e243376b",
      "metadata": {},
      "outputs": [],
      "source": [
        "crypto_corr = df[['avg_price'] + [f'{name}_avg_price' for name in currencies]].corr()\ncrypto_corr"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64f28e5f-b87c-43dc-a36f-51a88033c42b",
      "metadata": {},
      "outputs": [],
      "source": [
        "Now let's build heatmap for above correlation."
      ]
    },
    {
      "cell_type": "code",
      "id": "46640eec-3e50-48b1-83f1-265af2051575",
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(10,10))\nsns.heatmap(crypto_corr, cmap='RdBu', vmin=-1, vmax=1, annot=True, ax=ax)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18bcbb3d-f40b-4f53-aa38-1c9dfb6027e0",
      "metadata": {},
      "outputs": [],
      "source": [
        "### Continuous Numerical Variables:\n\nContinuous numerical variables are variables that may contain any value within some range. They can be of type `int64` or `float64`. A great way to visualize these variables is by using scatterplots with fitted lines.\n\nIn order to start understanding the (linear) relationship between an individual variable and the price, we can use `regplot` which plots the scatterplot plus the fitted regression line for the data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "371d5cf6-ac04-4052-b3fa-1c3ceb69aa7e",
      "metadata": {},
      "outputs": [],
      "source": [
        "Let's see several examples of different linear relationships:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "73c48651-011d-4da7-99ea-2ac8e19331a1",
      "metadata": {},
      "outputs": [],
      "source": [
        "#### Linear Relationships\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d43401b4-b479-4653-896a-071741a47957",
      "metadata": {},
      "outputs": [],
      "source": [
        "Let's find the scatterplot of 'avg_price' and 'matic_avg_price'.\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "f69f1911-908f-417e-8b1a-22f73712d948",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Engine size as potential predictor variable of price\nsns.regplot(x='avg_price', y='eth_avg_price', data=df)\nplt.ylim(0,)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "edbb5b1a-a508-4086-a349-6ad8582ba3a6",
      "metadata": {},
      "outputs": [],
      "source": [
        "<p>As the eth_avg_price goes up, the avg_price goes up as well: this indicates a positive direct correlation between these two variables. eth_avg_price size seems like a pretty good predictor of avg_price since dots fit our line really well.</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b25b744-bb28-4663-8142-39e51aad845e",
      "metadata": {},
      "outputs": [],
      "source": [
        "We can examine the correlation between 'avg_price' and 'eth_avg_price' and see that it's approximately 0.90.\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "e45f6a0e-4279-4fc4-a2ed-3a80ee5a39d5",
      "metadata": {},
      "outputs": [],
      "source": [
        "df[['avg_price', 'eth_avg_price']].corr()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7cbf5c62-970e-4ce6-8166-c4e991edd829",
      "metadata": {},
      "outputs": [],
      "source": [
        "matic_avg_price is a potential predictor of avg_price. Let's find the scatterplot of 'avg_price' and 'matic_avg_price'.\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "053017bc-5734-430e-8840-89b38778cfc2",
      "metadata": {},
      "outputs": [],
      "source": [
        "sns.regplot(x='avg_price', y='matic_avg_price', data=df)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a53d3b91-4cad-4627-bd4c-6418a9aba8b7",
      "metadata": {},
      "outputs": [],
      "source": [
        "<p>As matic_avg_price goes up, the avg_price goes up: this indicates an positive relationship between these two variables. matic_avg_price could potentially be a predictor of avg_price.</p> \n\n<p>It is good to understand that sometimes we may have an inverse/negative relationship between these two variables. Example: matic_avg_price going up, the avg_price going down. Such relationship could be a potential predictor as well.</p>\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5aa2b3c7-1e42-4151-93ce-d1e03db3da69",
      "metadata": {},
      "outputs": [],
      "source": [
        "We can examine the correlation between 'avg_price' and 'bnb_avg_price'and see it's approximately 0.80.\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "8cac9691-1bde-49ba-bfd2-7b0233021375",
      "metadata": {},
      "outputs": [],
      "source": [
        "df[['avg_price', 'matic_avg_price']].corr()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "374cdfb4-6392-4dff-94f9-16da7fff8a14",
      "metadata": {},
      "outputs": [],
      "source": [
        "Let's see if \"ape_avg_price\" is a predictor variable of \"avg_price\".\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "f0703b7a-f5d7-4900-9951-2c346486e637",
      "metadata": {},
      "outputs": [],
      "source": [
        "# change\nsns.regplot(x='ape_avg_price', y='avg_price', data=df)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5b0ef2c-ba91-41eb-bcb2-2e0e83a1ec0c",
      "metadata": {},
      "outputs": [],
      "source": [
        "<p>ape_avg_price does not seem like a good predictor of the avg_price at all since the regression line is close to horizontal. Also, the data points are very scattered and far from the fitted line, showing lots of variability. Therefore, it's not a reliable variable.</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e17a004e-c27a-488e-9eee-476ef4084b9c",
      "metadata": {},
      "outputs": [],
      "source": [
        "We can examine the correlation between 'ape_avg_price' and 'avg_price' and see it's approximately -0.032.\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "c328cedf-5be8-4252-8314-f14a445b718b",
      "metadata": {},
      "outputs": [],
      "source": [
        "df[['avg_price', 'ape_avg_price']].corr()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "326718b2-da98-45ca-a12e-cc53101c3165",
      "metadata": {},
      "outputs": [],
      "source": [
        "<div class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\">\n<b style=\"font-size: 2em; font-weight: bold;\">Question  3 a):</b>\n\n<p>Find the correlation  between 'xrp_avg_price' and 'bnb_avg_price'.</p>\n<p>Hint: if you would like to select those columns, use the following syntax: df[['xrp_avg_price', 'bnb_avg_price']].  </p>\n</div>\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "49d7c379-84ec-4eec-a079-efed1017eed3",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Write your code below and press Shift+Enter to execute\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1a9adecc-ab76-4987-af60-ea94c781f5db",
      "metadata": {},
      "outputs": [],
      "source": [
        "<details><summary>Click here for the solution</summary>\n\n```python\n\n#The correlation is 0.0823, the non-diagonal elements of the table.\n\ndf[['xrp_avg_price', 'bnb_avg_price']].corr()\n\n```\n\n</details>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "038f8f52-0313-4119-9fd8-5ea8581b0015",
      "metadata": {},
      "outputs": [],
      "source": [
        "<div class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\">\n<b style=\"font-size: 2em; font-weight: bold;\">Question  3 b):</b>\n\n<p>Given the correlation results between 'xrp_avg_price' and 'bnb_avg_price', do you expect a linear relationship?</p> \n<p>Verify your results using the function \"regplot()\".</p>\n</div>\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "fe8b97c4-f3ba-48e7-84fb-c3559f770b0f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Write your code below and press Shift+Enter to execute \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9183657-4a19-449e-bd18-d1b44d1210d1",
      "metadata": {},
      "outputs": [],
      "source": [
        "<details><summary>Click here for the solution</summary>\n\n```python\n\n#There is a weak correlation between the variable 'stroke' and 'price.' as such regression will not work well. We can see this using \"regplot\" to demonstrate this.\n\n#Code: \nsns.regplot(x='xrp_avg_price',  y='bnb_avg_price', data=df)\n\n```\n\n</details>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "60035337-7d70-40ee-a571-9bf036ee8d7e",
      "metadata": {},
      "outputs": [],
      "source": [
        "Now let's visualize values of our main cryptocurrency."
      ]
    },
    {
      "cell_type": "code",
      "id": "8f868682-be67-4753-aadd-0099d85f0ecc",
      "metadata": {},
      "outputs": [],
      "source": [
        "df[['open', 'high', 'low', 'close']].plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cfa39da6-0462-4c25-bdc4-1665fba591a8",
      "metadata": {},
      "outputs": [],
      "source": [
        "As you can see it is not convinient to make any assumptions from the above visualization, so let's draw candlesticks using <code>fplt</code>.\n\nWe are going to use slice of data from our dataframe. Note: you can customize style of plot, just pick any value for style from <code>['binance', 'blueskies', 'brasil', 'charles', 'checkers', 'classic', 'default', 'ibd', 'kenan', 'mike', 'nightclouds', 'sas', 'starsandstripes', 'yahoo']</code>"
      ]
    },
    {
      "cell_type": "code",
      "id": "c2da0629-def2-49af-8806-c22062b5c75b",
      "metadata": {},
      "outputs": [],
      "source": [
        "fplt.plot(\n            df.iloc[:10, :],\n            type='candle',\n            style='charles',\n            title='BTC',\n            ylabel='Price (BUSD)'\n        )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db18c5ac-7f7b-4dc0-8142-182a74233541",
      "metadata": {},
      "outputs": [],
      "source": [
        "Now let's plot candlesticks with volume; expanding our slice from 10 to 20 values."
      ]
    },
    {
      "cell_type": "code",
      "id": "25f48087-9f62-43ef-a272-7a88d75d069d",
      "metadata": {},
      "outputs": [],
      "source": [
        "fplt.plot(\n            df.iloc[:20, :],\n            type='candle',\n            style='classic',\n            title='BTC',\n            ylabel='Price (BUSD)',\n            volume=True,\n            ylabel_lower='Volume',\n        )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c52ee5b-9c60-4790-ab09-687e68b84c0a",
      "metadata": {},
      "outputs": [],
      "source": [
        "You can also use plotly or bqplot to display even more data, but we won't cover this here, because such things is a topic of another course."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0dd38d99-6204-4c56-b974-958f0803ba21",
      "metadata": {},
      "outputs": [],
      "source": [
        "Great! Now we know how to display a lot of candlesticks in one plot and we can save the plot as image."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9ce9468-97b0-4359-b0de-3ae55858f345",
      "metadata": {},
      "outputs": [],
      "source": [
        "#### Categorical Variables\n\nLet's create bins for all currencies inside out `dataFrame`.\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "e3cb0836-d07e-4b24-8433-21c6feae6ef3",
      "metadata": {},
      "outputs": [],
      "source": [
        "group_names = ['low', 'medium-low', 'medium', 'medium-high', 'high']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3fcd208c-592a-4ee4-b22d-b241a3878e7f",
      "metadata": {},
      "outputs": [],
      "source": [
        "Function that converts column of values to column of bins."
      ]
    },
    {
      "cell_type": "code",
      "id": "226007b7-dd09-4f2b-b2fd-b5db3b521d5d",
      "metadata": {},
      "outputs": [],
      "source": [
        "def to_categorical(column: pd.Series, labels: List[str]) -> pd.Series:\n    bins = np.linspace(min(column), max(column), len(labels) + 1)\n    res = pd.cut(column, bins, labels=labels, include_lowest=True)\n    return res"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff075e58-b263-4f45-bc9d-f6c67dec8b6b",
      "metadata": {},
      "outputs": [],
      "source": [
        "Create 'category' column that is created from 'avg_price' of our main cryptocurrency."
      ]
    },
    {
      "cell_type": "code",
      "id": "0efb1f75-f004-4176-b25a-828f22802a72",
      "metadata": {},
      "outputs": [],
      "source": [
        "df['category'] = to_categorical(df['avg_price'], group_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3836ccda-bf59-4967-ad43-7d772b8b9c1b",
      "metadata": {},
      "outputs": [],
      "source": [
        "Now let's use <code>unique()</code> command to see categories we have created."
      ]
    },
    {
      "cell_type": "code",
      "id": "19973430-f265-494d-b741-016c793bb3aa",
      "metadata": {},
      "outputs": [],
      "source": [
        "df['category'].unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db922c2d-4de3-4812-a754-962cac02d829",
      "metadata": {},
      "outputs": [],
      "source": [
        "Now let's do the same with other cryptocurrecies"
      ]
    },
    {
      "cell_type": "code",
      "id": "5c50068a-9286-4653-8dcb-861fb07c3aea",
      "metadata": {},
      "outputs": [],
      "source": [
        "for name in currencies:\n    category_column_name = f'{name}_category'\n    df[category_column_name] = to_categorical(df[f'{name}_avg_price'], group_names)"
      ]
    },
    {
      "cell_type": "code",
      "id": "05daf876-6361-4f95-9807-9a5b956f6931",
      "metadata": {},
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0d0ef81-4946-4a55-bd00-e84c642b89cf",
      "metadata": {},
      "outputs": [],
      "source": [
        "## 3. Descriptive Statistical Analysis\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae053ff1-7ea7-4048-b75b-f4fe27cb6880",
      "metadata": {},
      "outputs": [],
      "source": [
        "<p>Let's first take a look at the variables by utilizing a description method.</p>\n\n<p>The <b>describe</b> function automatically computes basic statistics for all continuous variables. We do not have NaN values in our dataframe, but it is worth mentioning that any NaN values are automatically skipped in these statistics.</p>\n\nThis will show:\n\n<ul>\n    <li>the count of that variable</li>\n    <li>the mean</li>\n    <li>the standard deviation (std)</li> \n    <li>the minimum value</li>\n    <li>the IQR (Interquartile Range: 25%, 50% and 75%)</li>\n    <li>the maximum value</li>\n<ul>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec4b21a7-b3a5-460e-ab0f-6972b311feb6",
      "metadata": {},
      "outputs": [],
      "source": [
        "We can apply the method \"describe\" as follows:\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "d1bc18f3-d8af-4be7-9441-6935d15c12cd",
      "metadata": {},
      "outputs": [],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45d04709-40ea-46ac-b4b2-35ce6dd9d54e",
      "metadata": {},
      "outputs": [],
      "source": [
        "The default setting of \"describe\" skips variables of type category. We can apply the method \"describe\" on the variables of type 'category' as follows:\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "277f03fe-3bd3-4755-8122-3efe1e822d5d",
      "metadata": {},
      "outputs": [],
      "source": [
        "df.describe(include=['category'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed2b4f0a-1def-4472-97bd-a0d16b5a0424",
      "metadata": {},
      "outputs": [],
      "source": [
        "#### Value Counts\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e857cf1e-16a3-4995-989d-12ff4e8c4504",
      "metadata": {},
      "outputs": [],
      "source": [
        "<p>Value counts is a good way of understanding how many units of each characteristic/variable we have. We can apply the \"value_counts\" method on the column \"drive-wheels\". Donâ€™t forget the method 'category' only works on pandas series, not pandas dataframes. As a result, we only include one bracket <code>df['category']</code>, not two brackets <code>df[['category']]</code>.</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "fab8bcfe-34a3-4b86-a1a6-56f44f6d8225",
      "metadata": {},
      "outputs": [],
      "source": [
        "df['category'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "502995a6-ae29-43a8-99aa-6286f7dbb59f",
      "metadata": {},
      "outputs": [],
      "source": [
        "We can convert the series to a dataframe as follows:\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "2fda6c90-90ae-48b1-82a3-1968defb37ab",
      "metadata": {},
      "outputs": [],
      "source": [
        "category_counts = df['category'].value_counts().to_frame()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "73676de5-064a-430f-99be-e5985c729fe5",
      "metadata": {},
      "outputs": [],
      "source": [
        "Let's repeat the above steps but save the results to the dataframe 'category_counts' and rename the column  'category' to 'category_value_counts'.\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "8d491808-afc3-4036-b3d2-fe25e5b4b090",
      "metadata": {},
      "outputs": [],
      "source": [
        "category_counts.rename(columns={'category': 'category_value_counts'}, inplace=True)\ncategory_counts.index.name = 'categories'\ncategory_counts"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "161a8a3e-b996-4d70-b072-ffcf32601e2c",
      "metadata": {},
      "outputs": [],
      "source": [
        "Now let's add other currencies into category_counts dataframe:\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "15798c1b-cd36-41dd-bb20-c3a532f9aad1",
      "metadata": {},
      "outputs": [],
      "source": [
        "all_category_counts = category_counts.copy()\n\nfor name in currencies:\n    category_column_name = f'{name}_category'\n    curr_counts = df[category_column_name].value_counts().to_frame()\n    curr_counts.rename(columns={category_column_name: f'{category_column_name}_value_counts'}, inplace=True)\n    curr_counts.index.name = 'categories'\n    # add new column to all_category_counts\n    all_category_counts = all_category_counts.merge(curr_counts, on='categories')\n    "
      ]
    },
    {
      "cell_type": "code",
      "id": "392a896c-c0ce-454e-8063-94239ae73bfb",
      "metadata": {},
      "outputs": [],
      "source": [
        "all_category_counts"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a4e9cd4f-1652-4c10-8f52-3a99013c0ffc",
      "metadata": {},
      "outputs": [],
      "source": [
        "## 4. Basics of Grouping\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de55c65f-d497-4b07-ae02-2e6c5df3d14d",
      "metadata": {},
      "outputs": [],
      "source": [
        "<p>The \"groupby\" method groups data by different categories. The data is grouped based on one or several variables, and analysis is performed on the individual groups.</p>\n\n<p>For example, let's group by the variable \"category\".</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "daa48c93-b416-47a6-be3a-7ab556d4c4a3",
      "metadata": {},
      "outputs": [],
      "source": [
        "df['category'].unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93e21569-d041-4c45-8efd-721526ddb5f6",
      "metadata": {},
      "outputs": [],
      "source": [
        "<p>If we want to know, on average, which type of drive wheel is most valuable, we can group 'category' and then average them.</p>\n\n<p>We can select the columns 'category', and 'avg_price', then assign it to the variable \"df_group_one\".</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "e31ed85a-b2a6-48ac-bc23-0f636d0254fb",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_group_one = df[['avg_price','category']]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2225ec92-c162-4b36-8f16-452b15ae96c7",
      "metadata": {},
      "outputs": [],
      "source": [
        "We can then calculate the average price for each of the different categories of data.\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "360f767f-2d97-4e1a-ac0a-004640ea730a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# grouping results\ndf_group_one = df_group_one.groupby(['category'],as_index=False).mean()\ndf_group_one"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e4cb68e-1e74-4656-8c67-c3ad487cdbaf",
      "metadata": {},
      "outputs": [],
      "source": [
        "<p>You can also group by multiple variables. For example, let's group by both 'category' and 'ape_category'. This groups the dataframe by the unique combination of 'category' and 'ape_category'. We can store the results in the variable 'grouped_test1'.</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "e34e0537-e480-4588-a315-38f021e307c0",
      "metadata": {},
      "outputs": [],
      "source": [
        "# grouping results\ndf_gptest = df[['avg_price', 'category','ape_category']]\ngrouped_test1 = df_gptest.groupby(['category', 'ape_category'],as_index=False).mean()\ngrouped_test1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5713088c-5568-4445-a0e0-9df5f207b87e",
      "metadata": {},
      "outputs": [],
      "source": [
        "<p>This grouped data is much easier to visualize when it is made into a pivot table. A pivot table is like an Excel spreadsheet, with one variable along the column and another along the row. We can convert the dataframe to a pivot table using the method \"pivot\" to create a pivot table from the groups.</p>\n\n<p>In this case, we will leave the category variable as the rows of the table, and pivot avg_price to become the columns of the table:</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "eef6f9af-d0cb-43cb-a261-799ad84ec573",
      "metadata": {},
      "outputs": [],
      "source": [
        "grouped_pivot = grouped_test1.pivot(index='category',columns='ape_category')\ngrouped_pivot"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f370c90-a462-4ecc-b7c7-ae2577c1706f",
      "metadata": {},
      "outputs": [],
      "source": [
        "<p>Often, we won't have data for some of the pivot cells. We can fill these missing cells with the value 0, but any other value could potentially be used as well. It should be mentioned that missing data is quite a complex subject and is an entire course on its own.</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "14b00283-6efa-41e9-bc63-a43013e7b4a6",
      "metadata": {},
      "outputs": [],
      "source": [
        "grouped_pivot = grouped_pivot.fillna(0) #fill missing values with 0\ngrouped_pivot"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f18ceb0-d9d4-40b6-b142-17e68a64d2f9",
      "metadata": {},
      "outputs": [],
      "source": [
        "<div class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\">\n<b style=\"font-size: 2em; font-weight: bold;\">Question 4:</b>\n    \n<p>Use the \"groupby\" function to find the average price of each car based on \"category\".</p>\n</div>\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "1e4e3d43-74e0-48f1-bcbf-bed77d62a4d3",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Write your code below and press Shift+Enter to execute \n# grouping results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85d963dc-145d-4c7e-9fe0-248d1936eee1",
      "metadata": {},
      "outputs": [],
      "source": [
        "<details><summary>Click here for the solution</summary>\n\n```python\n# grouping results\ndf_gptest2 = df[['category','avg_price']]\ngrouped_test_bodystyle = df_gptest2.groupby(['category'],as_index= False).mean()\ngrouped_test_bodystyle\n\n```\n\n</details>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b69031cb-c553-45b2-bf3a-e2d3165f0ed2",
      "metadata": {},
      "outputs": [],
      "source": [
        "Let's use a heat map to visualize the relationship between avg_price vs btc_category.\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "80d6aa01-ac1f-465d-bac2-d97de1a04994",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Astropy should not be here\n# from astropy.visualization import astropy_mpl_style\nastropy_mpl_style['axes.grid'] = False\nplt.style.use(astropy_mpl_style)"
      ]
    },
    {
      "cell_type": "code",
      "id": "f95d15f9-8812-411f-87c8-b982297c62a4",
      "metadata": {},
      "outputs": [],
      "source": [
        "#use the grouped\nplt.pcolor(grouped_pivot, cmap='RdBu')\nplt.colorbar()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "113e91fb-5a4e-436b-9a8b-06de138edbf2",
      "metadata": {},
      "outputs": [],
      "source": [
        "<p>The heatmap plots the target variable (price) proportional to colour with respect to the variables 'ape_category' and 'avg_price' on the vertical and horizontal axis, respectively. This allows us to visualize how the price is related to 'ape_category' and 'avg_price'.</p>\n\n<p>The default labels convey no useful information to us. Let's change that:</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "add97e52-cf7f-4815-932a-2e68b238f41f",
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots()\nim = ax.pcolor(grouped_pivot, cmap='RdBu')\n\n#label names\nrow_labels = grouped_pivot.columns.levels[1]\ncol_labels = grouped_pivot.index\n\n#move ticks and labels to the center\nax.set_xticks(np.arange(grouped_pivot.shape[1]) + 0.5, minor=False)\nax.set_yticks(np.arange(grouped_pivot.shape[0]) + 0.5, minor=False)\n\n#insert labels\nax.set_xticklabels(row_labels, minor=False)\nax.set_yticklabels(col_labels, minor=False)\n\n#rotate label if too long\nplt.xticks(rotation=90)\n\nfig.colorbar(im)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b2b3b75-7953-4214-9a45-ec50a82ec097",
      "metadata": {},
      "outputs": [],
      "source": [
        "<p>Visualization is very important in data science, and Python visualization packages provide great freedom. We will go more in-depth in a separate Python visualizations course.</p>\n\n<p>The main question we want to answer in this module is, \"Which other cryptocurrencies have the greatest impact on the average price of our cryptocurrency?\".</p>\n\n<p>To get a better measure of the important characteristics, we look at the correlation of our currency with other cryptocurrencies. In other words: how is the avarege price dependent on other average price variables?</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c177875-7c75-4986-9709-ba5019e48796",
      "metadata": {},
      "outputs": [],
      "source": [
        "## 5. Correlation and Causation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb7ab171-a5e7-4559-b82d-8f556ef25425",
      "metadata": {},
      "outputs": [],
      "source": [
        "<p><b>Correlation</b>: a measure of the extent of interdependence between variables.</p>\n\n<p><b>Causation</b>: the relationship between cause and effect between two variables.</p>\n\n<p>It is important to know the difference between these two. Correlation does not imply causation. Determining correlation is much simpler  the determining causation as causation may require independent experimentation.</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb656093-c014-4747-ac72-026a6d661144",
      "metadata": {},
      "outputs": [],
      "source": [
        "<p><b>Pearson Correlation</b></p>\n<p>The Pearson Correlation measures the linear dependence between two variables X and Y.</p>\n<p>The resulting coefficient is a value between -1 and 1 inclusive, where:</p>\n<ul>\n    <li><b>1</b>: Perfect positive linear correlation.</li>\n    <li><b>0</b>: No linear correlation, the two variables most likely do not affect each other.</li>\n    <li><b>-1</b>: Perfect negative linear correlation.</li>\n</ul>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10adaf38-68d8-4269-a53d-5da6179753e9",
      "metadata": {},
      "outputs": [],
      "source": [
        "<p>Pearson Correlation is the default method of the function \"corr\". Like before, we can calculate the Pearson Correlation of the of the 'int64' or 'float64'  variables.</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "2484bd7b-dac6-4b56-b0d7-3f7c002619ff",
      "metadata": {},
      "outputs": [],
      "source": [
        "df.corr()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "714a1eb2-9796-4956-961a-fde519cf12bf",
      "metadata": {},
      "outputs": [],
      "source": [
        "Sometimes we would like to know the significant of the correlation estimate.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08a96194-f5c3-4d88-b2fd-48bd78c60020",
      "metadata": {},
      "outputs": [],
      "source": [
        "<b>P-value</b>\n\n<p>What is this P-value? The P-value is the probability value that the correlation between these two variables is statistically significant. Normally, we choose a significance level of 0.05, which means that we are 95% confident that the correlation between the variables is significant.</p>\n\nBy convention, when the\n\n<ul>\n    <li>p-value is $<$ 0.001: we say there is strong evidence that the correlation is significant.</li>\n    <li>the p-value is $<$ 0.05: there is moderate evidence that the correlation is significant.</li>\n    <li>the p-value is $<$ 0.1: there is weak evidence that the correlation is significant.</li>\n    <li>the p-value is $>$ 0.1: there is no evidence that the correlation is significant.</li>\n</ul>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2fe64cd0-f930-4b0f-bcc7-e43304f04290",
      "metadata": {},
      "outputs": [],
      "source": [
        "We can obtain this information using  \"stats\" module in the \"scipy\"  library.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2241aa81-f5b2-4646-ad66-7ccbb89b65dd",
      "metadata": {},
      "outputs": [],
      "source": [
        "### APE average price vs BTC average price\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a05b7dec-cb2e-4b91-8f9a-385ea8e2f07f",
      "metadata": {},
      "outputs": [],
      "source": [
        "Let's calculate the  Pearson Correlation Coefficient and P-value of 'ape_avg_price' and 'avg_price'.\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "8e6dc79b-fe56-474b-bb0e-3e43116f9c2e",
      "metadata": {},
      "outputs": [],
      "source": [
        "pearson_coef, p_value = stats.pearsonr(df['ape_avg_price'], df['avg_price'])\nprint(f'The Pearson Correlation Coefficient is {pearson_coef:.5f} with a P-value of P = {p_value}')  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d250672b-b023-4eff-894e-aab943f6815a",
      "metadata": {},
      "outputs": [],
      "source": [
        "<h4>Conclusion:</h4>\n<p>Since the p-value is $<$ 0.001, the correlation between ape_avg_price and avg_price is statistically significant, although the linear relationship isn't extremely strong (~0.580).</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "302beae5-d373-4c4d-a45b-f2299a381c94",
      "metadata": {},
      "outputs": [],
      "source": [
        "Similarly to the above let's calculate Pearson Correlation Coefficient and P-value between our main cryptocurrency and other cryptocurrencies"
      ]
    },
    {
      "cell_type": "code",
      "id": "25266c06-baa4-486f-bb1d-92ed9cc82cee",
      "metadata": {},
      "outputs": [],
      "source": [
        "for name in currencies:\n    pearson_coef, p_value = stats.pearsonr(df['avg_price'], df[f'{name}_avg_price'])\n    print(f'The Pearson Correlation Coefficient between our main cryptocurrency and {name} is {pearson_coef:.6f} with a P-value of P = {p_value:.5f}') "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "92ae0a13-2ba2-4763-b0df-5d1b0d74b7ab",
      "metadata": {},
      "outputs": [],
      "source": [
        "From the rules and conclusions represented above, you can easily draw your own conclusions for all values we calculated. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40f36c5e-2322-4faa-bba1-321ae3f4333e",
      "metadata": {},
      "outputs": [],
      "source": [
        "## 6. ANOVA\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c4f88348-5e4e-4822-863d-e78e58357ee5",
      "metadata": {},
      "outputs": [],
      "source": [
        "### ANOVA: Analysis of Variance\n\nThe Analysis of Variance  (ANOVA) is a statistical method used to test whether there are significant differences between the means of two or more groups. ANOVA returns two parameters:\n\n**F-test score**: ANOVA assumes the means of all groups are the same, calculates how much the actual means deviate from the assumption, and reports it as the F-test score. A larger score means there is a larger difference between the means.\n\n**P-value**:  P-value tells how statistically significant our calculated score value is.\n\nIf our price variable is strongly correlated with the variable we are analyzing, we expect ANOVA to return a sizeable F-test score and a small p-value.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "65e206eb-334c-4542-a882-b36079bdc893",
      "metadata": {},
      "outputs": [],
      "source": [
        "### Category\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15d78945-1b1c-4ce6-9120-dd10376f45c6",
      "metadata": {},
      "outputs": [],
      "source": [
        "<p>Since ANOVA analyzes the difference between different groups of the same variable, the groupby function will come in handy. Because the ANOVA algorithm averages the data automatically, we do not need to take the average before hand.</p>"
      ]
    },
    {
      "cell_type": "code",
      "id": "1b574933-7944-4fbb-9e02-826b5e084b5b",
      "metadata": {},
      "outputs": [],
      "source": [
        "grouped_test2=df_gptest[['avg_price', 'category']].groupby(['category'])\ngrouped_test2.head(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc936738-9af0-4ac0-9a1a-ed4d6e0b957d",
      "metadata": {},
      "outputs": [],
      "source": [
        "We can obtain the values of the method group using the method \"get_group\".\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "0074b87e-8de8-45eb-9018-d36b7e32b54f",
      "metadata": {},
      "outputs": [],
      "source": [
        "grouped_test2.get_group('high')['avg_price']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76aced53-887c-4de9-949f-1dcac528bc2f",
      "metadata": {},
      "outputs": [],
      "source": [
        "We can use the function 'f_oneway' in the module 'stats' to obtain the <b>F-test score</b> and <b>P-value</b>.\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "1928f24c-dd13-4535-b7df-8d7f6e593fd0",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ANOVA\nf_val, p_val = stats.f_oneway(grouped_test2.get_group('low')['avg_price'], grouped_test2.get_group('medium-low')['avg_price'], grouped_test2.get_group('medium')['avg_price'], grouped_test2.get_group('medium-high')['avg_price'], grouped_test2.get_group('high')['avg_price'])  \n \nprint( \"ANOVA results: F=\", f_val, \", P =\", p_val)   "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2de710d7-4f48-4059-bfb5-1e55165dcc24",
      "metadata": {},
      "outputs": [],
      "source": [
        "This is a great result with a large F-test score showing a strong correlation and a P-value of almost 0 implying almost certain statistical significance. But does this mean all five tested groups are all this highly correlated?\n\nLet's examine them separately.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "46d52b36-2ff3-415f-91fd-9fc8f86caaad",
      "metadata": {},
      "outputs": [],
      "source": [
        "#### medium-low and medium\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "d75c5910-5aad-4f2c-aefe-96f770230c6f",
      "metadata": {},
      "outputs": [],
      "source": [
        "f_val, p_val = stats.f_oneway(grouped_test2.get_group('medium-low')['avg_price'], grouped_test2.get_group('medium')['avg_price'])  \n \nprint( \"ANOVA results: F=\", f_val, \", P =\", p_val )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bdc4c27b-0f7a-42ed-a601-2a4d333c0f42",
      "metadata": {},
      "outputs": [],
      "source": [
        "Let's examine the other groups.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d110422-4f4f-4234-962c-b832df12af0c",
      "metadata": {},
      "outputs": [],
      "source": [
        "#### medium and medium-high\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "ac60bf64-2cac-40e2-b4c1-fec89f16e115",
      "metadata": {},
      "outputs": [],
      "source": [
        "f_val, p_val = stats.f_oneway(grouped_test2.get_group('medium')['avg_price'], grouped_test2.get_group('medium-high')['avg_price'])  \n   \nprint( \"ANOVA results: F=\", f_val, \", P =\", p_val)   "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed2fc976-d0b9-4be6-9eb8-31e4c9813db3",
      "metadata": {},
      "outputs": [],
      "source": [
        "Let's create a for loop and calculate ANOVA for every pair"
      ]
    },
    {
      "cell_type": "code",
      "id": "28179dfd-8609-480d-9ec2-58b6b4d2bbda",
      "metadata": {},
      "outputs": [],
      "source": [
        "# make sure you created group_names in previous steps\nnames = group_names.copy()\n# generating column and row names for our future dataframe\ncols = [f\"{name}_x\" for name in names]\nidxs = [f\"{name}_y\" for name in names]\n\nanova_f_df = pd.DataFrame(columns=cols, index=idxs)\nanova_p_df = pd.DataFrame(columns=cols, index=idxs)\n\nfor (curr1, curr2) in itertools.permutations(names, 2):\n    f_val, p_val = stats.f_oneway(grouped_test2.get_group(curr1)['avg_price'], grouped_test2.get_group(curr2)['avg_price'])  \n    anova_f_df.loc[f\"{curr2}_y\", f\"{curr1}_x\"] = f_val\n    anova_p_df.loc[f\"{curr2}_y\", f\"{curr1}_x\"] = p_val"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fbc6896c-fc62-4c89-9556-b89909807ae9",
      "metadata": {},
      "outputs": [],
      "source": [
        "Now let's display f and p value dataframes"
      ]
    },
    {
      "cell_type": "code",
      "id": "096d3245-10fb-47ab-81c2-f90c7f9a942c",
      "metadata": {},
      "outputs": [],
      "source": [
        "anova_f_df"
      ]
    },
    {
      "cell_type": "code",
      "id": "2c1daecc-4b08-4465-85a9-38a806bbefd1",
      "metadata": {},
      "outputs": [],
      "source": [
        "anova_p_df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1f9d9a9-c0bf-40dc-af1c-e555729d3c28",
      "metadata": {},
      "outputs": [],
      "source": [
        "Result dataframes have NaN values; diagonal elements always going to be NaN(we are not supposed to calculate them). So let's replace them with space character."
      ]
    },
    {
      "cell_type": "code",
      "id": "006fc8d3-5738-45fc-a516-569554736d78",
      "metadata": {},
      "outputs": [],
      "source": [
        "np.fill_diagonal(anova_f_df.values, ' ')\nnp.fill_diagonal(anova_p_df.values, ' ')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c1fa117e-79d3-47b5-a811-4c01b5fb35ce",
      "metadata": {},
      "outputs": [],
      "source": [
        "And display one of f value and p value dataframes one more time."
      ]
    },
    {
      "cell_type": "code",
      "id": "c496623a-1288-4b66-b24d-52a2e63c4445",
      "metadata": {},
      "outputs": [],
      "source": [
        "anova_f_df  "
      ]
    },
    {
      "cell_type": "code",
      "id": "4627be88-fc4c-4283-bb37-33690555c2dc",
      "metadata": {},
      "outputs": [],
      "source": [
        "anova_p_df  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52c94749-5b30-4407-9c96-f6914ed2eb14",
      "metadata": {},
      "outputs": [],
      "source": [
        "## 7. Durbin-Watson Test"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd851d8d-0cf4-417d-b269-52570c02c804",
      "metadata": {},
      "outputs": [],
      "source": [
        "What is Durbin-Watson Test?\nIn regression analysis, Durbin-Watson (DW) is useful for checking the first-order autocorrelation (serial correlation). It analyzes the residuals for independence over time points (autocorrelation). The autocorrelation varies from -1 (negative autocorrelation) to 1 (positive autocorrelation).\n\nDurbin-Watson test analyzes the following hypotheses,\n\nNull hypothesis (H0): Residuals from the regression are not autocorrelated (autocorrelation coefficient, Ï = 0) Alternative hypothesis (Ha): Residuals from the regression are autocorrelated (autocorrelation coefficient, Ï > 0)\n\nWe will use durbin_watson for Durbin-Watson Test and OLS to get residuals from \"statsmodels\" library"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1edbb8f-123b-44ca-bdbc-649c55ee1fa8",
      "metadata": {},
      "outputs": [],
      "source": [
        "Let's implement a function that creates regression models"
      ]
    },
    {
      "cell_type": "code",
      "id": "3bd2f146-5530-4d0f-a9c7-19994c24c00d",
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_reg(x: pd.DataFrame, y: pd.Series):\n    # to get intercept\n    X = sm.add_constant(x)\n    # fit the regression model\n    reg = sm.OLS(y, X).fit()\n    return reg"
      ]
    },
    {
      "cell_type": "code",
      "id": "ecb76e83-e83b-4934-8f42-2b64b1dd37f6",
      "metadata": {},
      "outputs": [],
      "source": [
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\nX = df[[\"ape_avg_price\"]] # independent\ny = df[\"avg_price\"] # dependent\nreg = get_reg(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "id": "99436107-567c-4dc0-839f-f5229ebb194b",
      "metadata": {},
      "outputs": [],
      "source": [
        "durbin_watson(resids=np.array(reg.resid))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "92dc9721-ce0f-4788-8f9d-7caf5393f6fc",
      "metadata": {},
      "outputs": [],
      "source": [
        "Durbin-Watson test statistic is 0.0014, which is very close to 0. This suggests the presence of strong positive autocorrelation in the residuals of our regression model."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf9f8529-16ee-4043-b5fe-d3d4da3986de",
      "metadata": {},
      "outputs": [],
      "source": [
        "Now that we now how to calculate Durbin-Watson we can evaluate Durbin-Watson between main and other currencies."
      ]
    },
    {
      "cell_type": "code",
      "id": "80724eba-d07f-4238-a34b-cc06e798dbc6",
      "metadata": {},
      "outputs": [],
      "source": [
        "# define names that corresponds to names of all cryptocurrecies differnt from main.\nnames = [name for name in currencies]"
      ]
    },
    {
      "cell_type": "code",
      "id": "ab608162-f3d4-4334-9bc8-803e07d3c3d5",
      "metadata": {},
      "outputs": [],
      "source": [
        "for name in names:\n    X = df[[f\"avg_price\"]] # independent\n    y = df[f\"{name}_avg_price\"] # dependent\n    reg = get_reg(X, y)\n    dw = durbin_watson(resids=np.array(reg.resid))\n    print(f'Durbin-Watson between main currency and {name}: {dw:.5f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "209c854f-617f-4f51-b44f-702b9dcc9fb9",
      "metadata": {},
      "outputs": [],
      "source": [
        "Let's calculate Durbin-Watson for all other cryptocurrencies"
      ]
    },
    {
      "cell_type": "code",
      "id": "508fac58-cdec-4ce6-96ca-0fe3d90a03e1",
      "metadata": {},
      "outputs": [],
      "source": [
        "# generating column names for our new dataframe\ncols = [f\"{name}_dep\" for name in names]\n# generating row names for our new dataframe\nidxs = [f\"{name}_ind\" for name in names]\n\n# empty dataframe creation\ndw_df = pd.DataFrame(columns=cols, index=idxs)\n\n# we use itertools.permutations to generate pairs of different cryptocurrencies\n# refer to https://docs.python.org/3/library/itertools.html#itertools.permutations for more details\nfor (curr1, curr2) in itertools.permutations(names, 2):\n    X = df[[f\"{curr1}_avg_price\"]]\n    y = df[f\"{curr2}_avg_price\"]\n    reg = get_reg(X, y)\n    dw = durbin_watson(resids=np.array(reg.resid))\n    dw_df.loc[f\"{curr2}_ind\", f\"{curr1}_dep\"] = dw\ndw_df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5796fcc0-2aaf-4e16-a2aa-9e14c450370b",
      "metadata": {},
      "outputs": [],
      "source": [
        "Replace NaN values with empty values."
      ]
    },
    {
      "cell_type": "code",
      "id": "19a44a17-f10c-4a41-9f80-794c361b4055",
      "metadata": {},
      "outputs": [],
      "source": [
        "np.fill_diagonal(dw_df.values, ' ')\ndw_df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "98c9bf4a-c307-4ef1-8f90-c3302ddc73a5",
      "metadata": {},
      "outputs": [],
      "source": [
        "## 8. Granger Causality Test"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a9a9c75-080b-473d-bc08-a2b2a8c894a8",
      "metadata": {},
      "outputs": [],
      "source": [
        "<b>Granger causality test</b> is a statistical test that helps us to determine if an observed time series y and a given lag of it is co-varying. If the null hypothesis holds true then we are not supposed to find any Granger causality. We reject the null hypothesis if in our sample p-values are smaller than a desired significance level."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f77e9339-e56e-421c-bbe4-56b488190e57",
      "metadata": {},
      "outputs": [],
      "source": [
        "Run cell above to reassing plt to 'Matplotlib' pyplot(we used other library previously it may break visualizations now)."
      ]
    },
    {
      "cell_type": "code",
      "id": "aee269e1-d665-4040-957b-ae34933a5b56",
      "metadata": {},
      "outputs": [],
      "source": [
        "left_ax, right_ax = 'avg_price', 'xrp_avg_price'\ndf_to_test = df[[left_ax, right_ax]]\n# assign variables for plot\nt = df.index # ts\ndata1 = df_to_test[left_ax]\ndata2 = df_to_test[right_ax]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93e2bddb-9de6-4e16-9b84-226b0584cdf6",
      "metadata": {},
      "outputs": [],
      "source": [
        "Now let's draw plot based on variables we created in previous cell. "
      ]
    },
    {
      "cell_type": "code",
      "id": "a9707947-e97f-407a-9326-af49da2e4fee",
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, ax1 = plt.subplots(figsize = (16,9))\n\ncolor = 'tab:red'\nax1.set_xlabel('Time', fontsize=14)\nax1.set_ylabel('Main cryptocurrency(ADA)', color=color, fontsize=14)\nax1.plot(t, data1, color=color)\nax1.tick_params(axis='x', labelcolor=color)\n\nax2 = ax1.twinx()\n\ncolor = 'tab:blue'\nax2.set_ylabel('XRP', color=color, fontsize=14)\nax2.plot(t, data2, color=color)\nax2.tick_params(axis='y', labelcolor=color)\n\nfig.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "code",
      "id": "c95fba46-c8eb-4add-9c0d-68360eb37098",
      "metadata": {},
      "outputs": [],
      "source": [
        "def grangers_causation_matrix(data, maxlag, variables, test='ssr_chi2test', verbose=False):    \n    \"\"\"Check Granger Causality of all possible combinations of the Time series.\n    The rows are the response variable, columns are predictors. The values in the table \n    are the P-Values. P-Values lesser than the significance level (0.05), implies \n    the Null Hypothesis that the coefficients of the corresponding past values is \n    zero, that is, the X does not cause Y can be rejected.\n\n    data      : pandas dataframe containing the time series variables\n    variables : list containing names of the time series variables.\n    \"\"\"\n    df = pd.DataFrame(np.zeros((len(variables), len(variables))), columns=variables, index=variables)\n    for c in df.columns:\n        for r in df.index:\n            test_result = grangercausalitytests(data[[r, c]], maxlag=maxlag, verbose=False)\n            p_values = [round(test_result[i+1][0][test][1],4) for i in range(maxlag)]\n            if verbose: print(f'Y = {r}, X = {c}, P Values = {p_values}')\n            min_p_value = np.min(p_values)\n            df.loc[r, c] = min_p_value\n    df.columns = [var + '_x' for var in variables]\n    df.index = [var + '_y' for var in variables]\n    return df"
      ]
    },
    {
      "cell_type": "code",
      "id": "cdee83b5-2581-4f93-b074-6ee228c4cdcc",
      "metadata": {},
      "outputs": [],
      "source": [
        "grangers_causation_matrix(df_to_test, 1, variables=df_to_test.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e3ac01dc-3b66-451a-a784-f20beb857cd3",
      "metadata": {},
      "outputs": [],
      "source": [
        "How to interpret the p-values?\n\nIn our case, the value of 0.2117 in the first row and second column suggests that the past values of xrp_avg_price can help predict the future values of avg_price, after accounting for the past values of avg_price and xrp_avg_price. On the other hand, the value of 0.0494 in the second row and first column suggests that the past values of avg_price have a weaker influence on predicting the future values of xrp_avg_price, after accounting for the past values of both variables."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d99ad6c-deda-4891-bafd-67cdb3a0203c",
      "metadata": {},
      "outputs": [],
      "source": [
        "Let's calculate Granger Causality Test between our cryptocurrency and others."
      ]
    },
    {
      "cell_type": "code",
      "id": "192c0655-aba5-4c66-9875-513c4c2df5e9",
      "metadata": {},
      "outputs": [],
      "source": [
        "names = currencies.copy()"
      ]
    },
    {
      "cell_type": "code",
      "id": "d422bc87-23cc-4b76-aa22-9c9864562852",
      "metadata": {},
      "outputs": [],
      "source": [
        "for name in names:\n    tmp_df = df[[f\"avg_price\", f\"{name}_avg_price\"]]\n    curr_res_df = grangers_causation_matrix(tmp_df, 1, variables=tmp_df.columns)\n    print(curr_res_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d651b92-5504-42a5-9c96-3527def79d47",
      "metadata": {},
      "outputs": [],
      "source": [
        "We can see a many small dataframes and draw some conclusions. Let's take first matrix into consideration:\n\nThe value of __0.2902 in the upper right corner__ indicates that there is a __strong positive correlation__ between avg_price and ape_avg_price. This means that __changes in the average price of our main cryptocurrency tend to coincide with changes in the average price of another cryptocurrency APE__.\nThe value of __0.1238 in the lower left corner__ indicates that there is a __weaker positive correlation__ between ape_avg_price_y and avg_price_y. This means that __changes in the average price of cryptocurrency APE tend to coincide with changes in the average price of cryptocurrency BTC__, but the relationship is not as strong as the other way around."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d8801c2-f789-42c4-ab48-4c4cee3d1802",
      "metadata": {},
      "outputs": [],
      "source": [
        "*Overall, __this suggests that changes in the average price of our main cryptocurrency(BTC) are more likely to cause changes in the average price of cryptocurrency APE than the other way around__. However, the relationship is not completely one-sided, as changes in the average price of APE can also have some impact on the average price of BTC.*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b565fcb-9ef8-4c6b-a6dc-4c2a295afef9",
      "metadata": {},
      "outputs": [],
      "source": [
        "***In conclusion, DOGE and APE are more likely to affect or main currency(BTC).***"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7aa18461-9320-4435-92a9-29612d159c99",
      "metadata": {},
      "outputs": [],
      "source": [
        "Let's calculate Granger Causality Test for all available pairs."
      ]
    },
    {
      "cell_type": "code",
      "id": "430c51cb-c691-49f8-a5c0-cf23bff5a082",
      "metadata": {},
      "outputs": [],
      "source": [
        "cols = [f\"{name}_x\" for name in names]\nidxs = [f\"{name}_y\" for name in names]\n\ngc_df = pd.DataFrame(columns=cols, index=idxs)\n\nfor (curr1, curr2) in itertools.permutations(names, 2):\n    df_to_test_2 = df[[f\"{curr1}_avg_price\", f\"{curr2}_avg_price\"]]\n    res_df = grangers_causation_matrix(df_to_test_2, 1, variables=df_to_test_2.columns)\n    p1 = res_df[f\"{curr1}_avg_price_x\"][f\"{curr2}_avg_price_y\"]\n    p2 = res_df[f\"{curr2}_avg_price_x\"][f\"{curr1}_avg_price_y\"]\n    gc_df.loc[f\"{curr1}_y\", f\"{curr2}_x\"] = p1\n    gc_df.loc[f\"{curr2}_y\", f\"{curr1}_x\"] = p2\n\n# replace diagonal values with space char\nnp.fill_diagonal(gc_df.values, ' ')\n    \ngc_df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8057f58a-0d6a-487c-87ee-36429a49f3fe",
      "metadata": {},
      "outputs": [],
      "source": [
        "Now, you can draw your own conclusions based on the matrix above and the ideas we showed you previously.\n\nIt's worth noting that the __Granger Causality test does not prove causation in the traditional sense, but rather identifies potential causal relationships between variables based on statistical patterns__. Therefore, __it's important to interpret the results with caution and consider other factors that may be influencing the relationship between the variables__."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a782003-a092-496f-8637-d9cd1688a829",
      "metadata": {},
      "outputs": [],
      "source": [
        "Finally, let's save out dataframe, so we can use it later(we will include categorical data to our current one)."
      ]
    },
    {
      "cell_type": "code",
      "id": "2631688e-03c0-404d-bf95-29f97584e255",
      "metadata": {},
      "outputs": [],
      "source": [
        "df.to_csv('BTCBUSD_1min_categories.csv', index=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a17db15-7334-4087-9fcf-7e728e55654f",
      "metadata": {},
      "outputs": [],
      "source": [
        "### Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "92350055-8151-48e8-afd7-e77cd1f843eb",
      "metadata": {},
      "outputs": [],
      "source": [
        "Now we have a better idea of our data and understand what cryptocurrency affects our main cryptocurrency(BTCBUSD) more.\n\nAs we now move into building machine learning models to automate our analysis, feeding the model with variables that meaningfully affect our target variable will improve our model's prediction performance."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3cb3cc58-5019-41c3-9acb-9c80f20ad1b2",
      "metadata": {},
      "outputs": [],
      "source": [
        "# **Thank you for completing Lab 3!**\n\n## Authors\n\n<a href=\"https://author.skills.network/instructors/nazar_kohut\">Nazar Kohut</a>\n\n<a href=\"https://author.skills.network/instructors/yaroslav_vyklyuk_2?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkGuidedProjectsIBMSkillsNetworkGPXX0QGDEN2306-2023-01-01\">Prof. Yaroslav Vyklyuk, DrSc, PhD</a>\n\n<a href=\"https://author.skills.network/instructors/mariya_fleychuk?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkGuidedProjectsIBMSkillsNetworkGPXX0QGDEN2306-2023-01-01\">Prof. Mariya Fleychuk, DrSc, PhD</a>\n\n## Change Log\n\n| Date (YYYY-MM-DD) | Version | Changed By   | Change Description                                         |\n| ----------------- | ------- | -------------| ---------------------------------------------------------- |\n|     2023-03-11    |   1.0   | Nazar Kohut  | Lab created                                                |\n\n<hr>\n\n<h3 align=\"center\"> Â© IBM Corporation 2023. All rights reserved. <h3/>"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": ""
    },
    "kernelspec": {
      "name": "",
      "display_name": ""
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}