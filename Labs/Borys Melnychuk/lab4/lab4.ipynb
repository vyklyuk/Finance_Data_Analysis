{"cells":[{"cell_type":"markdown","id":"7d7a434c-8a81-4d5b-8af4-98abdf3f3b97","metadata":{},"outputs":[],"source":["\u003ccenter\u003e\n","    \u003cimg src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"500\" alt=\"cognitiveclass.ai logo\"\u003e\n","\u003c/center\u003e\n","\n","#  **Investigation of MATIC/BUSD exchange rate dynamic,  calculation and analysis of separate  technical financial indicators of cryptocurrency market (ATR, OBV, RSI, AD)**\n","\n","## **Lab 4. Model development**\n","\n","## **The tasks**\n","* To built Linear Regression and Multiple Linear Regression.\n","* To built Multiple Linear Regression.\n","* To make Model Evaluation Using Visualization.\n","* To built Polynomial Regression and Pipelines.\n","* To apply In-Sample Evaluation.\n","\n","\n","Estimated time needed: **30** minutes\n","\n","## **Objectives**\n","\n","After completing this lab you will be able to:\n","\n","*   develop prediction models;\n","*   compare models;\n","*   perform model evaluation using visualization.\n"]},{"cell_type":"markdown","id":"22020cec-64c7-4eb9-b212-7b413d9c43cb","metadata":{},"outputs":[],"source":["In this section, we will develop several models that will predict **\"Avg_price\"** of the cryptocurrency using the technical indicators. This is just an estimate but should give us an objective idea of how much the cryptocurrency should cost.\n"]},{"cell_type":"markdown","id":"63c01387-5781-495e-91d6-1844e7ac5677","metadata":{},"outputs":[],"source":["Some questions we want to ask in this module\n","\n","* How good are models in predicting **\"Avg_price\"**?\n","* Which model predicts the best?\n"]},{"cell_type":"markdown","id":"158e49ba-5e3f-4f45-af09-176bdfd6a0e1","metadata":{},"outputs":[],"source":["## **Table of Contents**\n","\n","\u003cdiv class=\"alert alert-block alert-info\" style=\"margin-top: 20px\"\u003e\n","\u003col\u003e\n","    \u003cli\u003eImport Data\u003c/li\u003e\n","    \u003cli\u003eLinear Regression and Multiple Linear Regression\u003c/li\u003e\n","        \u003cul\u003e\n","            \u003cli\u003eLinear Regression\u003c/li\u003e\n","            \u003cli\u003eMultiple Linear Regression\u003c/li\u003e\n","        \u003c/ul\u003e\n","    \u003cli\u003eModel Evaluation Using Visualization\u003c/li\u003e\n","        \u003cul\u003e\n","            \u003cli\u003eRegression Plot\u003c/li\u003e\n","            \u003cli\u003eResidual Plot\u003c/li\u003e\n","            \u003cli\u003eMultiple Linear Regression\u003c/li\u003e\n","        \u003c/ul\u003e\n","    \u003cli\u003ePolynomial Regression and Pipelines\u003c/li\u003e\n","        \u003cul\u003e\n","            \u003cli\u003ePolynomial Regression\u003c/li\u003e\n","            \u003cli\u003ePipeline\u003c/li\u003e\n","        \u003c/ul\u003e\n","    \u003cli\u003eMeasures for In-Sample Evaluation\u003c/li\u003e\n","    \u003cul\u003e\n","        \u003cli\u003e$R^2$ / $R$-squared\u003c/li\u003e\n","        \u003cli\u003eMean Squared Error (MSE)\u003c/li\u003e\n","        \u003cli\u003eF-test score\u003c/li\u003e\n","        \u003cli\u003eP-value\u003c/li\u003e\n","        \u003cli\u003eModel 1: Simple Linear Regression\u003c/li\u003e\n","        \u003cli\u003eModel 2: Multiple Linear Regression\u003c/li\u003e\n","        \u003cli\u003eModel 3: Polynomial Fit\u003c/li\u003e\n","    \u003c/ul\u003e\n","    \u003cli\u003ePrediction and Decision Making\u003c/li\u003e\n","    \u003cul\u003e\n","        \u003cli\u003ePrediction\u003c/li\u003e\n","        \u003cli\u003eDecision Making: Determining a Good Model Fit\u003c/li\u003e\n","        \u003cli\u003eSimple Linear Regression Model (SLR) vs Multiple Linear Regression Model (MLR)\u003c/li\u003e\n","        \u003cli\u003eSimple Linear Model (SLR) vs. Polynomial Fit\u003c/li\u003e\n","        \u003cli\u003eMultiple Linear Regression (MLR) vs. Polynomial Fit\u003c/li\u003e\n","    \u003c/ul\u003e\n","    \u003cli\u003eSources\u003c/li\u003e\n","\u003c/ol\u003e\n","\n","\u003c/div\u003e\n","\n","\u003chr\u003e\n"]},{"cell_type":"markdown","id":"7c54cd57-df07-4066-92f9-93a657852637","metadata":{},"outputs":[],"source":["## **Dataset Description**\n","\n","### **Files**\n","* #### **MATICBUSD_trades_1m_preprocessed.csv** - the file contains historical changes of the pair **MATIC/BUSD** and ATR, OBV, RSI, AD indicators for the period from 11/11/2022 to 12/29/2022 with an aggregation time of 1 minute. **MATIC/BUSD** - the exchange rate of **MATIC** cryptocurrency to **BUSD** cryptocurrency\n","\n","### **Columns**\n","\n","* #### `Ts` - the timestamp of the record\n","* #### `Open` -  the price of the asset at the beginning of the trading period\n","* #### `High` -  the highest price of the asset during the trading period\n","* #### `Low` - the lowest price of the asset during the trading period.\n","* #### `Close` - the price of the asset at the end of the trading period\n","* #### `Volume` - the total number of shares or contracts of a particular asset that are traded during a given period\n","* #### `Rec_count` -  the number of individual trades or transactions that have been executed during a given time period\n","* #### `Avg_price` - the average price at which a particular asset has been bought or sold during a given period\n","* #### `ATR` - average true range indicator\n","* #### `OBV` - on-balance volume indicator\n","* #### `RSI` - relative strength index indicator\n","* #### `AD` - accumulation / distribution indicator\n"]},{"cell_type":"markdown","id":"c4029c86-a6f6-4c2a-97b7-a511b52d8c9a","metadata":{},"outputs":[],"source":["In data analytics, we often use **Model Development** to help us predict future observations from the data we have. A model will help us understand the exact relationship between different variables and how these variables are used to predict the result.\n"]},{"cell_type":"markdown","id":"ef75fb1c-0df8-4f0a-b116-4acc21066c98","metadata":{},"outputs":[],"source":["# **1. Import data**\n"]},{"cell_type":"markdown","id":"188eae34-d845-4e0c-9e6f-61cc263c328a","metadata":{},"outputs":[],"source":["Run the following cell to install required libraries:\n"]},{"cell_type":"code","id":"1550b6f2-9d3e-493a-ab1b-3f1c5e196b03","metadata":{},"outputs":[],"source":["# If you run the lab locally using Anaconda, you can load the correct library and versions by uncommenting the following:\n# install specific version of libraries used in lab\n\n# ! conda install -q -y pandas\n! conda install -q -y numpy\n# ! conda install -q -y matplotlib\n# ! conda install -q -y seaborn\n# ! conda install -q -y -c anaconda statsmodels -y\n\n! conda install -q -y -c anaconda scikit-learn\n# ! conda install -q -y scipy"]},{"cell_type":"code","id":"08b30fca-3840-468f-a25a-dc9f1f5971b7","metadata":{},"outputs":[],"source":["import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport statsmodels.api as sm\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import PolynomialFeatures, StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn import set_config\nfrom scipy import stats\n\nimport warnings\nfrom typing import Callable, Union\npd.set_option(\"display.precision\", 5) # setting numbers after digits\npd.options.display.float_format = \"{:.5f}\".format\nset_config(display=\"diagram\")\nwarnings.filterwarnings(\"ignore\")"]},{"cell_type":"markdown","id":"c051ba9c-4720-4099-9278-217a5528587e","metadata":{},"outputs":[],"source":["This dataset was hosted \u003ca href=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-GPXX087UEN/MATICBUSD_trades_1m_preprocessed.csv\"\u003eHERE\u003c/a\u003e.\n"]},{"cell_type":"code","id":"02ffb93b-aae1-4c7c-865f-a843f909e5c8","metadata":{},"outputs":[],"source":["path = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-GPXX087UEN/MATICBUSD_trades_1m_preprocessed.csv\""]},{"cell_type":"markdown","id":"771009f6-2545-4709-a4b3-186d16ee5630","metadata":{},"outputs":[],"source":["Load the data and store it in dataframe `df`:\n"]},{"cell_type":"code","id":"dc6c1b78-8bee-4589-91b6-841678a77463","metadata":{},"outputs":[],"source":["df = pd.read_csv(path, parse_dates=[\"Ts\"])"]},{"cell_type":"code","id":"e7267ac1-461a-47c2-9158-84db73d79598","metadata":{},"outputs":[],"source":["df.head()"]},{"cell_type":"markdown","id":"a791f329-ea75-4b6e-9d3e-18490072a378","metadata":{},"outputs":[],"source":["We will need to drop first 15 `NaN`'s\n"]},{"cell_type":"code","id":"9d331522-a28b-4b51-9766-43afc95b3d77","metadata":{},"outputs":[],"source":["df = df.dropna()"]},{"cell_type":"markdown","id":"a49a6fb1-1d9b-4947-a910-c27ffc478426","metadata":{},"outputs":[],"source":["# **2. Linear Regression and Multiple Linear Regression**\n"]},{"cell_type":"markdown","id":"4fe50726-835f-4eb5-9bb2-21b2032e9e15","metadata":{},"outputs":[],"source":["## **Linear regression**\n","\n","**Linear regression** is an algorithm that provides a linear relationship between an independent variable and a dependent variable to predict the outcome of future events. It is a statistical method used in data science and machine learning for predictive analysis.\n","\n","The independent variable is also the predictor or explanatory variable that remains unchanged due to the change in other variables. However, the dependent variable changes with fluctuations in the independent variable. The regression model predicts the value of the dependent variable, which is the response or outcome variable being analyzed or studied.\n","\n","Thus, linear regression is a supervised learning algorithm that simulates a mathematical relationship between variables and makes predictions for *continuous or numeric variables such as sales, salary, age, product price, etc*.\n","\n","This analysis method is advantageous when at least two variables are available in the data, as observed in stock market forecasting, portfolio management, scientific analysis, etc.\n","\n","A sloped straight line represents the linear regression model.\n"]},{"cell_type":"markdown","id":"4a54a16a-4340-4f6d-b1c9-acdb0d9db4e0","metadata":{},"outputs":[],"source":["\u003ccenter\u003e\n","    \u003cimg src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-GPXX087UEN/25-4.png\" width=\"550\" alt=\"linear regression image\"\u003e\n","\u003c/center\u003e\n"]},{"cell_type":"markdown","id":"ee822b3b-7b44-4409-a098-27e29c9e06f7","metadata":{},"outputs":[],"source":["\u003ccenter\u003eBest Fit Line for a Linear Regression Model\u003c/center\u003e\n","\n","In the above figure,\n","\n","$X$-axis = Independent variable\n","\n","$Y$-axis = Output / dependent variable\n","\n","Line of regression = Best fit line for a model\n","\n","Here, a line is plotted for the given data points that suitably fit all the issues. Hence, it is called the **\"best fit line\"**. The goal of the linear regression algorithm is to find this best fit line seen in the above figure.\n"]},{"cell_type":"markdown","id":"1d7e8f91-0a83-4ec7-9400-df29c119217d","metadata":{},"outputs":[],"source":["The result of Linear Regression is a **linear function** that predicts the dependent variable as a function of the independent variable.\n"]},{"cell_type":"markdown","id":"39db4309-ab54-446c-93e2-bca71be89b91","metadata":{},"outputs":[],"source":["\u003ch3\u003e\n","$$\n","Y : Dependent \\ Variable\\\\\\\\\\\\\\\\\\\\\\\\\n","X : Independent \\ Variables\n","$$\n","\u003c/h3\u003e\n"]},{"cell_type":"markdown","id":"efc4bfad-79b1-4abc-9d49-b3f6d9193a8c","metadata":{},"outputs":[],"source":["**Linear Function**\n","\n","\u003ccenter\u003e\n","\u003ch3\u003e\n","$\n","\\widehat{Y} = a + b  X\n","$\n","\u003c/h3\u003e\n","\u003c/center\u003e\n"]},{"cell_type":"markdown","id":"08e19cc4-ac36-4888-86dc-c9dc43e85866","metadata":{},"outputs":[],"source":["$a$ refers to the intercept of the regression line, in other words: the value of $Y$ when $X$ is 0 \u003cbr\u003e\n","$b$ refers to the slope of the regression line, in other words: the value with which $Y$ changes when $X$ increases by 1 unit\n"]},{"cell_type":"markdown","id":"9b18b55b-ac11-4b5a-8675-cbcc8d7bbf00","metadata":{},"outputs":[],"source":["**Advantages:**\n","\n","* Easy to understand and interpret the results.\n","* It is computationally efficient and requires minimal computational power.\n","* Can be used to identify the relationship between two variables, making it useful for predictive modeling.\n","* Useful when the relationship between the dependent and independent variable is linear.\n","\n","**Disadvantages:**\n","\n","* Assumes a linear relationship between the dependent and independent variables.\n","* It is sensitive to outliers, which can negatively affect the results.\n","* Cannot be used when there are multiple independent variables.\n"]},{"cell_type":"markdown","id":"3d98109a-94c0-4c6f-9e71-b6197aa82d15","metadata":{},"outputs":[],"source":["Create the linear regression object:\n"]},{"cell_type":"code","id":"04595beb-3c32-492b-b725-65b9f2b4e2a3","metadata":{},"outputs":[],"source":["lm = LinearRegression()\nlm"]},{"cell_type":"markdown","id":"86f221d2-352b-4820-8677-301ba183299a","metadata":{},"outputs":[],"source":["**How could \"ATR\" help us predict \"Avg_price\"?**\n"]},{"cell_type":"markdown","id":"46614cff-346f-4ea0-9c7e-9f4a8cb897aa","metadata":{},"outputs":[],"source":["In the previous lab we did Granger Causality Test and concluded that **\"ATR\"** granger-causes **\"Avg_price\"** so we will use **\"ATR\"** as independent variable.\n"]},{"cell_type":"code","id":"733a4445-0b1b-4230-ad21-e5caa7818462","metadata":{},"outputs":[],"source":["X_lr = df[[\"ATR\"]]\nY = df[\"Avg_price\"]"]},{"cell_type":"markdown","id":"7bbb8fb7-7005-492a-aece-56e642ceae01","metadata":{},"outputs":[],"source":["Fit the linear model using **\"ATR\"** and **\"Avg_price\"**:\n"]},{"cell_type":"code","id":"e4d47b32-d33c-47b7-bb84-1b256a2240f5","metadata":{},"outputs":[],"source":["lm.fit(X_lr, Y)"]},{"cell_type":"markdown","id":"1f808afc-c8e1-4261-8e5e-7c1f381729e4","metadata":{},"outputs":[],"source":["We can output a prediction:\n"]},{"cell_type":"code","id":"2ffe6211-1e1a-4673-918e-4b7dad809fcd","metadata":{},"outputs":[],"source":["Y_hat = lm.predict(X_lr)\nY_hat[0:5]"]},{"cell_type":"markdown","id":"507d194b-e1c6-4e48-8420-b0d09711c2a5","metadata":{},"outputs":[],"source":["**What is the value of the intercept ($a$)?**\n"]},{"cell_type":"code","id":"7622fc37-5928-4a62-85a3-9040f9305c0c","metadata":{},"outputs":[],"source":["lm.intercept_"]},{"cell_type":"markdown","id":"b9643107-2541-4fda-a90e-dfbdaf4fab1f","metadata":{},"outputs":[],"source":["**What is the value of the slope ($b$)?**\n"]},{"cell_type":"code","id":"aa391716-6d97-49b3-b212-96d93ebf6e51","metadata":{},"outputs":[],"source":["lm.coef_"]},{"cell_type":"markdown","id":"6be67980-a378-4604-a126-7673ef8e6c03","metadata":{},"outputs":[],"source":["Now let's do the same but we will consider **\"OBV\"** and **\"AD\"** as independent variables\n"]},{"cell_type":"markdown","id":"81d67cfb-fd30-49bb-b6fe-cb0c20e2dee1","metadata":{},"outputs":[],"source":["**What is the final estimated linear model we get?**\n"]},{"cell_type":"markdown","id":"26bc4d55-f0d0-454c-85a5-a4b4383146df","metadata":{},"outputs":[],"source":["As we saw above, we should get a final linear model with the structure:\n"]},{"cell_type":"markdown","id":"7d473bed-604b-41f0-a00d-b7eafd4d9fd4","metadata":{},"outputs":[],"source":["\u003ccenter\u003e\n","    \u003ch3\u003e\n","$\n","\\widehat{Y} = a + b  X\n","$\n","    \u003c/h3\u003e\n","\u003c/center\u003e\n"]},{"cell_type":"markdown","id":"3b14db2e-4888-491a-b4d1-bc8fddbea70d","metadata":{},"outputs":[],"source":["Plugging in the actual values we get:\n"]},{"cell_type":"markdown","id":"f581142d-2a64-4c76-a35c-735aa306a205","metadata":{},"outputs":[],"source":["**Avg_price** = 0.8439822752478543 + 22.49597877 x **ATR**\n"]},{"cell_type":"code","id":"f6aa292a-f591-4187-b1ac-a3ac7f388606","metadata":{},"outputs":[],"source":["lm_obv = LinearRegression()\n\nX_obv = df[[\"OBV\"]]\n\nlm_obv.fit(X_obv, Y)\n\nY_obv = lm_obv.predict(X_obv)\nprint(f\"First 5 predictions: {Y_obv[:5]}\")\nprint(f\"Y-intercept: {lm_obv.intercept_}\")\nprint(f\"Coef: {lm_obv.coef_}\")"]},{"cell_type":"code","id":"34a22083-a9b5-47f5-b836-73512f8d9669","metadata":{},"outputs":[],"source":["lm_ad = LinearRegression()\n\nX_ad = df[[\"AD\"]]\n\nlm_ad.fit(X_ad, Y)\n\nY_ad = lm_ad.predict(X_ad)\nprint(f\"First 5 predictions: {Y_ad[:5]}\")\nprint(f\"Y-intercept: {lm_ad.intercept_}\")\nprint(f\"Coef: {lm_ad.coef_}\")"]},{"cell_type":"markdown","id":"f584fddf-08cc-47e7-905e-63de3024b148","metadata":{},"outputs":[],"source":["\u003cdiv class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\"\u003e\n","\u003ch1\u003e\u003cstrong\u003eQuestion #1 a): \u003c/strong\u003e\u003c/h1\u003e\n","\n","**Create a linear regression object called `lm_rsi`.**\n","\n","\u003c/div\u003e\n"]},{"cell_type":"code","id":"b703725c-daf0-4879-8e33-7d95258ba1d4","metadata":{},"outputs":[],"source":["# Write your code below and press Shift+Enter to execute \n"]},{"cell_type":"markdown","id":"2dfc7b64-d043-4c93-8272-dad9a3a2ddd8","metadata":{},"outputs":[],"source":["\u003cdetails\u003e\u003csummary\u003eClick here for the solution\u003c/summary\u003e\n","\n","```python\n","lm_rsi = LinearRegression()\n","lm_rsi\n","```\n","\n","\u003c/details\u003e\n"]},{"cell_type":"markdown","id":"c7f33c33-f331-4e8b-9464-668e2be9a565","metadata":{},"outputs":[],"source":["\u003cdiv class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\"\u003e\n","\u003ch1\u003e\u003cstrong\u003eQuestion #1 b):\u003c/strong\u003e\u003c/h1\u003e\n","\n","**Train the model using \"RSI\" as the independent variable and \"Avg_price\" as the dependent variable?**\n","\n","\u003c/div\u003e\n"]},{"cell_type":"code","id":"6c410f18-b048-46c5-bca5-7b5d1c2b5eef","metadata":{},"outputs":[],"source":["# Write your code below and press Shift+Enter to execute \n"]},{"cell_type":"markdown","id":"5bdc4ba0-11c7-4a04-8e42-5acd4450c46e","metadata":{},"outputs":[],"source":["\u003cdetails\u003e\u003csummary\u003eClick here for the solution\u003c/summary\u003e\n","\n","```python\n","lm_rsi.fit(df[[\"RSI\"]], df[\"Avg_price\"])\n","lm_rsi\n","```\n","\n","\u003c/details\u003e\n"]},{"cell_type":"markdown","id":"878b51b5-7ffc-46f2-937c-e7f49aa7135f","metadata":{},"outputs":[],"source":["\u003cdiv class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\"\u003e\n","\u003ch1\u003e\u003cstrong\u003eQuestion #1 c):\u003c/strong\u003e\u003c/h1\u003e\n","\n","**Find the slope and intercept of the model.**\n","\n","\u003c/div\u003e\n"]},{"cell_type":"markdown","id":"9d6be68e-1f7a-4295-bee7-36175587a7a9","metadata":{},"outputs":[],"source":["Slope\n"]},{"cell_type":"code","id":"07ee5829-8272-4176-b531-fc3086e9e15a","metadata":{},"outputs":[],"source":["# Write your code below and press Shift+Enter to execute \n"]},{"cell_type":"markdown","id":"2ddc1c09-868c-46b4-8223-c737de3ff5c5","metadata":{},"outputs":[],"source":["\u003cdetails\u003e\u003csummary\u003eClick here for the solution\u003c/summary\u003e\n","\n","```python\n","# Slope \n","lm_rsi.coef_\n","```\n","\n","\u003c/details\u003e\n"]},{"cell_type":"markdown","id":"f62762c4-0345-43ae-845f-fbe44cacd5b3","metadata":{},"outputs":[],"source":["Intercept\n"]},{"cell_type":"code","id":"8539c53e-2c41-4dbe-9a91-b92864d8a9b3","metadata":{},"outputs":[],"source":["# Write your code below and press Shift+Enter to execute \n"]},{"cell_type":"markdown","id":"5f23a776-68f0-43ba-bab5-a235b7e3a5bd","metadata":{},"outputs":[],"source":["\u003cdetails\u003e\u003csummary\u003eClick here for the solution\u003c/summary\u003e\n","\n","```python\n","# Intercept\n","lm_rsi.intercept_\n","```\n","\n","\u003c/details\u003e\n"]},{"cell_type":"markdown","id":"e75ae0b7-80a4-4d05-880f-89ff58dd4ce9","metadata":{},"outputs":[],"source":["\u003cdiv class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\"\u003e\n","\u003ch1\u003e\u003cstrong\u003eQuestion #1 d):\u003c/strong\u003e\u003c/h1\u003e\n","\n","**What is the equation of the predicted line? Assign the equation to `y_hat` variable.**\n","\n","\u003c/div\u003e\n"]},{"cell_type":"code","id":"487f8323-8fc9-42e7-80e6-4ba5f9cc781d","metadata":{},"outputs":[],"source":["# Write your code below and press Shift+Enter to execute \n"]},{"cell_type":"markdown","id":"be9d7510-a924-4139-a3d3-22b267257602","metadata":{},"outputs":[],"source":["\u003cdetails\u003e\u003csummary\u003eClick here for the solution\u003c/summary\u003e\n","\n","```python\n","y_hat = 0.00014489 * df[\"RSI\"] + 0.8573564226902424\n","\n","```\n","\n","\u003c/details\u003e\n"]},{"cell_type":"markdown","id":"0e30032b-eae7-4c05-a445-f72087d2755e","metadata":{},"outputs":[],"source":["## **Multiple Linear Regression**\n"]},{"cell_type":"markdown","id":"1a6b2596-883a-474f-86c0-1dedabfd6af9","metadata":{},"outputs":[],"source":["**What if we want to predict \"Avg_price\" using more than one variable?**\n","\n","If we want to use more variables in our model to predict price, we can use **Multiple Linear Regression**.\n","Multiple Linear Regression is very similar to Simple Linear Regression, but this method is used to explain the relationship between one continuous response (dependent) variable and **two or more** predictor (independent) variables.\n","\n","**Example:** Consider the task of calculating blood pressure. In this case, height, weight, and amount of exercise can be considered independent variables. Here, we can use multiple linear regression to analyze the relationship between the three independent variables and one dependent variable, as all the variables considered are quantitative.\n","\n","**What Multiple Linear Regression Can Tell You?**\n","\n","Simple linear regression is a function that allows an analyst or statistician to make predictions about one variable based on the information that is known about another variable. Linear regression can only be used when one has two continuous variables — an independent variable and a dependent variable. The independent variable is the parameter that is used to calculate the dependent variable or outcome. A multiple regression model extends to several explanatory variables.\n","\n","**How Are Multiple Regression Models Used in Finance?**\n","\n","Any econometric model that looks at more than one variable may be a multiple. Factor models compare two or more factors to analyze relationships between variables and the resulting performance. The Fama and French Three-Factor Mod is such a model that expands on the capital asset pricing model (**CAPM**) by adding size risk and value risk factors to the market risk factor in **CAPM** (which is itself a regression model). By including these two additional factors, the model adjusts for this outperforming tendency, which is thought to make it a better tool for evaluating manager performance.\n","\n","Most of the real-world regression models involve multiple predictors. We will illustrate the structure by using four predictor variables, but these results can generalize to any integer:\n"]},{"cell_type":"markdown","id":"08ee07c2-bb7b-4eba-af84-30acc9c6a0f4","metadata":{},"outputs":[],"source":["\u003ch3\u003e\n","$$\n","Y: \\text{Dependent Variable}\\\\\\\\\\\\\\\\\\\\\\\\\n","X_1: \\text{Independent Variable 1}\\\\\\\\\n","X_2: \\text{Independent Variable 2}\\\\\\\\\n","X_3: \\text{Independent Variable 3}\\\\\\\\\n","X_4: \\text{Independent Variable 4}\\\\\\\\\n","$$\n","\u003c/h3\u003e\n"]},{"cell_type":"markdown","id":"99e367a6-be43-4826-b39c-47fe99d76af9","metadata":{},"outputs":[],"source":["\u003ch3\u003e\n","$$\n","a: \\text{intercept}\\\\\\\\\\\\\\\\\\\\\\\\\n","b_1 : \\text{coefficients of Variable 1}\\\\\\\\\n","b_2: \\text{coefficients of Variable 2}\\\\\\\\\n","b_3: \\text{coefficients of Variable 3}\\\\\\\\\n","b_4: \\text{coefficients of Variable 4}\\\\\\\\\n","$$\n","\u003c/h3\u003e\n"]},{"cell_type":"markdown","id":"3bed334a-6007-4144-8ae2-068401b9db79","metadata":{},"outputs":[],"source":["The equation is given by:\n"]},{"cell_type":"markdown","id":"75344ad0-add5-4d81-a35e-2e21d199a85b","metadata":{},"outputs":[],"source":["\u003ch3\u003e\n","$$\n","\\widehat{Y} = a + b_1 X_1 + b_2 X_2 + b_3 X_3 + b_4 X_4\n","$$\n","\u003c/h3\u003e\n"]},{"cell_type":"markdown","id":"38106c48-0b76-4a96-9584-5f8c7605e068","metadata":{},"outputs":[],"source":["From the previous section  we know that good predictors of **\"Avg_price\"** could be:\n","\n","* **\"ATR\"**\n","* **\"OBV\"**\n","* **\"RSI\"**\n","* **\"AD\"**\n"]},{"cell_type":"markdown","id":"93a2ecb8-dcf8-4e36-b6fc-3b20b61baae1","metadata":{},"outputs":[],"source":["**Advantages:**\n","\n","* Can be used to identify the relationship between multiple independent variables and a dependent variable.\n","* It can account for the effect of confounding variables on the dependent variable.\n","* Can improve the accuracy of predictions compared to simple linear regression.\n","* Can identify which independent variable(s) have the most impact on the dependent variable.\n","\n","**Disadvantages:**\n","\n","* Requires more data than simple linear regression.\n","* The results can be difficult to interpret when there are multiple independent variables.\n","* Assumes a linear relationship between the dependent and independent variables.\n"]},{"cell_type":"markdown","id":"c8fb1123-5bd1-4dd8-90ac-49845cd20e29","metadata":{},"outputs":[],"source":["Let's calculate a correlation between these cryptocurrencies\n"]},{"cell_type":"code","id":"0b1c6110-53b9-4307-bf05-aff667733325","metadata":{},"outputs":[],"source":["df.corr()"]},{"cell_type":"markdown","id":"18bf8122-2b65-4156-9509-f6fcd531958f","metadata":{},"outputs":[],"source":["Let's develop a model using these variables as the predictor variables.\n"]},{"cell_type":"code","id":"72ee0254-286f-4397-98f1-1c4adf3e5137","metadata":{},"outputs":[],"source":["Z = df[[\"ATR\", \"OBV\", \"RSI\", \"AD\"]]"]},{"cell_type":"markdown","id":"e98a65da-8a59-4b3e-b524-1ebaa8b39fb8","metadata":{},"outputs":[],"source":["Fit the linear model using the four above-mentioned variables.\n"]},{"cell_type":"code","id":"6204e8df-a7eb-44d9-9a5d-254a6444c49d","metadata":{},"outputs":[],"source":["mlr = LinearRegression()\nmlr.fit(Z, Y)"]},{"cell_type":"code","id":"1309780f-3e28-44b9-ab06-d482c591f1a5","metadata":{},"outputs":[],"source":["Y_mlr = mlr.predict(Z)"]},{"cell_type":"markdown","id":"65d2437c-6bfb-4acb-913b-5ec56ae27f81","metadata":{},"outputs":[],"source":["**What is the value of the intercept ($a$)?**\n"]},{"cell_type":"code","id":"31137fe4-3964-45e7-9d16-d27c1d7a224c","metadata":{},"outputs":[],"source":["mlr.intercept_"]},{"cell_type":"markdown","id":"57517f90-02f0-4e77-becb-8367a266dfee","metadata":{},"outputs":[],"source":["**What are the values of the coefficients ($b_1$, $b_2$, $b_3$, $b_4$)?**\n"]},{"cell_type":"code","id":"bc9f0ae9-d0f2-49ae-ae09-37ce46f82c6f","metadata":{},"outputs":[],"source":["mlr.coef_"]},{"cell_type":"markdown","id":"9683a345-2cd5-43de-8532-0c6bfc30dec2","metadata":{},"outputs":[],"source":["**What is the final estimated linear model that we get?**\n"]},{"cell_type":"markdown","id":"b8c91bf2-2223-4e9c-a1ae-876c1d538445","metadata":{},"outputs":[],"source":["As we saw above, we should get a final linear function with the structure:\n","\n","\u003ch3\u003e\n","$$\n","\\widehat{Y} = a + b_1 X_1 + b_2 X_2 + b_3 X_3 + b_4 X_4\n","$$\n","\u003c/h3\u003e\n","    \n","**What is the linear function we get in this example?**\n"]},{"cell_type":"markdown","id":"fcc38a60-1c65-491d-af01-3d964d5fe482","metadata":{},"outputs":[],"source":["**Avg_price** = 1.0480399345639373 - 0.993894360 x **ATR** + 0.00000000672461253 x **OBV** + 0.0000742896268 x **RSI** + 0.00000000578434954 x **AD**\n"]},{"cell_type":"markdown","id":"9e1cccff-77b8-424d-836c-8144d4b65df4","metadata":{},"outputs":[],"source":["\u003cdiv class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\"\u003e\n","    \n","# **Question  #2 a):**\n","    \n","**Create and train a Multiple Linear Regression model `lm2` where the dependent variable is \"Avg_price\", and the independent variable is \"ATR\" and \"AD\".**\n","    \n","\u003c/div\u003e\n"]},{"cell_type":"code","id":"20af30c5-c6b9-408e-b098-07f9f00ba27d","metadata":{},"outputs":[],"source":["# Write your code below and press Shift+Enter to execute \n"]},{"cell_type":"markdown","id":"5dcd498d-0c28-4112-94c9-3ce1dd170447","metadata":{},"outputs":[],"source":["\u003cdetails\u003e\u003csummary\u003eClick here for the solution\u003c/summary\u003e\n","\n","```python\n","lm2 = LinearRegression()\n","lm2.fit(df[[\"ATR\", \"AD\"]], df[\"Avg_price\"])\n","\n","\n","```\n","\n","\u003c/details\u003e\n"]},{"cell_type":"markdown","id":"7e333cd5-2148-444a-bd64-9329ec87b37a","metadata":{},"outputs":[],"source":["\u003cdiv class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\"\u003e\n","    \n","# **Question  #2 b):**\n","    \n","**Find the coefficient of the model.**\n","    \n","\u003c/div\u003e\n"]},{"cell_type":"code","id":"fe5370b2-2331-4c44-9cb4-ab0717c96537","metadata":{},"outputs":[],"source":["# Write your code below and press Shift+Enter to execute \n"]},{"cell_type":"markdown","id":"82a79018-55a4-45bd-a727-5ac0da096f64","metadata":{},"outputs":[],"source":["\u003cdetails\u003e\u003csummary\u003eClick here for the solution\u003c/summary\u003e\n","\n","```python\n","lm2.coef_\n","\n","```\n","\n","\u003c/details\u003e\n"]},{"cell_type":"markdown","id":"e7914d70-2a24-477e-a29c-4a8676bb54f2","metadata":{},"outputs":[],"source":["# **3. Model Evaluation Using Visualization**\n"]},{"cell_type":"markdown","id":"0f41b85b-884d-4de2-a997-26fb3799e5c0","metadata":{},"outputs":[],"source":["Now that we've developed some models, how do we evaluate our models and choose the best one? One way to do this is by using a visualization.\n"]},{"cell_type":"markdown","id":"98bb8f29-b39e-4b5c-9fbf-0b799f9fe4fb","metadata":{},"outputs":[],"source":["## **Regression Plot**\n"]},{"cell_type":"markdown","id":"e778dc39-da19-41bb-aa58-1412def2b428","metadata":{},"outputs":[],"source":["When it comes to simple linear regression, an excellent way to visualize the fit of our model is by using **regression plots**.\n","\n","This plot will show a combination of a scattered data points (a **scatterplot**), as well as the fitted **linear regression** line going through the data. This will give us a reasonable estimate of the relationship between the two variables, the strength of the correlation, as well as the direction (positive or negative correlation).\n"]},{"cell_type":"markdown","id":"be5e11ee-0cad-4dea-a8ac-c5356c3f6208","metadata":{},"outputs":[],"source":["Let's visualize **\"AD\"** as potential predictor variable of **\"Avg_price\"**:\n"]},{"cell_type":"code","id":"e9d1f6f8-d310-45a6-aa11-316dd2073e3a","metadata":{},"outputs":[],"source":["width = 6\nheight = 5\nplt.figure(figsize=(width, height))\nplt.title(\"AD as potential predictor variable of Avg_price\")\nsns.regplot(x=\"AD\", y=\"Avg_price\", data=df, scatter_kws={\"s\": 1})"]},{"cell_type":"markdown","id":"ec1ed9fb-b127-4f6f-8456-2a3350c9cfad","metadata":{},"outputs":[],"source":["As we can see, the points are not scattered in a straight line so the line does not describe these data well\n","\n","One thing to keep in mind when looking at a regression plot is to pay attention to how scattered the data points are around the regression line. This will give you a good indication of the variance of the data and whether a linear model would be the best fit or not. If the data is too far off from the line, this linear model might not be the best model for this data.\n","\n","Let's compare this plot to the regression plot of **\"ATR\"**.\n"]},{"cell_type":"code","id":"2c90ab66-bcc7-48bc-86d0-bc35797a07f8","metadata":{},"outputs":[],"source":["plt.figure(figsize=(width, height))\nplt.title(\"ATR as potential predictor variable of Avg_price\")\nsns.regplot(x=\"ATR\", y=\"Avg_price\", data=df, scatter_kws={\"s\": 1})"]},{"cell_type":"markdown","id":"0e0652fa-5a57-4eba-bd5e-a6d4c34de7b1","metadata":{},"outputs":[],"source":["We can see positive correlation and many outliers. But the line does not describe the data well\n"]},{"cell_type":"markdown","id":"f7dba676-b6c4-4139-bab6-afd04912a2e1","metadata":{},"outputs":[],"source":["\u003cdiv class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\"\u003e\n","\n","# **Question #3:**\n","    \n","**Given the regression plots above, is \"AD\" or \"ATR\" more strongly correlated with \"Avg_price\"? Use the method  `.corr()` to verify your answer.**\n","\n","\u003c/div\u003e\n"]},{"cell_type":"code","id":"9e91cc03-e1c7-4ee8-bff2-58c38a237357","metadata":{},"outputs":[],"source":["# Write your code below and press Shift+Enter to execute \n"]},{"cell_type":"markdown","id":"273924b3-b089-4777-936b-bd5b433e2db1","metadata":{},"outputs":[],"source":["\u003cdetails\u003e\u003csummary\u003eClick here for the solution\u003c/summary\u003e\n","\n","```python\n","# The variable \"AD\" has a stronger correlation with \"Avg_price\", it is approximate 0.481835 compared to \"ATR\" which is approximate 0.334486. You can verify it using the following command:\n","\n","df[[\"AD\", \"ATR\", \"Avg_price\"]].corr()\n","\n","```\n","\n","\u003c/details\u003e\n"]},{"cell_type":"markdown","id":"5552bef8-497f-4038-8ddf-8eecb83cb838","metadata":{},"outputs":[],"source":["## **Residual Plot**\n","\n","A good way to visualize the variance of the data is to use a residual plot.\n"]},{"cell_type":"markdown","id":"3fa11a0b-4756-46d2-9152-96b1f161d170","metadata":{},"outputs":[],"source":["**What is a residual?**\n","\n","The difference between the observed value $(y)$ and the predicted value $(\\widehat{Y})$ is called the residual $(e)$. When we look at a regression plot, the residual is the distance from the data point to the fitted regression line.\n","\n","**So what is a residual plot?**\n","\n","A residual plot is a graph that shows the residuals on the vertical $y$-axis and the independent variable on the horizontal $x$-axis.\n","\n","**What do we pay attention to when looking at a residual plot?**\n","\n","We look at the spread of the residuals:\n","\n","If the points in a residual plot are **randomly spread out around the $x$-axis**, then a **linear model is appropriate** for the data.\n","\n","**Why is that?** Randomly spread out residuals means that the variance is constant, and thus the linear model is a good fit for this data.\n"]},{"cell_type":"code","id":"4fdf8a46-a292-408f-b825-2a1f090c8ff8","metadata":{},"outputs":[],"source":["width = 6\nheight = 5\nplt.figure(figsize=(width, height))\nplt.title(\"Residual plot of AD (x) and Avg_price (y)\")\nsns.residplot(x=df[\"AD\"], y=df[\"Avg_price\"], scatter_kws={\"s\": 1})\nplt.show()"]},{"cell_type":"markdown","id":"5706e64b-845d-4a42-8369-a73abdc2160d","metadata":{},"outputs":[],"source":["**What is this plot telling us?**\n","\n","We can see from this residual plot that the residuals are not randomly spread around the $x$-axis, leading us to believe that maybe a non-linear model is more appropriate for this data.\n"]},{"cell_type":"markdown","id":"20aa51b8-2065-4d1f-b1e6-fd8383612644","metadata":{},"outputs":[],"source":["## **Multiple Linear Regression**\n"]},{"cell_type":"markdown","id":"8f3c52ae-5034-45a2-818d-10312cda3f18","metadata":{},"outputs":[],"source":["**How do we visualize a model for Multiple Linear Regression?** This gets a bit more complicated because you can't visualize it with regression or residual plot.\n","\n","One way to look at the fit of the model is by looking at the **distribution plot**. We can look at the distribution of the fitted values that result from the model and compare it to the distribution of the actual values.\n"]},{"cell_type":"markdown","id":"fd33e04f-987b-4005-bea7-364c20e5f920","metadata":{},"outputs":[],"source":["First, let's make a prediction:\n"]},{"cell_type":"code","id":"c34af5a1-5e92-405e-b9a3-f6245853209b","metadata":{},"outputs":[],"source":["Y_hat_mlr = mlr.predict(Z)"]},{"cell_type":"code","id":"b8c56cd4-b8de-49cb-a5aa-084af4b7df9f","metadata":{},"outputs":[],"source":["plt.figure(figsize=(width, height))\n\ntemp_df = pd.DataFrame({\"Avg_price\": df[\"Avg_price\"], \"Fitted values\": Y_hat_mlr})\ntemp_df.plot.kde(figsize=(width, height))\n\nplt.title(\"Actual vs Fitted Values for Avg_price\")\nplt.xlabel(\"Price (in dollars)\")\nplt.ylabel(\"Proportion\")\n\nplt.show()\nplt.close()"]},{"cell_type":"markdown","id":"ab30ccc2-d548-4d0e-85c8-039c32145603","metadata":{},"outputs":[],"source":["\u003cp\u003eWe can see that the fitted values are reasonably close to the actual values. However, there is definitely some room for improvement.\u003c/p\u003e\n"]},{"cell_type":"markdown","id":"f6b66706-e188-484d-93b1-e69cb39dd380","metadata":{},"outputs":[],"source":["# **4. Polynomial Regression and Pipelines**\n"]},{"cell_type":"markdown","id":"b3c5db60-be23-4104-bfa4-7ce4d9d33e8f","metadata":{},"outputs":[],"source":["## **Polynomial regression**\n"]},{"cell_type":"markdown","id":"97bcc82d-8255-4eb8-a58f-a02114a6ae77","metadata":{},"outputs":[],"source":["In statistics, **polynomial regression** is a form of regression analysis in which the relationship between the independent variable $x$ and the dependent variable $y$ is modelled as an $n$-th degree polynomial in $x$. **Polynomial regression** is a particular case of the general linear regression model or multiple linear regression models. We get non-linear relationships by squaring or setting higher-order terms of the predictor variables.\n"]},{"cell_type":"markdown","id":"83a96f77-b5be-4f5b-b6f8-ff6fe4060431","metadata":{},"outputs":[],"source":["There are different orders of polynomial regression:\n"]},{"cell_type":"markdown","id":"0e67d566-94a6-4214-8c11-e50b2be532c2","metadata":{},"outputs":[],"source":["\u003ccenter\u003eQuadratic - 2nd Order\u003c/center\u003e\n","\u003ch3 style=\"margin-bottom: 5px; margin-top: 5px\"\u003e\n","$$\n","Yhat = a + b_1 X +b_2 X^2 \n","$$\n","\u003c/h3\u003e\n","    \n","\u003ccenter\u003eCubic - 3rd Order\u003c/center\u003e\n","\u003ch3 style=\"margin-top: 5px\"\u003e\n","$$\n","Yhat = a + b_1 X +b_2 X^2 +b_3 X^3\n","$$\n","\u003c/h3\u003e \n","\n","\u003ccenter\u003eHigher-Order:\u003c/center\u003e\n","\u003ch3 style=\"margin-top: 5px\"\u003e\n","$$\n","Y = a + b_1 X +b_2 X^2 +b_3 X^3\n","$$\n","\u003c/h3\u003e\n"]},{"cell_type":"markdown","id":"0da87ede-ba41-418b-a88e-823fe47c3b45","metadata":{},"outputs":[],"source":["**The example:** Imagine you want to predict how many likes your new social media post will have at any given point after the publication. There is no linear correlation between the number of likes and the time that passes. Your new post will probably get many likes in the first 24 hours after publication, and then its popularity will decrease.\n"]},{"cell_type":"markdown","id":"1c5c5f88-cf3d-4a73-aa0a-2c59f2fcdc34","metadata":{},"outputs":[],"source":["**Why do we need Polynomial Regression?**\n"]},{"cell_type":"markdown","id":"55cdea86-7f35-4e78-880d-4528091c8e37","metadata":{},"outputs":[],"source":["A simple linear regression algorithm only works when the relationship between the data is linear. But suppose we have non-linear data, then linear regression will not be able to draw a best-fit line. Simple regression analysis fails in such conditions. Consider the below diagram, which has a non-linear relationship, and you can see the linear regression results on it, which does not perform well, meaning it does not come close to reality. Hence, we introduce polynomial regression to overcome this problem, which helps identify the curvilinear relationship between independent and dependent variables.\n"]},{"cell_type":"markdown","id":"a6c3f118-fc13-4233-9971-dad2fb3aa6f8","metadata":{},"outputs":[],"source":["\u003ccenter\u003e\u003cimg width=\"550\" src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-GPXX087UEN/kawer8rc.5_(5).png\" alt=\"poly\"\u003e\u003c/center\u003e\n"]},{"cell_type":"markdown","id":"37690ccc-6263-4a66-b79d-9259c4db6f89","metadata":{},"outputs":[],"source":["**Advantages:**\n","\n","\n","* Can fit complex curves and relationships between the dependent and independent variables.\n","* Can improve the accuracy of predictions compared to linear regression models.\n","* Can be used when the relationship between the dependent and independent variables is non-linear.\n","\n","**Disadvantages:**\n","\n","* Can be overfitting to the data, leading to poor performance on new data.\n","* The higher degree of the polynomial used, the more complex and difficult to interpret the model becomes.\n","* Requires more data than simple linear regression models.\n"]},{"cell_type":"markdown","id":"91a8f84d-8d51-49c1-90ab-2602a4bb5a1a","metadata":{},"outputs":[],"source":["We saw earlier that a linear model did not provide the best fit while using **\"ATR\"** as the predictor variable. Let's see if we can try fitting a polynomial model to the data instead.\n"]},{"cell_type":"markdown","id":"f4b81564-7e8d-4366-833b-e99762a0aaa5","metadata":{},"outputs":[],"source":["\u003cp\u003eWe will use the following function to plot the data:\u003c/p\u003e\n"]},{"cell_type":"code","id":"f00a296e-9af8-4daf-94a8-7ad73671982e","metadata":{},"outputs":[],"source":["def plot_poly(model: Callable, independent_variable: pd.Series, dependent_variable: pd.Series, name: str) -\u003e None:\n    \"\"\"\n    Plots polynomial function\n    \n    Parameters\n    ----------\n    model: Callable\n        Function which will calculate polynomial\n    independent_variable: pd.Series\n        Independent variable (x)\n    dependent_variable: pd.Series\n        Dependent variable (y)\n    name: str\n        Name of indicator which will be used as label of x-axis\n    \"\"\"\n    x_new = np.linspace(min(independent_variable) - 100, max(independent_variable) + 100, 100)\n    y_new = model(x_new)\n\n    plt.plot(independent_variable, dependent_variable, \".\", x_new, y_new, \"-\", markersize=1)\n    plt.title(\"Polynomial Fit with Matplotlib for Price\")\n    ax = plt.gca()\n    ax.set_facecolor((0.898, 0.898, 0.898))\n    fig = plt.gcf()\n    plt.xlabel(name)\n    plt.ylabel(\"Avg_price\")\n\n    plt.show()\n    plt.close()"]},{"cell_type":"markdown","id":"fde01558-f7be-43dd-a3a8-a08f141ef2f1","metadata":{},"outputs":[],"source":["Let's get the variables:\n"]},{"cell_type":"code","id":"08bfa071-e3d3-4f93-9b7b-751e19d16c58","metadata":{},"outputs":[],"source":["X_poly = df[\"AD\"]"]},{"cell_type":"markdown","id":"f04409c2-a5da-419e-976a-3c8d90e2db6e","metadata":{},"outputs":[],"source":["Let's fit the polynomial using the function \u003ccode\u003epolyfit\u003c/code\u003e, then use the function \u003ccode\u003epoly1d\u003c/code\u003e to display the polynomial function.\n"]},{"cell_type":"code","id":"bbcd4a9f-6811-41a0-b887-74666ba03b6c","metadata":{},"outputs":[],"source":["# Here we use a polynomial of the 3rd order (cubic) \nf = np.polyfit(X_poly, Y, 3)\np = np.poly1d(f)\nY_poly = p(X_poly)\nprint(p)"]},{"cell_type":"markdown","id":"2d33942f-c405-48cf-9fe7-821b954dfd9b","metadata":{},"outputs":[],"source":["Let's plot the function:\n"]},{"cell_type":"code","id":"f49af989-d341-4c3f-aa92-bafc0ab92b39","metadata":{},"outputs":[],"source":["plot_poly(p, X_poly, Y, \"AD\")"]},{"cell_type":"code","id":"bae9c8bf-7f44-48b7-a9ad-6280317ef203","metadata":{},"outputs":[],"source":["np.polyfit(X_poly, Y, 3)"]},{"cell_type":"markdown","id":"dd8dbde6-dbba-47e9-b092-bf294f4fc6c2","metadata":{},"outputs":[],"source":["\u003cp\u003eWe can already see from plotting that this polynomial model performs better than the linear model. This is because the generated polynomial function  \"hits\" more of the data points.\u003c/p\u003e\n"]},{"cell_type":"markdown","id":"3acb9ba8-4d7d-436f-88cd-c5bea00d8551","metadata":{},"outputs":[],"source":["\u003cdiv class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\"\u003e\n","\n","# **Question #4:**\n","    \n","**Create 2 order polynomial model with the variables $x$ and $y$ from above.**\n","    \n","\u003c/div\u003e\n"]},{"cell_type":"code","id":"c0bdcac0-d32d-432b-9fe0-da9a76f54ca5","metadata":{},"outputs":[],"source":["# Write your code below and press Shift+Enter to execute \n"]},{"cell_type":"markdown","id":"e9429558-ac27-4a7b-bfaf-8580611c8bde","metadata":{},"outputs":[],"source":["\u003cdetails\u003e\u003csummary\u003eClick here for the solution\u003c/summary\u003e\n","\n","```python\n","# Here we use a polynomial of the 2nd order\n","f1 = np.polyfit(X_poly, Y, 2)\n","p1 = np.poly1d(f1)\n","print(p1)\n","plot_poly(p1, X_poly, Y, \"AD\")\n","\n","```\n","\n","\u003c/details\u003e\n"]},{"cell_type":"markdown","id":"6f0d0eec-eaab-4f99-a2b4-a06452081092","metadata":{},"outputs":[],"source":["The analytical expression for Multivariate Polynomial function gets complicated. For example, the expression for a second-order (`degree=2`) polynomial with two variables is given by:\n"]},{"cell_type":"markdown","id":"38f34505-ac8f-4335-9040-01996c672636","metadata":{},"outputs":[],"source":["\u003ch3\u003e\n","$$\n","\\widehat{Y} = a + b_1 X_1 + b_2 X_2 +b_3 X_1 X_2 + b_4 X_1^2 + b_5 X_2^2\n","$$\n","\u003c/h3\u003e\n"]},{"cell_type":"markdown","id":"7c23b591-00ef-4a06-bbc4-72f1622ea16f","metadata":{},"outputs":[],"source":["We can perform a polynomial transform on multiple features. We create a \u003ccode\u003ePolynomialFeatures\u003c/code\u003e object of degree 2:\n"]},{"cell_type":"code","id":"72f37a8a-5906-428d-8ffb-494f8f254c02","metadata":{},"outputs":[],"source":["pr = PolynomialFeatures(degree=2)\npr"]},{"cell_type":"code","id":"d39aa7eb-f4ba-4ca4-b6dc-a9a3fd77c63a","metadata":{},"outputs":[],"source":["Z_pr = pr.fit_transform(Z)"]},{"cell_type":"markdown","id":"f64136ae-92da-4ea7-9083-f8f884a96cd2","metadata":{},"outputs":[],"source":["In the original data, there are 66846 samples and 4 features.\n"]},{"cell_type":"code","id":"d3150246-01fa-4cdb-8ed7-7affdfb0b907","metadata":{},"outputs":[],"source":["Z.shape"]},{"cell_type":"markdown","id":"6b97a999-1a6e-4303-ba95-ef8318c30ea1","metadata":{},"outputs":[],"source":["After the transformation, there are 66154 samples and 15 features.\n"]},{"cell_type":"code","id":"4904aa5f-2cf8-459a-b711-bef3a01ef5a7","metadata":{},"outputs":[],"source":["Z_pr.shape"]},{"cell_type":"markdown","id":"47816ca4-6ab3-43e9-9e7c-164e6d702fdc","metadata":{},"outputs":[],"source":["## **Pipeline**\n"]},{"cell_type":"markdown","id":"5a9238a2-90cb-4fd8-be8f-6ba97de3a7fc","metadata":{},"outputs":[],"source":["Data Pipelines simplify the steps of processing the data. We use the module `Pipeline` to create a pipeline. We also use `StandardScaler` as a step in our pipeline.\n"]},{"cell_type":"markdown","id":"05d959d3-e5f3-4286-93e0-ade0f0cecd21","metadata":{},"outputs":[],"source":["We create the pipeline by creating a list of tuples including the name of the model or estimator and its corresponding constructor.\n"]},{"cell_type":"code","id":"9c5801b7-42c7-49bc-bf34-271f2ee9c9bb","metadata":{},"outputs":[],"source":["Input = [\n    (\"scale\", StandardScaler()), \n    (\"polynomial\", PolynomialFeatures(include_bias=False)), \n    (\"model\", LinearRegression())\n]"]},{"cell_type":"markdown","id":"d2ca1a77-e889-4aeb-8158-517ecc4ebbd7","metadata":{},"outputs":[],"source":["We input the list as an argument to the pipeline constructor:\n"]},{"cell_type":"code","id":"a4da25ee-f9fc-4ac9-a4de-5ab97d8a814c","metadata":{},"outputs":[],"source":["pipe = Pipeline(Input)\npipe"]},{"cell_type":"markdown","id":"8418a71f-7dc3-4ee0-82ee-0a489f21e220","metadata":{},"outputs":[],"source":["First, we convert the data type `Z` to type float to avoid conversion warnings that may appear as a result of `StandardScaler` taking float inputs.\n","\n","Then, we can normalize the data, perform a transform and fit the model simultaneously.\n"]},{"cell_type":"code","id":"13b07481-9420-4a02-98b3-733af554cb04","metadata":{},"outputs":[],"source":["Z = Z.astype(float)\npipe.fit(Z, Y)"]},{"cell_type":"markdown","id":"2621e9e5-0fce-442d-8250-004c672e1340","metadata":{},"outputs":[],"source":["Similarly,  we can normalize the data, perform a transform and produce a prediction  simultaneously.\n"]},{"cell_type":"code","id":"cc8a0404-f197-41d7-8136-18ef72e114a4","metadata":{},"outputs":[],"source":["y_pipe = pipe.predict(Z)\ny_pipe[0:4]"]},{"cell_type":"markdown","id":"bc7811f0-e76f-4953-8c0d-24fe069c2e5b","metadata":{},"outputs":[],"source":["\u003cdiv class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\"\u003e\n","\n","# **Question #5:**\n","    \n","**Create a pipeline that standardizes the data, then produce a prediction using a linear regression model using the features `Z` and target `Y`.**\n","    \n","\u003c/div\u003e\n"]},{"cell_type":"code","id":"7eef82f7-3973-4527-af9d-417eb2d4e1b5","metadata":{},"outputs":[],"source":["# Write your code below and press Shift+Enter to execute \n"]},{"cell_type":"markdown","id":"3320d6ee-bfd2-4e47-9e14-61ba85a55710","metadata":{},"outputs":[],"source":["\u003cdetails\u003e\u003csummary\u003eClick here for the solution\u003c/summary\u003e\n","\n","```python\n","Input = [\n","    (\"scale\", StandardScaler()),\n","    (\"model\", LinearRegression())\n","]\n","\n","pipe = Pipeline(Input)\n","\n","pipe.fit(Z, Y)\n","\n","y_pipe = pipe.predict(Z)\n","y_pipe[0:10]\n","```\n","\n","\u003c/details\u003e\n"]},{"cell_type":"markdown","id":"96ac2343-3e2b-4a6f-8eec-95c76254644e","metadata":{},"outputs":[],"source":["# **5. Measures for In-Sample Evaluation**\n"]},{"cell_type":"markdown","id":"56c744a8-e840-4d22-8735-8962e71ac990","metadata":{},"outputs":[],"source":["When evaluating our models, not only do we want to visualize the results, but we also want a quantitative measure to determine how accurate the model is.\n","\n","Five very important measures that are often used in Statistics to determine the accuracy of a model are:\n","\n","* **$R^2$ / R-squared**\n","* **Mean Squared Error (MSE)**\n","* **F-test score**\n","* **P-value**\n"]},{"cell_type":"markdown","id":"ef64136a-1618-4421-8ad1-dc11ccac7b5d","metadata":{},"outputs":[],"source":["## **R-squared**\n","\n","**R-squared**, also known as the **coefficient of determination**, is a measure to indicate how close the data is to the fitted regression line.\n","\n","The value of the R-squared is the percentage of variation of the response variable ($y$) that is explained by a linear model.\n","\n","R-squared values range from 0 to 1 and are commonly stated as percentages from 0% to 100%. An R-squared of 100% means that all movements of a security (or another dependent variable) are completely explained by movements in the index (or the independent variable(s) you are interested in).\n","\n","In finance, an R-Squared above 0.7 would generally be seen as showing a high level of correlation, whereas a measure below 0.4 would show a low correlation.\n","\n","## **Mean Squared Error (MSE)**\n","\n","The **Mean Squared Error** measures the average of the squares of errors. That is, the difference between actual value ($y$) and the estimated value ($\\widehat{y}$).\n","\n","## **F-test score**\n","\n","**F-test score** or **Fisher criterion** is a discriminant criterion function that was first presented by Fisher in 1936. It is defined by the ratio of the between-class scatter to the within-class scatter. By maximizing this criterion, one can obtain an optimal discriminant projection axis. After the sample being projected on to this projection axis, the within-class scatter is minimized and the between-class scatter is maximized.\n","\n","## **P-value**\n","\n","The **P-value** is the probability value that the correlation between these two variables is statistically significant. Normally, we choose a significance level of 0.05, which means that we are 95% confident that the correlation between the variables is significant.\n","\n","By convention, when the\n","\n","* p-value is $\u003c$ 0.001: we say there is strong evidence that the correlation is significant.\n","* the p-value is $\u003c$ 0.05: there is moderate evidence that the correlation is significant.\n","* the p-value is $\u003c$ 0.1: there is weak evidence that the correlation is significant.\n","* the p-value is $\u003e$ 0.1: there is no evidence that the correlation is significant.\n"]},{"cell_type":"markdown","id":"eebef685-5aae-4a10-a299-b40f54208568","metadata":{},"outputs":[],"source":["Let's define function that will calculate all needed metrics\n"]},{"cell_type":"code","id":"09901aa4-e08e-47e9-97c6-6727f34bc69e","metadata":{},"outputs":[],"source":["def calculate_metrics(y_pred: Union[pd.Series, np.array], y: Union[pd.Series, np.array]) -\u003e tuple:\n    \"\"\"\n    Calculates R-squared, MSE, F-test score, P-value\n    \n    Parameters\n    ----------\n    y_pred: pd.Series\n        output of model\n    y: pd.Series\n        true values of y\n    \n    Returns\n    -------\n    r2: float\n        R^2 / R-squared\n    mse: float\n        MSE\n    f_val: float\n        F-test score\n    p_val: float\n        P-value\n    \"\"\"\n    r2 = r2_score(y, y_pred)\n    mse = mean_squared_error(y, y_pred)\n    f_val, p_val = stats.f_oneway(y, y_pred)\n    \n    return r2, mse, f_val, p_val"]},{"cell_type":"code","id":"54ddd282-2661-42a6-8049-79b23ac66ee0","metadata":{},"outputs":[],"source":["temp_df = pd.DataFrame({\n    \"y_true\": Y,\n    \"y_pred\": Y_hat,\n    \"ts\": df[\"Ts\"]\n})\ntemp_df.plot(x=\"ts\", y=[\"y_true\", \"y_pred\"], title=\"Comprasion of true values and predicted by SLR\")\nplt.ylabel(\"BUSD\")\nplt.xlabel(\"Time\")"]},{"cell_type":"markdown","id":"06d2eb38-65bf-40be-bccc-010b8bb712be","metadata":{},"outputs":[],"source":["## **Model 1: Simple Linear Regression**\n"]},{"cell_type":"code","id":"34fe4a6a-9f86-4094-b36f-fd11be58070d","metadata":{},"outputs":[],"source":["calculate_metrics(Y_hat, Y)"]},{"cell_type":"markdown","id":"a027029a-d6c9-4e29-8686-e5dc19777f67","metadata":{},"outputs":[],"source":["**Conclusion:**\n","\n","* **$R^2$ / R-squared:** We can say that ≈ 11.18% of the variation of **\"Avg_price\"** is explained by this simple linear model.\n","* **MSE:** We got 0.0026927796894885793\n","* **F-test score:** 4.99 * $10^{-26}$ what means that the differences between the groups being compared are not statistically significant.\n","* **P-value:** 1.0 what means there is no evidence that the correlation is significant\n"]},{"cell_type":"markdown","id":"263cb11a-e979-48b3-8131-36e935dfac45","metadata":{},"outputs":[],"source":["## **Model 2: Multiple Linear Regression**\n"]},{"cell_type":"code","id":"2e387943-ec16-4bea-9a6d-a13486fada32","metadata":{},"outputs":[],"source":["calculate_metrics(Y_mlr, Y)"]},{"cell_type":"markdown","id":"a9f18ce7-b9d5-48a3-9087-db8cd7942e0e","metadata":{},"outputs":[],"source":["**Conclusion:**\n","\n","* **$R^2$ / R-squared:** We can say that ≈ 78.91% of the variation of **\"Avg_price\"** is explained by this multiple linear model.\n","* **MSE:** We got 0.0006392628534897521\n","* **F-test score:** 3.7 * $10^{-27}$ what means that the differences between the groups being compared are not statistically significant\n","* **P-value:** 1.0 what means there is no evidence that the correlation is significant\n"]},{"cell_type":"markdown","id":"d5517ab0-e94b-461a-8554-c63d74793e9b","metadata":{},"outputs":[],"source":["## **Model 3: Polynomial Fit**\n"]},{"cell_type":"code","id":"982cdff8-33e2-4c54-b207-2b93a55e2242","metadata":{},"outputs":[],"source":["calculate_metrics(Y_poly, Y)"]},{"cell_type":"markdown","id":"8dbb0e6c-ee16-442e-a688-1eb7bd1ae1e9","metadata":{},"outputs":[],"source":["**Conclusion:**\n","\n","* **$R^2$ / R-squared**: We can say that ≈ 29.29% of the variation of **\"Avg_price\"** is explained by this polynomial model.\n","* **MSE:** We got 0.0021438907476508517\n","* **F-test score:** 8.02 * $10^{-23}$ what means that the differences between the groups being compared are not statistically significant\n","* **P-value:** 1.0 what means there is no evidence that the correlation is significant\n"]},{"cell_type":"markdown","id":"23d79bc0-1cae-4796-b1d3-588b1b20da6f","metadata":{},"outputs":[],"source":["# **6. Prediction and Decision Making**\n","\n","## **Prediction**\n","\n","In the previous section, we trained the model using the method `fit`. Now we will use the method `predict` to produce a prediction.\n"]},{"cell_type":"code","id":"53ce07ca-ee23-47a0-8496-4e8bd8e73bcf","metadata":{},"outputs":[],"source":["# Generating simple input\nnew_input = np.linspace(min(df[\"ATR\"]), max(df[\"ATR\"]), len(df)).reshape(-1, 1)\nnew_input"]},{"cell_type":"markdown","id":"908ca6a1-b80a-42dd-bb80-9381138600ee","metadata":{},"outputs":[],"source":["Fit the model:\n"]},{"cell_type":"code","id":"b9f65693-ee79-4e10-9cf4-d4f35ea7e45f","metadata":{},"outputs":[],"source":["lm.fit(X_lr, Y)\nlm"]},{"cell_type":"markdown","id":"4d1bdcbe-df1b-4b63-8e75-6e576a432a71","metadata":{},"outputs":[],"source":["Produce a prediction:\n"]},{"cell_type":"code","id":"ad8b4b4d-8272-4ece-bb15-4dcc5740865a","metadata":{},"outputs":[],"source":["yhat = lm.predict(new_input)\nyhat[0:5]"]},{"cell_type":"markdown","id":"7d028c63-13f3-431e-89bc-edfc9aa8e5fb","metadata":{},"outputs":[],"source":["Obviously we have got a straight line. \n"]},{"cell_type":"code","id":"38287c6a-7c4e-447f-91c1-98f06e42ba9b","metadata":{},"outputs":[],"source":["plt.plot(new_input, yhat)\nplt.title(\"Prediction based on ATR\")\nplt.xlabel(\"ATR\")\nplt.ylabel(\"Avg_price\")\nplt.show()"]},{"cell_type":"markdown","id":"cf7d6424-a7ed-4897-92a7-3c78dfc7213c","metadata":{},"outputs":[],"source":["## **Decision Making: Determining a Good Model Fit**\n"]},{"cell_type":"markdown","id":"a541c2d1-8d25-4ee0-8815-710ab1dca32b","metadata":{},"outputs":[],"source":["Now that we have visualized the different models, and generated the R-squared and MSE values for the fits, how do we determine a good model fit?\n","\n","* *What is a good R-squared value?*\n","\n","When comparing models, **the model with the higher R-squared value is a better fit** for the data.\n","\n","* *What is a good MSE?*\n","\n","When comparing models, **the model with the smallest MSE value is a better fit** for the data.\n","\n","* *What is a good F-test score?*\n","\n","When comparing models, **the model with the smallest F-test value is a better fit** for the data.\n","\n","* *What is a good P-value?*\n","\n","When comparing models, **the model with the higher P-value is a better fit** for the data.\n","\n","Let's take a look at the values for the different models.\n","\n","We prefer R-squared, MSE when comparing models. Simple Linear Regression: Using **\"ATR\"** as an independent variable of **\"Avg_price\"**.\n","\n","* **R-squared:** 0.1118\n","* **MSE:** 0.002692\n","* **F-test score:** 4.99 * $10^{-26}$\u003c/sup\u003e\n","* **P-value:** 1.0\n","\n","Multiple Linear Regression: Using **\"ATR\"**, **\"OBV\"**, **\"RSI\"** and **\"AD\"** as predictor variables of **\"Avg_price\"**.\n","\n","* **R-squared:** 0.7891\n","* **MSE:** 0.000639\n","* **F-test score:** 3.7 * $10^{-27}$\n","* **P-value:** 1.0\n","\n","Polynomial Fit: **\"ATR\"**, **\"OBV\"**, **\"RSI\"** and **\"AD\"** as predictor variables of **\"Avg_price\"**.\n","\n","* **R-squared:** 0.2929\n","* **MSE:** 0.002143\n","* **F-test score:**  8.02 * $10^{-23}$\n","* **P-value:** 1.0\n"]},{"cell_type":"markdown","id":"e07c887f-a3f7-460e-92e0-d25b5d258bee","metadata":{},"outputs":[],"source":["## **Simple Linear Regression Model (SLR) vs Multiple Linear Regression Model (MLR)**\n"]},{"cell_type":"markdown","id":"2f1d4de5-750d-4bea-9bf9-a0a222f5e7c2","metadata":{},"outputs":[],"source":["Usually, the more variables you have, the better your model is at predicting, but this is not always true. Sometimes you may not have enough data, you may run into numerical problems, or many of the variables may not be useful and even act as noise. As a result, you should always check the MSE and $R^2$ / R-squared.\n","\n","In order to compare the results of the MLR vs SLR models, we look at a combination of both the R-squared and MSE to make the best conclusion about the fit of the model.\n","\n","* **MSE:** The MSE of SLR is 0.002692 while MLR has an MSE of 0.000639. The MSE of MLR is much smaller.\n","* **R-squared:** In this case, we can also see that there is a difference between the R-squared of the SLR and the R-squared of the MLR. The R-squared for the SLR (≈ 0.1118) is much smaller compared to the R-squared for the MLR (≈ 0.7891).\n","\n","This R-squared in combination with the MSE show that MLR seems like the better model fit in this case compared to SLR.\n"]},{"cell_type":"markdown","id":"60996408-1fa0-4846-94cc-49f0702a334b","metadata":{},"outputs":[],"source":["## **Simple Linear Model (SLR) vs. Polynomial Fit**\n"]},{"cell_type":"markdown","id":"061bf774-c6aa-43d6-9eb5-60639608c882","metadata":{},"outputs":[],"source":["* **MSE:** We can see that Polynomial Fit brought down the MSE, since this MSE is smaller than the one from the SLR.\n","* **R-squared:** The R-squared for the Polynomial Fit is larger than the R-squared for the SLR, so the Polynomial Fit also brought up the R-squared quite a bit.\n","\n","Since the Polynomial Fit resulted in a lower MSE and a higher R-squared, we can conclude that this was a better fit model than the simple linear regression for predicting **\"Avg_price\"** with **\"ATR\"** as a predictor variable.\n"]},{"cell_type":"markdown","id":"a217b765-d32f-4f0b-8a8d-bc0e7944f402","metadata":{},"outputs":[],"source":["## **Multiple Linear Regression (MLR) vs. Polynomial Fit**\n"]},{"cell_type":"markdown","id":"79d07919-b0ca-49a3-ae44-03f573113f7d","metadata":{},"outputs":[],"source":["* **MSE:** The MSE for the MLR is smaller than the MSE for the Polynomial Fit.\n","* **R-squared:** The R-squared for the MLR is larger than for the Polynomial Fit.\n"]},{"cell_type":"markdown","id":"8ce461fe-2ea7-48fe-bdd6-79b180158954","metadata":{},"outputs":[],"source":["# **Conclusion:**\n"]},{"cell_type":"markdown","id":"42b40a89-7774-4d24-998b-a628f56df854","metadata":{},"outputs":[],"source":["Comparing these three models, we conclude that **the MLR model is the best model** to be able to predict **\"Avg_price\"** from our dataset. This result makes sense since we have 4 technical indicators in total and we know that more than one of those indicators are potential predictors of **\"Avg_price\"**.\n"]},{"cell_type":"markdown","id":"5dd076c7-b96a-4e25-996f-a2babb1e2aa7","metadata":{},"outputs":[],"source":["# **7. Sources:**\n","\n","\u003cul\u003e\n","    \u003cli\u003e\u003ca href=\"https://www.spiceworks.com/tech/artificial-intelligence/articles/what-is-linear-regression?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkGuidedProjectsIBMSkillsNetworkGPXX087UEN2510-2023-01-01\"\u003ehttps://www.spiceworks.com/tech/artificial-intelligence/articles/what-is-linear-regression\u003c/a\u003e\u003c/li\u003e\n","    \u003cli\u003e\u003ca href=\"https://www.investopedia.com/terms/m/mlr.asp?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkGuidedProjectsIBMSkillsNetworkGPXX087UEN2510-2023-01-01\"\u003ehttps://www.investopedia.com/terms/m/mlr.asp\u003c/a\u003e\u003c/li\u003e\n","    \u003cli\u003e\u003ca href=\"https://serokell.io/blog/polynomial-regression-analysis?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkGuidedProjectsIBMSkillsNetworkGPXX087UEN2510-2023-01-01\"\u003ehttps://serokell.io/blog/polynomial-regression-analysis\u003c/a\u003e\u003c/li\u003e\n","    \u003cli\u003e\u003ca target=\"_blank\" href=\"https://pimages.toolbox.com/wp-content/uploads/2022/04/07040339/25-4.png?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkGuidedProjectsIBMSkillsNetworkGPXX087UEN2510-2023-01-01\"\u003ehttps://pimages.toolbox.com/wp-content/uploads/2022/04/07040339/25-4.png\u003c/a\u003e\u003c/li\u003e\n","    \u003cli\u003e\u003ca href=\"https://serokell.io/files/ka/kawer8rc.5_(5).png?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkGuidedProjectsIBMSkillsNetworkGPXX087UEN2510-2023-01-01\"\u003ehttps://serokell.io/files/ka/kawer8rc.5_(5).png\u003c/a\u003e\u003c/li\u003e\n","\u003c/ul\u003e\n"]},{"cell_type":"markdown","id":"5a1694ee-ca9b-44b2-aee6-7a8add1c0c3e","metadata":{},"outputs":[],"source":["# **Thank you for completing this lab!**\n","\n","## Author\n","\n","\u003ca href=\"https://author.skills.network/instructors/borys_melnychuk?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkGuidedProjectsIBMSkillsNetworkGPXX087UEN2510-2023-01-01\" \u003eBorys Melnychuk\u003c/a\u003e\n","\n","\u003ca href=\"https://author.skills.network/instructors/yaroslav_vyklyuk_2?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkGuidedProjectsIBMSkillsNetworkGPXX0QGDEN2306-2023-01-01\"\u003eProf. Yaroslav Vyklyuk, DrSc, PhD\u003c/a\u003e\n","\n","\u003ca href=\"https://author.skills.network/instructors/mariya_fleychuk?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkGuidedProjectsIBMSkillsNetworkGPXX0QGDEN2306-2023-01-01\"\u003eProf. Mariya Fleychuk, DrSc, PhD\u003c/a\u003e\n","\n","\n","\n","## Change Log\n","\n","| Date (YYYY-MM-DD) | Version | Changed By      | Change Description                                         |\n","| ----------------- | ------- | ----------------| ---------------------------------------------------------- |\n","|     2023-03-18    |   1.0   | Borys Melnychuk | Creation of the lab                                        |\n","\n","\u003chr\u003e\n","\n","## \u003ch3 align=\"center\"\u003e © IBM Corporation 2023. All rights reserved. \u003c/h3\u003e\n"]}],"metadata":{"kernelspec":{"display_name":"Python","language":"python","name":"conda-env-python-py"},"language_info":{"name":""}},"nbformat":4,"nbformat_minor":4}